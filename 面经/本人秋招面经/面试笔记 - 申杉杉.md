

# Java

## 基础知识

### **1.** Arrays.sort() 的底层实现？

底层使用的排序算法：

- 元素数量少于 47 个时，使用插入排序。
- 大于 47 个，使用快速排序。

### 2. 为什么重写 equals() 方法要重写 hashcode() 方法？

#### hashCode() 有什么用？

`hashCode()` 的作用是获取哈希码（`int` 整数），也称为散列码。这个哈希码的作用是确定该对象在哈希表中的索引位置。

`hashCode()` 定义在 JDK 的 `Object` 类中，这就意味着 Java 中的任何类都包含有 `hashCode()` 函数。另外需要注意的是： `Object` 的 `hashCode()` 方法是本地方法，也就是用 C 语言或 C++ 实现的，该方法通常用来将对象的内存地址转换为整数之后返回。

HashMap 存储的是键值对（key-value），它能根据“键”快速的检索出对应的“值”。这其中就利用到了散列码！（可以快速找到所需要的对象）

#### 为什么要有 hashCode？

我们以“`HashSet` 如何检查重复”为例子来说明为什么要有 `hashCode`？

下面这段内容摘自《Head First Java》:

> 当你把对象加入 `HashSet` 时，`HashSet` 会先计算对象的 `hashCode` 值来判断对象加入的位置，同时也会与其他已经加入的对象的 `hashCode` 值作比较，如果没有相符的 `hashCode`，`HashSet` 会假设对象没有重复出现。但是如果发现有相同 `hashCode` 值的对象，这时会调用 `equals()` 方法来检查 `hashCode` 相等的对象是否真的相同。如果两者相同，`HashSet` 就不会让其加入操作成功。如果不同的话，就会重新散列到其他位置。这样我们就大大减少了 `equals` 的次数，相应就大大提高了执行速度。

因此， `hashCode()` 和 `equals()` 都用于比较两个对象是否相等。

**那为什么 JDK 还要同时提供这两个方法呢？**

这是因为在一些容器（比如 `HashMap`、`HashSet`）中，有了 `hashCode()` 之后，判断元素是否在对应容器中的效率会更高（参考添加元素进 `HashSet` 的过程）！

我们在前面也提到了添加元素进 `HashSet` 的过程，如果 `HashSet` 在对比的时候，同样的 `hashCode` 有多个对象，它会继续使用 `equals()` 来判断是否真的相同。也就是说 `hashCode` 帮助我们大大缩小了查找成本。

**那为什么不只提供 `hashCode()` 方法呢？**

这是因为两个对象的 `hashCode` 值相等并不代表两个对象就相等。

**那为什么两个对象有相同的 `hashCode` 值，它们也不一定是相等的？**

因为 `hashCode()` 所使用的哈希算法也许刚好会让多个对象传回相同的哈希值。越糟糕的哈希算法越容易碰撞，但这也与数据值域分布的特性有关（所谓哈希碰撞也就是指的是不同的对象得到相同的 `hashCode` )。

**总结**：

- 如果两个对象的 `hashCode` 值相等，那这两个对象不一定相等（哈希碰撞）。
- 如果两个对象的 `hashCode` 值相等并且 `equals()` 方法也返回 `true`，我们才认为这两个对象相等。
- 如果两个对象的 `hashCode` 值不相等，我们就可以直接认为这两个对象不相等。

#### 为什么重写 equals() 时必须重写 hashCode() 方法？

因为两个相等的对象的 `hashCode` 值必须是相等。也就是说如果 `equals` 方法判断两个对象是相等的，那这两个对象的 `hashCode` 值也要相等。

如果重写 `equals()` 时没有重写 `hashCode()` 方法的话就可能会导致 `equals` 方法判断是相等的两个对象，`hashCode` 值却不相等。

**思考**：重写 `equals()` 时没有重写 `hashCode()` 方法的话，使用 `HashMap` 可能会出现什么问题。

**总结**：

- `equals` 方法判断两个对象是相等的，那这两个对象的 `hashCode` 值也要相等。
- 两个对象有相同的 `hashCode` 值，他们也不一定是相等的（哈希碰撞）。

> 参考资料：
>
> - [为什么重写equals方法，还必须要重写hashcode方法_被作业逼疯的孩子的博客-CSDN博客_为什么重写了equals就必须重写hashcode](https://blog.csdn.net/jiatenghui1/article/details/124103685)
> - [Java hashCode() 和 equals()的若干问题解答](https://www.cnblogs.com/skywang12345/p/3324958.html)

### 3. final 的底层实现？被 final 修饰的类和方法是否可以被更改？

#### final 的作用

- 修饰类：
  - 被 final 修饰的类无法被继承。
  - 应用场景：如果一个类你永远不会让他被继承（子类继承往往可以重写父类的方法和改变父类属性，会带来一定的安全隐患），就可以用 final 进行修饰。
  - 注意：final 类中的成员变量可以根据需要设置为 final，但是它的所有成员方法会被隐式地指定为 final 方法。
- 修饰方法：
  - 在父类中被 final 修饰的方法无法被子类重写。
  - 注意：如果父类中被 final 修饰的方法的访问控制权限为 private，将会导致子类中不能直接继承到此方法，此时子类中就可以定义相同的方法名和参数（不算重写）。
- 修饰变量：
  - 被 final 修饰的变量不能被修改。
    - 基本类型：其值不能被修改。
    - 引用类型：该引用不能指向别的对象（即该变量所引用的地址值不能发生改变），但被该引用指向的对象的属性值是可以发生变化的。
  - 成员变量：
    - 类变量（static）：被 final 修饰的类变量必须要在静态初始化块中指定初始值或者声明该类变量时指定初始值，而且只能在这两个地方之一进行指定，一旦赋值后不能再修改。
    - 实例变量：被 final 修饰的实例变量必须要在非静态初始化块，声明该实例变量或者在构造器中指定初始值，而且只能在这三个地方之一进行指定，一旦赋值后不能再修改。
  - 局部变量：
    - 变量被声明以后，只能被赋值一次。

final 域重排规则：

- final 域为基本类型：
  - 写规则：
    - 禁止把 final 域的写操作（构造函数中）重排到构造函数之外。
    - 底层实现：final 写 -> storestore 内存屏障 -> 构造函数 return。
    - 异常情况：普通域变量的初始化（构造函数中）可能被重排序到构造函数之外（后），此时读到的是未初始化过的普通域变量。
    - 写 final 域的重排序规则可以保证：在对象引用为任意线程可见之前，对象的 final 域已经被正确初始化过了，而普通域不具有这个保障。
  - 读规则：
    - 禁止重排：初次读对象引用、初次读该对象包含的 final 域。
    - 初次读对象引用 -> loadload 内存屏障 -> 初次读该对象包含的 final 域。
    - 异常情况：读对象的普通域的操作被处理器重排序到读对象引用之前。读普通域时，该域可能还没有被初始化，这是一个错误的读取操作。而读 final 域的重排序规则会把读对象 final 域的操作限定在读对象引用之后，此时该 final 域已经被初始化过了，这是一个正确的读取操作。
    - 读 final 域的重排序规则可以确保：在读一个对象的 final 域之前，一定会先读包含这个 final 域的对象的引用。
- final 域为引用类型：
  - 写规则：……
  - 读规则：……

final 底层实现：

- 写 final 域：写 final 域变量 -> storestore 内存屏障 -> 构造函数返回。
- 读 final 域：读对象引用 -> loadload 内存屏障 -> 读该对象的 final 域变量。

> 参考资料：
>
> - [深入理解final底层原理_贤子磊的博客-CSDN博客_final底层原理](https://blog.csdn.net/weixin_41951205/article/details/123193025)

### 4. Java 的四种引用？

#### 强引用

- 含义：被强引用指向的对象永远不会被系统回收。
- 示例：M m = new M()。
- 当有强引用指向对象时，该对象不会被 System.gc() 回收，只有当 m = null 时才会被回收。

#### 软引用

- 含义：被软引用指向的对象，只有当系统内存不够用时才会被回收。
- 示例：SoftReference<被指对象类型> m = new SoftReference<>(new 被指对象)。
- 应用场景：缓存。

#### 弱引用

- 含义：被弱引用指向的对象，只要遇到 gc 就会被回收。
- 示例：WeakReference< M > m = new WeakReference<>(new M())。
- 应用场景：容器、ThreadLocal。

#### 虚引用

- 含义：被虚引用指向的对象，只要遇到 gc 就会被回收，可以通过 QUEUE 检测到，然后清理堆外内存。
- 示例：PhantomReference< M > pr = new PhantomReference<>(new M(), QUEUE)。
- 应用场景：访问堆外内存。

### 5. ThreadLocal？

ThreadLocal：

- 含义：每一个线程有一个自己独享的内存区域，是一个 Map(ThreadLocal, 存入的对象)。
- 示例：ThreadLocal<存入的对象类型> tl = new ThreadLocal<>()。
- 应用场景：声明式事务，保证同一个 Connection，保存与获取登录用户的 id。

弱引用与内存泄露的问题：

![Image](E:\编程学习\学习笔记\面试笔记\img\Image-165767781814818.png)

![Image](E:\编程学习\学习笔记\面试笔记\img\Image-165767787593019.png)

> 参考资料：
>
> - [ThreadLocalMap里弱引用_vicoqi的博客-CSDN博客_threadlocal弱引用](https://blog.csdn.net/vicoqi/article/details/79743112)

### 6. 值传递和引用传递的区别？

Java 只有值传递！

- 值传递：在方法调用的时候，实参是将自己的一份拷贝赋给形参，在方法内，对该参数值的修改不影响原来的实参。
- 引用传递：在方法调用的时候，实参将自己的地址传递给形参，此时方法内对该参数值的改变，就是对该实参的实际操作。

当方法参数是 Integer 类型时：

- Integer 使用 final 修饰的 int 进行存储。
- 被 final 修饰的变量不能被重新赋值，所以操作参数传递变量时，实际上是操作变量对象的副本（Java 中的包装类型都是默认使用这种方式实现的，使用拷贝副本的方式提升效率和减少内存消耗）。 

当方法参数是数组类型时：

- 形参数组是原数组对象的引用的拷贝，而不是对象本身的拷贝。
- 实参数组变量（引用）与方法形参数组（引用）指向的是同一个数组对象。

对于 swap 方法，若参数是引用类型，判断原内容到底有没有交换，主要是看它修改的是变量（引用）还是修改的引用里面的数据。

> 参考资料：
>
> - [Java中是值传递和引用传递_秦淼的博客-CSDN博客_java值传递和引用传递](https://blog.csdn.net/qq_52467117/article/details/122508481)
> - [为什么 Java 中只有值传递？ | JavaGuide](https://javaguide.cn/java/basis/why-there-only-value-passing-in-java.html#案例3-传递引用类型参数2)

### 7. Java 深拷贝和浅拷贝？

#### 对象拷贝

- 需要实现标记接口 Cloneable。（标记接口：内容是空的，没有方法，仅用作标记）
- 应用场景：用于一个对象的属性已经确定，需要产生很多相同对象的时候。

#### 浅拷贝

- 浅拷贝会在堆上创建一个新的对象（区别于引用拷贝的一点），不过，如果原对象内部的属性是引用类型的话，浅拷贝会直接复制内部对象的引用地址，也就是说拷贝对象和原对象共用同一个内部对象。
- p1 和 p2 的 loc 指向同一个对象（内存），修改 p1 的 loc 以后，p2 的 loc 也会跟着变化。
- 缺点：两个复制的对象之间，他们的 loc 指向同一个对象，互相之间会有影响。

```java
class Person implements Cloneable {
    int age = 8;
    int score = 100;
    Location loc = new Location("bj", 22);
    
    @Override
    public Object clone() throws CloneNotSupportedException {
        return super.clone();
    }
}

class Test {
    public static void main(String[] args){
        Person p1 = new Person();
        Person p2 = (Person)p1.clone();
        // 测试
        System.out.println(p1.loc == p2.loc); // true
        p1.loc.street = "sh";
        System.out.println(p2.loc.street); // "sh"
    }
}
```

#### 深拷贝

要解决上面的问题，可以让 Location 也去实现 Cloneable 接口，并在 Person 中重写 clone 方法，对 Location 对象也做一次克隆。

- 深拷贝会完全复制整个对象，包括这个对象所包含的内部对象。
- 复制成员对象的值到新开辟的空间，副本和原来的值没有任何耦合。
- 在拷贝 person 对象的时候，将其 loc 对象也重新拷贝一份（为其分配新的内存，而不是只拷贝 loc 对象的引用）。
- 注意：String 类型的成员不需要进行深克隆。

```java
class Person implements Cloneable {
    int age = 8;
    int score = 100;
    Location loc = new Location("bj", 22);
    
    @Override
    public Object clone() throws CloneNotSupportedException {
        Person p = (Person) super.clone();
        // 额外克隆一份 Location 对象
        p.loc = (Location) loc.clone();
        return p;
    }
}

class Test {
    public static void main(String[] args){
        Person p1 = new Person();
        Person p2 = (Person) p1.clone();
        // 测试
        System.out.println(p1.loc == p2.loc); // false
        p1.loc.street = "sh";
        System.out.println(p2.loc.street); // "bj"
    }
}
```

String 类型：

![Image](E:\编程学习\学习笔记\面试笔记\img\Image-165767941138320.png)

![Image](E:\编程学习\学习笔记\面试笔记\img\Image-165767941963221.png)

#### 引用拷贝

简单来说，引用拷贝就是两个不同的引用指向同一个对象。

![浅拷贝、深拷贝、引用拷贝示意图](%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0%20-%20%E7%94%B3%E6%9D%89%E6%9D%89.assets/shallow&deep-copy.jpg)

> 参考资料：
>
> - [Java浅拷贝和深拷贝(一文足矣)，及String类型的坑。_JAVA|Mr.Java的博客-CSDN博客](https://blog.csdn.net/q258523454/article/details/88942478)

### 8. 说说反射的用途及实现？反射是不是很慢？我们在项目中是否要避免使用反射？

应用场景：反射被广泛地用于那些需要在运行时检测或修改程序行为的程序中。

获取字节码 class 对象的三种方法：

- Class.forName()：
  - 程序未运行时，使用 Class.forName("导包全类名") 将字节码文件加载进内存，返回 class 对象。
  - 使用场景：多用于配置文件，将类名定义在配置文件中，读取文件，加载类。
- 类名.class：
  - 通过类名的属性 class 获取。
  - 使用场景：多用于参数的传递。
- 对象名.getClass()：
  - 对象已经创建时，使用对象名.getClass() 获取，getClass 方法在 Object 类中定义。
  - 使用场景：多用于对象的获取字节码的方式。

优点：

- 提高了程序的灵活性、扩展性和自适应能力，降低了耦合性。
- 它允许程序创建和控制任何类的对象，无需提前硬编码目标类。

缺点：

- 影响性能：反射包括了一些动态类型，所以 JVM 无法对这些代码进行优化。因此，反射操作的效率要比那些非反射操作低得多。我们应该避免在经常被执行的代码或对性能要求很高的程序中使用反射。
- 安全限制：使用反射技术要求程序必须在一个没有安全限制的环境中运行。
- 内部暴露：由于反射允许代码执行一些在正常情况下不被允许的操作（比如访问私有的属性和方法），所以使用反射可能会导致意料之外的副作用：代码有功能上的错误，降低可移植性。 反射代码破坏了抽象性，因此当平台发生改变的时候，代码的行为就有可能也随着变化。

> 参考资料：
>
> - [使用反射的优缺点_丘鸣山RM的博客-CSDN博客_反射的优缺点](https://blog.csdn.net/zyzBulus/article/details/90605429)
> - [java获取字节码class对象的三种方法_程序员小宁的博客-CSDN博客_java 获取class字节码](https://blog.csdn.net/qq_33088807/article/details/111369083?utm_medium=distribute.pc_aggpage_search_result.none-task-blog-2~aggregatepage~first_rank_ecpm_v1~rank_v31_ecpm-1-111369083-null-null.pc_agg_new_rank&utm_term=java+字节码获取对象&spm=1000.2123.3001.4430)

### 9. Integer 常量缓存池？

示例：

```java
// 若 x 在 -128 到 127 范围内，则是同一个对象。
Integer a , b = x;
// 若 x 在 -128 到 127 范围外，则不是同一个对象。
Integer c , d = x;

// 通过 new 创建的是不同的对象。
Integer e = new Integer("100");
Integer f = new Integer("100");
```

总结：

- Java 中，在 -128 ~ 127 的 Integer 值并且以 Integer x = value 的方式赋值的 Integer 值在进行 == 和 equals 比较时，都会返回 true，因为 Java 里面对处在 -128~127 之间的 Integer 值，用的是原生数据类型 int，会存在整数型常量内存池里，也就是说这之间的 Integer 值进行 == 比较时只是进行 int 原生数据类型的数值比较，而超出 -128~127 的范围，进行 == 比较时是进行地址及数值比较。
- 如果通过 Integer x = new Integer("xxx") 方式创建，还是和以前创建对象引用一样，在堆区中创建一个对象，然后将栈中引用指向这个对象，因此两个引用的内存地址不同。

### 10.基本类型和包装类型的区别？

- 成员变量包装类型不赋值就是 `null` ，而基本类型有默认值且不是 `null`。
- 包装类型可用于泛型，而基本类型不可以。
- 基本数据类型的局部变量存放在 Java 虚拟机栈中的局部变量表中，基本数据类型的成员变量（未被 `static` 修饰）存放在 Java 虚拟机的堆中。包装类型属于对象类型，我们知道几乎所有对象实例都存在于堆中。
- 相比于对象类型， 基本数据类型占用的空间非常小。

**为什么说是“几乎”所有对象实例（在堆上分配内存）呢？**

这是因为 HotSpot 虚拟机引入了 JIT 优化之后，会对对象进行逃逸分析，如果发现某一个对象并没有逃逸到方法外部，那么就可能通过标量替换来实现栈上分配，而避免堆上分配内存。

注意：**基本数据类型存放在栈中是一个常见的误区！** 

基本数据类型的成员变量如果没有被 `static` 修饰的话（不建议这么使用，应该要使用基本数据类型对应的包装类型），就存放在堆中。

### 11. 包装类型的缓存机制了解么？

Java 基本数据类型的包装类型的大部分都用到了缓存机制来提升性能。

`Byte`、`Short`、`Integer`、`Long` 这 4 种包装类默认创建了数值 **[-128，127]** 的相应类型的缓存数据，`Character` 创建了数值在 **[0,127]** 范围的缓存数据，`Boolean` 直接返回 `True` or `False`。

如果超出对应范围仍然会去创建新的对象，缓存的范围区间的大小只是在性能和资源之间的权衡。

两种浮点数类型的包装类 `Float`、`Double` 并没有实现缓存机制。

```java
Integer i1 = 33;
Integer i2 = 33;
System.out.println(i1 == i2); // true

Float i11 = 333f;
Float i22 = 333f;
System.out.println(i11 == i22); // false

Double i3 = 1.2;
Double i4 = 1.2;
System.out.println(i3 == i4); // false

Integer i1 = 40;
Integer i2 = new Integer(40);
System.out.println(i1 == i2); // false
```

对于最后一个例子：`Integer i1 = 40` 这一行代码会发生装箱，也就是说这行代码等价于 `Integer i1 = Integer.valueOf(40)` 。因此，`i1` 直接使用的是缓存中的对象。而 `Integer i2 = new Integer(40)` 会直接创建新的对象。因此，答案是 `false` 。

**所有整型包装类对象之间值的比较，应全部使用 equals 方法进行比较**（`==` 比较的是实际引用的内存地址）。

总结：

- 对于 Integer = … 在 -128 ~ 127 之间的赋值，会复用已有对象，这个区间内的 Integer 对象可以直接使用 == 进行判断。
- 在这个区间范围外的对象会在堆上创建，不会复用已有对象，应使用 equals 方法进行判断。

### 12. 自动装箱与拆箱了解吗？原理是什么？

什么是自动装箱与拆箱？

- **装箱**：将基本类型用它们对应的引用类型包装起来。
- **拆箱**：将包装类型转换为基本数据类型。

举例：

```java
Integer i = 10;  // 装箱
int n = i;   // 拆箱
```

- `Integer i = 10` 等价于 `Integer i = Integer.valueOf(10)`。
- `int n = i` 等价于 `int n = i.intValue()`。

注意：如果频繁拆装箱的话，会严重影响系统的性能，因此我们应该尽量避免不必要的拆装箱操作。

### 13. 为什么浮点数运算的时候会有精度丢失的风险？

#### 精度丢失的原因

示例：

```java
float a = 2.0f - 1.9f;
float b = 1.8f - 1.7f;
System.out.println(a); // 0.100000024
System.out.println(b); // 0.099999905
System.out.println(a == b); // false
```

我们知道计算机是二进制的，而且计算机在表示一个数字时，宽度是有限的，无限循环的小数存储在计算机时，只能被截断，所以就会导致小数精度发生损失的情况。这也就是解释了为什么浮点数没有办法用二进制精确表示。

就比如说十进制下的 0.2 就没办法精确转换成二进制小数：

```java
// 0.2 转换为二进制数的过程为：不断乘以 2，直到不存在小数为止，在这个计算过程中，得到的整数部分从上到下排列就是二进制的结果（乘二取余）。
0.2 * 2 = 0.4 -> 0
0.4 * 2 = 0.8 -> 0
0.8 * 2 = 1.6 -> 1
0.6 * 2 = 1.2 -> 1
0.2 * 2 = 0.4 -> 0（发生循环）
// ...
```

浮点数之间的等值判断：

- 基本数据类型不能用 == 来比较。
- 包装数据类型不能用 equals 来判断。

![image-20220817113250468](%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0%20-%20%E7%94%B3%E6%9D%89%E6%9D%89.assets/image-20220817113250468.png)

如何解决？

![image-20220817113339572](%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0%20-%20%E7%94%B3%E6%9D%89%E6%9D%89.assets/image-20220817113339572.png)

#### BigDecimal

`BigDecimal` 可以实现对浮点数的运算，不会造成精度丢失。通常情况下，大部分需要浮点数精确运算结果的业务场景（比如涉及到钱的场景）都是通过 `BigDecimal` 来做的。

```java
BigDecimal a = new BigDecimal("1.0");
BigDecimal b = new BigDecimal("0.9");
BigDecimal c = new BigDecimal("0.8");

BigDecimal x = a.subtract(b);
BigDecimal y = b.subtract(c);

System.out.println(x); // 0.1
System.out.println(y); // 0.1
System.out.println(Objects.equals(x, y)); // true
```

##### 构造方法

![img](%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0%20-%20%E7%94%B3%E6%9D%89%E6%9D%89.assets/image-20211213102222601.png)

##### 加减乘除

`add` 方法用于将两个 `BigDecimal` 对象相加，`subtract` 方法用于将两个 `BigDecimal` 对象相减。`multiply` 方法用于将两个 `BigDecimal` 对象相乘，`divide` 方法用于将两个 `BigDecimal` 对象相除。

```java
BigDecimal a = new BigDecimal("1.0");
BigDecimal b = new BigDecimal("0.9");
System.out.println(a.add(b)); // 1.9
System.out.println(a.subtract(b)); // 0.1
System.out.println(a.multiply(b)); // 0.90
System.out.println(a.divide(b)); // 无法除尽，抛出 ArithmeticException 异常
System.out.println(a.divide(b, 2, RoundingMode.HALF_UP)); // 1.11
```

这里需要注意的是，在我们使用 `divide` 方法的时候尽量使用 3 个参数版本，并且`RoundingMode` 不要选择 `UNNECESSARY`，否则很可能会遇到 `ArithmeticException`（无法除尽出现无限循环小数的时候），其中 `scale` 表示要保留几位小数，`roundingMode` 代表保留规则。

##### 比较大小

`a.compareTo(b)` : 返回 -1 表示 `a` 小于 `b`，0 表示 `a` 等于 `b` ， 1 表示 `a` 大于 `b`。

![img](%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0%20-%20%E7%94%B3%E6%9D%89%E6%9D%89.assets/image-20220714161315993.png)

equals 比较的是值的大小（value）和精度（scale）。

##### 保留规则

通过 `setScale` 方法设置保留几位小数以及保留规则。保留规则有挺多种，不需要记，IDEA 会提示。

```java
BigDecimal m = new BigDecimal("1.255433");
BigDecimal n = m.setScale(3, RoundingMode. HALF_DOWN);
System.out.println(n); // 1.255
```

> 参考资料：
>
> - [BigDecimal 详解 | JavaGuide](https://javaguide.cn/java/basis/bigdecimal.html#bigdecimal-介绍)

### 14. 超过 long 整型的数据应该如何表示？

基本数值类型都有一个表达范围，如果超过这个范围就会有数值溢出的风险。在 Java 中，64 位 long 整型是最大的整数类型。

```java
long l = Long.MAX_VALUE;
System.out.println(l + 1); // -9223372036854775808
System.out.println(l + 1 == Long.MIN_VALUE); // true
```

`BigInteger` 内部使用 `int[]` 数组来存储任意大小的整形数据。相对于常规整数类型的运算来说，`BigInteger` 运算的效率会相对较低。

### 15. 对象相等和引用相等的区别？

- 对象相等一般比较的是内存中存放的内容是否相等。
- 引用相等一般比较的是他们指向的内存地址是否相等。

### 16. 类的构造方法可以被重写吗？

构造方法不能被 override（重写），但是可以 overload（重载），所以你可以看到一个类中有多个构造函数的情况。

### 17. 接口和抽象类有什么共同点和区别？

#### 共同点

- 都不能被实例化。
- 都可以包含抽象方法。
- 都可以有默认实现的方法（Java 8 可以用 `default` 关键字在接口中定义默认方法）。

#### 区别

- 接口主要用于对类的行为进行约束，你实现了某个接口就具有了对应的行为。抽象类主要用于代码复用，强调的是所属关系。
- 一个类只能继承一个类，但是可以实现多个接口。
- 接口中的成员变量只能是 `public static final` 类型的，不能被修改且必须有初始值，而抽象类的成员变量默认 default，可在子类中被重新定义，也可被重新赋值。

### 18. Object 类的常见方法有哪些？

Object 类是一个特殊的类，是所有类的父类。它主要提供了以下 11 个方法：

```java
/**
 * native 方法，用于返回当前运行时对象的 Class 对象，使用了 final 关键字修饰，故不允许子类重写。
 */
public final native Class<?> getClass()
    
/**
 * native 方法，用于返回对象的哈希码，主要使用在哈希表中，比如 JDK 中的 HashMap。
 */
public native int hashCode()
    
/**
 * 用于比较 2 个对象的内存地址是否相等，String 类对该方法进行了重写以用于比较字符串的值是否相等。
 */
public boolean equals(Object obj)
    
/**
 * naitive 方法，用于创建并返回当前对象的一份拷贝。
 */
protected native Object clone() throws CloneNotSupportedException
    
/**
 * 返回类的名字实例的哈希码的 16 进制的字符串。建议 Object 所有的子类都重写这个方法。
 */
public String toString()
    
/**
 * native 方法，并且不能重写。唤醒一个在此对象监视器上等待的线程(监视器相当于就是锁的概念)。如果有多个线程在等待只会任意唤醒一个。
 */
public final native void notify()
    
/**
 * native 方法，并且不能重写。跟 notify 一样，唯一的区别就是会唤醒在此对象监视器上等待的所有线程，而不是一个线程。
 */
public final native void notifyAll()
    
/**
 * native 方法，并且不能重写。暂停线程的执行。注意：sleep 方法没有释放锁，而 wait 方法释放了锁，timeout 是等待时间。
 */
public final native void wait(long timeout) throws InterruptedException
    
/**
 * 多了 nanos 参数，这个参数表示额外时间（以毫微秒为单位，范围是 0-999999）。所以超时的时间还需要加上 nanos 毫秒。
 */
public final void wait(long timeout, int nanos) throws InterruptedException
    
/**
 * 跟之前的 2 个 wait 方法一样，只不过该方法一直等待，没有超时时间这个概念
 */
public final void wait() throws InterruptedException
    
/**
 * 实例被垃圾回收器回收的时候触发的操作
 */
protected void finalize() throws Throwable { }
```

### 19. == 和 equals() 的区别？

#### ==

**`==`** 对于基本类型和引用类型的作用效果是不同的：

- 对于基本数据类型来说，`==` 比较的是值。
- 对于引用数据类型来说，`==` 比较的是对象的内存地址。

因为 Java 只有值传递，所以，对于 == 来说，不管是比较基本数据类型，还是引用数据类型的变量，其本质比较的都是值，只是引用类型变量存的值是对象的地址。

#### equals()

`equals()` 不能用于判断基本数据类型的变量，只能用来判断两个对象是否相等。`equals()` 方法存在于 `Object` 类中，而 `Object` 类是所有类的直接或间接父类，因此所有的类都有 `equals()` 方法。

`equals()` 的两种使用方法：

- **类没有重写 `equals()` 方法**：通过 `equals()` 比较该类的两个对象时，等价于通过 `==` 比较这两个对象，使用的默认是 `Object` 类的 `equals()` 方法。
- **类重写了 `equals()`方法**：一般我们都重写 `equals()` 方法来比较两个对象中的属性是否相等；若它们的属性相等，则返回 true（即，认为这两个对象相等）。

#### String

`String` 中的 `equals` 方法是被重写过的，因为 `Object` 的 `equals` 方法是比较的对象的内存地址，而 `String` 的 `equals` 方法比较的是对象的值。

当创建 `String` 类型的对象时（不使用 new），虚拟机会在常量池中查找有没有已经存在的值和要创建的值相同的对象，如果有就把它赋给当前引用。如果没有就在常量池中重新创建一个 `String` 对象。

```java
String a = new String("ab"); // a 为一个引用
String b = new String("ab"); // b 为另一个引用，对象的内容一样
String aa = "ab"; // 放在常量池中
String bb = "ab"; // 从常量池中查找
System.out.println(aa == bb); // true
System.out.println(a == b); // false
System.out.println(a.equals(b)); // true
System.out.println(42 == 42.0); // true
```

### 20. String、StringBuffer、StringBuilder 的区别？

#### （1）可变性

`String` 是不可变的。

`StringBuilder` 与 `StringBuffer` 都继承自 `AbstractStringBuilder` 类，在 `AbstractStringBuilder` 中也是使用字符数组保存字符串，不过没有使用 `final` 和 `private` 关键字修饰，最关键的是这个 `AbstractStringBuilder` 类还提供了很多修改字符串的方法比如 `append` 方法。

#### （2）线程安全性

`String` 中的对象是不可变的，也就可以理解为常量，线程安全。

`AbstractStringBuilder` 是 `StringBuilder` 与 `StringBuffer` 的公共父类，定义了一些字符串的基本操作，如 `expandCapacity`、`append`、`insert`、`indexOf` 等公共方法。

- `StringBuffer` 对方法加了同步锁或者对调用的方法加了同步锁，所以是线程安全的。
- `StringBuilder` 并没有对方法进行加同步锁，所以是非线程安全的（适用于单线程的情况）。

#### （3）性能

每次对 `String` 类型进行改变（`+` 与 `subString`）的时候，都会生成一个新的 `String` 对象，然后将指针指向新的 `String` 对象。

`StringBuffer` 每次都会对 `StringBuffer` 对象本身进行操作，而不是生成新的对象并改变对象引用。相同情况下使用 `StringBuilder` 相比使用 `StringBuffer` 仅能获得 10%~15% 左右的性能提升，但却要冒多线程不安全的风险。

### 21. String 为什么是不可变的?

#### 什么是不可变类？

对于 Java 而言，除了 primitive type 值（即 int、long、double 等），其余的都是对象，因此讨论不可变类即讨论不可变对象。

不可变对象的特点：

- 对象一旦创建后，其状态不可修改。
- 所有域都是 final 类型。
- 其构造函数构造对象期间，this 引用没有泄露。

除了 String 类型之外，Integer 等包装类也属于不可变类。

#### String 为什么是不可变的?

String 对象的不可变是由于对 String 类型的所有改变，内部存储结构的操作都会 new 出一个新的 String 对象。

如下所示，将一个字符串赋值为一个新的值，不是在原内存地址上修改数据，而是重新指向一个新对象（新地址）。

![image-20220817173944174](%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0%20-%20%E7%94%B3%E6%9D%89%E6%9D%89.assets/image-20220817173944174.png)

`String` 类中使用 `final` 关键字修饰字符数组来保存字符串。

注意：`String` 对象是可变的。

```java
public final class String implements java.io.Serializable, Comparable<String>, CharSequence {
    private final char value[];
	//...
}
```

我们知道被 `final` 关键字修饰的类不能被继承，修饰的方法不能被重写，修饰的变量是基本数据类型则值不能改变，修饰的变量是引用类型则不能再指向其他对象。

因此，`final` 关键字修饰的数组保存字符串并不是 `String` 不可变的根本原因，因为这个数组保存的字符串是可变的（这个数组的引用不可变，但是堆中数组的内容是可变的）。

`String` 不可变的真正原因：

- 保存字符串的数组被 `final` 修饰且为私有的，并且 `String` 类没有提供/暴露修改这个字符串的方法（set 方法）。
- `String` 类被 `final` 修饰导致其不能被继承，进而避免了子类破坏 `String` 不可变。

为什么 char 数组已经是 private 了却还要用 final 修饰呢？

- 禁止继承的子类修改。
- 防止通过反射的方式被修改。

在 Java 9 之后，`String` 、`StringBuilder` 与 `StringBuffer` 的实现改用 `byte` 数组存储字符串。

总结：String 是不可变的关键都在于底层的实现方式，而不只是因为一个 final。

#### 不可变有什么好处？

因为安全！

不要用可变类型做 HashMap 和 HashSet 的键值，因为可能会破坏其键值的唯一性。

![image-20220817175624657](%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0%20-%20%E7%94%B3%E6%9D%89%E6%9D%89.assets/image-20220817175624657.png)

在并发场景下，多个线程同时读一个资源，是不会引发竟态条件的。只有对资源做写操作才有危险。不可变对象不能被写，所以线程安全。

String 类型有一个字符串常量池，在大量使用相同字符串的情况下，可以节省内存空间，提高效率。

> 参考资料：
>
> - [如何理解 String 类型值的不可变？ - 知乎提问](https://www.zhihu.com/question/20618891/answer/114125846)

### 22. 字符串拼接用 + 还是 StringBuilder?

Java 语言本身并不支持运算符重载，`+` 和 `+=` 是专门为 String 类重载过的运算符，也是 Java 中仅有的两个重载过的运算符。

字符串对象使用 `+` 的拼接方式，实际上是通过 `StringBuilder` 调用 `append()` 方法实现的，拼接完成之后调用 `toString()` 得到一个新的 `String` 对象。

不过，在循环内使用 `+` 进行字符串拼接的话，存在比较明显的缺陷：编译器不会创建单个 `StringBuilder` 以复用，会导致创建过多的 `StringBuilder` 对象。如果直接使用 `StringBuilder` 对象进行字符串拼接的话，就不会存在这个问题了。

```java
String[] arr = {"he", "llo", "world"};
StringBuilder s = new StringBuilder();
for (String value : arr) {
    s.append(value);
}
System.out.println(s);
```

### 23. 字符串常量池？

#### 基本概念

字符串常量池是 JVM 为了提升性能和减少内存消耗针对字符串（String）专门开辟的一块区域，主要目的是为了避免字符串的重复创建。

```java
// 在堆中创建字符串对象”ab“
// 将字符串对象”ab“的引用保存在字符串常量池中
String aa = "ab";
// 直接返回字符串常量池中字符串对象”ab“的引用
String bb = "ab";
System.out.println(aa == bb); // true
```

#### String s1 = new String("abc"); 创建了几个字符串对象？

会创建 1 或 2 个字符串对象：

- 如果字符串常量池中不存在字符串对象“abc”的引用，那么会在堆中创建 2 个字符串对象“abc”。（即在堆、堆的常量池中分别创建一个对象）
  - 在堆中创建一个 String 对象，此时未被初始化。
  - 堆中创建字符串对象“abc”，并在字符串常量池中保存对应的引用。`ldc` 命令用于判断字符串常量池中是否保存了对应的字符串对象的引用，如果保存了的话直接返回，如果没有保存的话，会在堆中创建对应的字符串对象并将该字符串对象的引用保存到字符串常量池中。
  - 调用构造方法对之前创建的 String 对象赋值。
- 如果字符串常量池中已存在字符串对象“abc”的引用，则只会在堆中创建 1 个字符串对象“abc”。

#### intern() 方法

`String.intern()` 是一个 native（本地）方法，其作用是将指定的字符串对象的引用保存在字符串常量池中，可以简单分为两种情况：

- 如果字符串常量池中保存了对应的字符串对象的引用，就直接返回该引用。
- 如果字符串常量池中没有保存对应的字符串对象的引用，那就在常量池中创建一个指向该字符串对象的引用并返回。

```java
// 在堆中创建字符串对象”Java“
// 将字符串对象”Java“的引用保存在字符串常量池中
String s1 = "Java";
// 直接返回字符串常量池中字符串对象”Java“对应的引用
String s2 = s1.intern();
// 会在堆中再创建一个字符串对象
String s3 = new String("Java");
// 直接返回字符串常量池中字符串对象”Java“对应的引用
String s4 = s3.intern();
// s1 和 s2 指向的是堆中的同一个对象
System.out.println(s1 == s2); // true
// s3 和 s4 指向的是堆中不同的对象
System.out.println(s3 == s4); // false
// s1 和 s4 指向的是堆中的同一个对象
System.out.println(s1 == s4); // true
```

#### String 类型的变量和常量做 + 运算时发生了什么？

先来看字符串不加 `final` 关键字拼接的情况（JDK1.8）：

```java
String str1 = "str";
String str2 = "ing";
String str3 = "str" + "ing"; // 常量池中的对象
String str4 = str1 + str2; // 在堆上创建的新的对象
String str5 = "string"; // 常量池中的对象
System.out.println(str3 == str4); // false
System.out.println(str3 == str5); // true
System.out.println(str4 == str5); // false
```

注意 ：比较 String 字符串的值是否相等，可以使用 `equals()` 方法。 `String` 中的 `equals` 方法是被重写过的。 `Object` 的 `equals` 方法比较的是对象的内存地址，而 `String` 的 `equals` 方法比较的是字符串的值是否相等。

对于编译期可以确定值的字符串，也就是常量字符串 ，jvm 会将其存入字符串常量池。并且，字符串常量拼接得到的字符串常量也会在编译阶段被存放到字符串常量池中，这得益于编译器的优化。

在编译过程中，Javac 编译器（下文中统称为编译器）会进行一个叫做“**常量折叠**” (Constant Folding) 的代码优化。常量折叠会把常量表达式的值求出来作为常量嵌在最终生成的代码中，这是 Javac 编译器会对源代码做的极少量优化措施之一。

对于 `String str3 = "str" + "ing";` 编译器会给你优化成 `String str3 = "string";` 。

并不是所有的常量都会进行折叠，只有编译器在程序编译期就可以确定值的常量才可以：

- 基本数据类型( `byte`、`boolean`、`short`、`char`、`int`、`float`、`long`、`double`)以及字符串常量。
- `final` 修饰的基本数据类型和字符串变量。
- 字符串通过 `+` 拼接得到的字符串、基本数据类型之间算数运算（加减乘除）、基本数据类型的位运算（<<、>>、>>> ）。

引用的值在程序编译期是无法确定的，编译器无法对其进行优化。对象引用和 + 的字符串拼接方式，实际上是通过 `StringBuilder` 调用 `append()` 方法实现的，拼接完成之后调用 `toString()` 得到一个 `String` 对象。

我们平时在写代码的时候，应尽量避免多个字符串对象的拼接，因为这样会重新创建对象。如果需要改变字符串的话，可以使用 `StringBuilder` 或者 `StringBuffer`。

不过，字符串使用 `final` 关键字声明之后，可以被编译器当做常量来处理。

```java
final String str1 = "str";
final String str2 = "ing";
// 下面两个表达式其实是等价的
String c = "str" + "ing"; // 常量池中的对象
String d = str1 + str2; // 常量池中的对象
System.out.println(c == d); // true
```

被 `final` 关键字修饰之后的 `String` 变量会被编译器当做常量来处理，编译器在程序编译期就可以确定它的值，其效果就相当于访问常量。

如果编译器在运行时才能知道其确切值的话，就无法对其优化。如下所示，`str2` 在运行时才能确定其值：

```java
final String str1 = "str";
final String str2 = getStr();
String c = "str" + "ing"; // 常量池中的对象
String d = str1 + str2; // 在堆上创建的新的对象
System.out.println(c == d);// false
public static String getStr() {
      return "ing";
}
```

> 参考资料：
>
> - [如何理解 String 类型值的不可变？ - 知乎提问](https://www.zhihu.com/question/20618891/answer/114125846)
> - [Java 内存区域详解](https://javaguide.cn/java/jvm/memory-area.html)
> - [深入解析String#intern - 美团技术团队 (meituan.com)](https://tech.meituan.com/2014/03/06/in-depth-understanding-string-intern.html)

## 泛型

### 1. 什么是泛型？有什么作用？

**Java 泛型（Generics）**是 JDK 5 中引入的一个新特性。使用泛型参数，可以增强代码的可读性以及稳定性。

编译器可以对泛型参数进行检测，并且通过泛型参数可以指定传入的对象类型。比如 `ArrayList<Persion> persons = new ArrayList<Persion>()` 这行代码就指明了该 `ArrayList` 对象只能传入 `Persion` 对象，如果传入其他类型的对象就会报错。

并且，原生 `List` 返回的类型是 `Object` ，需要手动转换类型才能使用，使用泛型后编译器自动转换。

### 2. 泛型的使用方式有哪几种？

泛型一般有三种使用方式：**泛型类**、**泛型接口**、**泛型方法**。

```java
// 1.泛型类
public class Generic<T> {
    private T key;

    public Generic(T key) {
        this.key = key;
    }

    public T getKey() {
        return key;
    }
}
// 实例化
Generic<Integer> genericInteger = new Generic<Integer>(123456);

// 2.泛型接口
public interface Generator<T> {
    public T method();
}
// 实现泛型接口，不指定类型
class GeneratorImpl<T> implements Generator<T> {
    @Override
    public T method() {
        return null;
    }
}
// 实现泛型接口，指定类型
class GeneratorImpl<T> implements Generator<String> {
    @Override
    public String method() {
        return "hello";
    }
}

// 3.泛型方法
public static <E> void printArray(E[] inputArray) {
    for (E element : inputArray) {
        System.out.printf("%s ", element);
    }
    System.out.println();
}
// 使用
Integer[] intArray = {1, 2, 3};
String[] stringArray = {"Hello", "World"};
printArray(intArray);
printArray(stringArray);
```

注意：`public static <E> void printArray(E[] inputArray)` 属于**静态泛型方法**，在 Java 中泛型只是一个占位符，必须在传递类型后才能使用。类在实例化时才能真正的传递类型参数，由于静态方法的加载先于类的实例化，也就是说类中的泛型还没有传递真正的类型参数，静态的方法的加载就已经完成了，所以静态泛型方法是没有办法使用类上声明的泛型的。只能使用自己声明的 `<E>`。

### 项目中哪里用到了泛型？

- 自定义接口通用返回结果 `CommonResult<T>` 通过参数 `T` 可根据具体的返回类型动态指定结果的数据类型。
- 构建集合工具类（参考 `Collections` 中的 `sort`、`binarySearch` 方法）。
- ......

## 集合

### 1. ArrayList 动态扩容机制？

#### 基本概念

`ArrayList` 的底层是数组队列，相当于动态数组。与 Java 中的数组相比，它的容量能动态增长。在添加大量元素前，应用程序可以使用 `ensureCapacity` 操作来增加 `ArrayList` 实例的容量。这可以减少递增式再分配的数量。

`ArrayList` 继承于 `AbstractList` ，实现了 `List`、`RandomAccess`、`Cloneable`、`java.io.Serializable` 这些接口。

- `RandomAccess` 是一个标志接口，表明实现这个这个接口的 List 集合是支持快速随机访问的。在 `ArrayList` 中，我们即可以通过元素的序号快速获取元素对象，这就是快速随机访问。
- `ArrayList` 实现了 `Cloneable` 接口 ，即覆盖了函数 `clone()`，能被克隆。
- `ArrayList` 实现了 `java.io.Serializable` 接口，这意味着 `ArrayList` 支持序列化，能通过序列化去传输。

#### 扩容机制

**以无参数构造方法创建 `ArrayList` 时，实际上初始化赋值的是一个空数组。当真正对数组进行添加元素操作时，才真正分配容量。即向数组中添加第一个元素时，数组容量扩为 10。**

`add` 方法首先调用了 `ensureCapacityInternal(size + 1)`，当加入第一个元素时，`minCapacity` 为 1，在 `Math.max()` 方法比较后，`minCapacity` 为 10。

如果调用 `ensureCapacityInternal()` 方法就一定会进入（执行） `ensureExplicitCapacity()` 方法。

- 当我们要 `add` 进第 1 个元素到 ArrayList 时，`elementData.length`（数组当前容量）为 0 （因为还是一个空的 list），因为执行了 `ensureCapacityInternal()` 方法 ，所以 minCapacity 此时为 10。此时，`minCapacity - elementData.length > 0` 成立，所以会进入 `grow(minCapacity)` 方法。
- 当 `add` 第 2 个元素时，`minCapacity` 为 2，此时 `elementData.length` 在添加第一个元素后扩容成 10 了。此时，`minCapacity - elementData.length > 0` 不成立，所以不会进入 （执行）`grow(minCapacity)` 方法。
- 添加第 3、4··· 到第 10 个元素时，依然不会执行 `grow` 方法，数组容量都为 10。直到添加第 11 个元素，`minCapacity`（为 11）比 `elementData.length`（为 10）要大。进入 grow 方法进行扩容。

`grow()` 方法：

- int newCapacity = oldCapacity + (oldCapacity >> 1)
- **所以 ArrayList 每次扩容之后容量都会变为原来的 1.5 倍左右（oldCapacity 为偶数就是 1.5 倍，否则是 1.5 倍左右）！**奇偶不同，比如 ：10 + 10/2 = 15, 33 + 33/2 = 49。如果是奇数的话会丢掉小数。

`hugeCapacity()` 方法：

- 如果新容量大于 `MAX_ARRAY_SIZE`，则会进入 `hugeCapacity()` 方法来比较 `minCapacity` 和 `MAX_ARRAY_SIZE`，如果 `minCapacity` 大于最大容量，则新容量则为 `Integer.MAX_VALUE`，否则，新容量大小则为 `MAX_ARRAY_SIZE` 即为 `Integer.MAX_VALUE - 8`。

#### 总结

- `minCapacity`：当前数组中的元素数量（size），即需要的最小容量。
- `elementData.length`：数组当前的容量。
- 当 `minCapacity` < `elementData.length` 时，可以直接往数组中添加元素；当 `minCapacity` > `elementData.length` 时，会发生扩容，容量扩大为原来的 1.5 倍。
- 如果新容量 > `MAX_ARRAY_SIZE`，则新容量变为 `Integer.MAX_VALUE`。

#### 补充

最好在向 `ArrayList` 添加大量元素之前用 `ensureCapacity` 方法，减少增量重新分配的次数，可以提升性能。不过，这个性能差距几乎可以忽略不计。而且，实际项目根本也不可能往 `ArrayList` 里面添加这么多元素。

## 异常

![Java 异常类层次结构图](%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0%20-%20%E7%94%B3%E6%9D%89%E6%9D%89.assets/types-of-exceptions-in-java.png)

### 1. Exception 和 Error 有什么区别？

在 Java 中，所有的异常都有一个共同的祖先 `java.lang` 包中的 `Throwable` 类。`Throwable` 类有两个重要的子类:

- **`Exception`**：程序本身可以处理的异常，可以通过 `catch` 来进行捕获。`Exception` 又可以分为 Checked Exception（受检查异常，必须处理）和 Unchecked Exception（不受检查异常，可以不处理）。
- **`Error`**：`Error` 属于程序无法处理的错误 ，不建议通过 `catch` 捕获 。例如 Java 虚拟机运行错误（`Virtual MachineError`）、虚拟机内存不够错误（`OutOfMemoryError`）、类定义错误（`NoClassDefFoundError`）等 。这些异常发生时，Java 虚拟机（JVM）一般会选择线程终止。

### 2. Checked Exception 和 Unchecked Exception 有什么区别？

**Checked Exception** 即“受检查异常” ，Java 代码在编译过程中，如果受检查异常没有被 `catch` 或者 `throws` 关键字处理的话，就没办法通过编译。

除了 `RuntimeException` 及其子类以外，其他的 `Exception` 类及其子类都属于受检查异常。常见的受检查异常有： IO 相关的异常、`ClassNotFoundException` 、`SQLException` ...。

**Unchecked Exception** 即“不受检查异常” ，Java 代码在编译过程中 ，我们即使不处理不受检查异常也可以正常通过编译。

`RuntimeException` 及其子类都统称为非受检查异常，常见的有（建议记下来，日常开发中会经常用到）：

- `NullPointerException`（空指针错误）
- `IllegalArgumentException`（参数错误比如方法入参类型错误）
- `NumberFormatException`（字符串转换为数字格式错误，`IllegalArgumentException` 的子类）
- `ArrayIndexOutOfBoundsException`（数组越界错误）
- `ClassCastException`（类型转换错误）
- `ArithmeticException`（算术错误）
- `SecurityException`（安全错误比如权限不够）
- `UnsupportedOperationException`（不支持的操作错误比如重复创建同一用户）
- ......

### 3. Throwable 类常用方法有哪些？

- `String getMessage()`：返回异常发生时的简要描述。
- `String toString()`：返回异常发生时的详细信息。
- `String getLocalizedMessage()`：返回异常对象的本地化信息。使用 `Throwable` 的子类覆盖这个方法，可以生成本地化信息。如果子类没有覆盖该方法，则该方法返回的信息与 `getMessage()` 返回的结果相同。
- `void printStackTrace()`：在控制台上打印 `Throwable` 对象封装的异常信息。

### 4. try-catch-finally 如何使用？

- `try`：用于捕获异常。其后可接零个或多个 `catch` 块，如果没有 `catch` 块，则必须跟一个 `finally` 块。
- `catch`：用于处理 try 捕获到的异常。
- `finally`：无论是否捕获或处理异常，`finally` 块里的语句都会被执行。当在 `try` 块或 `catch` 块中遇到 `return` 语句时，`finally` 语句块将在方法返回之前被执行。

**注意：不要在 finally 语句块中使用 return!** 

当 try 语句和 finally 语句中都有 return 语句时，try 语句块中的 return 语句会被忽略。这是因为 try 语句中的 return 返回值会先被暂存在一个本地变量中，当执行到 finally 语句中的 return 之后，这个本地变量的值就变为了 finally 语句中的 return 返回值。

### 5. finally 中的代码一定会执行吗？

不一定！在某些情况下，finally 中的代码不会被执行。

就比如说 finally 之前虚拟机被终止运行的话，finally 中的代码就不会被执行。

```java
try {
    System.out.println("Try to do something");
    throw new RuntimeException("RuntimeException");
} catch (Exception e) {
    System.out.println("Catch Exception -> " + e.getMessage());
    // 终止当前正在运行的Java虚拟机
    System.exit(1);
} finally {
    System.out.println("Finally");
}
```

另外，在以下两种特殊情况下，`finally` 中的代码也不会被执行：

- 程序所在的线程死亡
- 关闭 CPU

### 6. 如何使用 try-with-resources 代替 try-catch-finally？

- **适用范围（资源）**：任何实现 `java.lang.AutoCloseable` 或者 `java.io.Closeable` 的对象
- **关闭资源和 finally 块的执行顺序**：在 `try-with-resources` 语句中，任何 catch 或 finally 块在声明的资源关闭后运行。

面对必须要关闭的资源，我们总是应该优先使用 `try-with-resources` 而不是`try-finally`。随之产生的代码更简短，更清晰，产生的异常对我们也更有用。

Java 中类似于 `InputStream`、`OutputStream`、`Scanner`、`PrintWriter` 等的资源都需要我们调用 `close()` 方法来手动关闭，一般情况下我们都是通过 `try-catch-finally` 语句来实现这个需求，如下：

```java
// 读取文本文件的内容
Scanner scanner = null;
try {
    scanner = new Scanner(new File("D://read.txt"));
    while (scanner.hasNext()) {
        System.out.println(scanner.nextLine());
    }
} catch (FileNotFoundException e) {
    e.printStackTrace();
} finally {
    if (scanner != null) {
        scanner.close();
    }
}
```

使用 Java 7 之后的 `try-with-resources` 语句改造上面的代码：

```java
try (Scanner scanner = new Scanner(new File("test.txt"))) {
    while (scanner.hasNext()) {
        System.out.println(scanner.nextLine());
    }
} catch (FileNotFoundException fnfe) {
    fnfe.printStackTrace();
}
```

当多个资源需要关闭的时候，使用 `try-with-resources` 实现起来也非常简单，如果你还是用 `try-catch-finally` 可能会带来很多问题。通过使用分号分隔，可以在 `try-with-resources` 块中声明多个资源。

```java
try (BufferedInputStream bin = new BufferedInputStream(new FileInputStream(new File("test.txt")));
     BufferedOutputStream bout = new BufferedOutputStream(new FileOutputStream(new File("out.txt")))) {
    int b;
    while ((b = bin.read()) != -1) {
        bout.write(b);
    }
}
catch (IOException e) {
    e.printStackTrace();
}
```

### 7. 异常使用有哪些需要注意的地方？

- 不要把异常定义为静态变量，因为这样会导致异常栈信息错乱。每次手动抛出异常，我们都需要手动 new 一个异常对象抛出。
- 抛出的异常信息一定要有意义。
- 建议抛出更加具体的异常比如字符串转换为数字格式错误的时候应该抛出 `NumberFormatException` 而不是其父类 `IllegalArgumentException`。
- 使用日志打印异常之后就不要再抛出异常了（两者不要同时存在一段代码逻辑中）。
- ......

## 反射

### 1. 什么是反射？

如果说大家研究过框架的底层原理或者咱们自己写过框架的话，一定对反射这个概念不陌生。反射之所以被称为框架的灵魂，主要是因为它赋予了我们在运行时分析类以及执行类中方法的能力。通过反射你可以获取任意一个类的所有属性和方法，你还可以调用这些方法和属性。

### 2. 反射的优缺点？

反射可以让我们的代码更加灵活、为各种框架提供开箱即用的功能提供了便利。

不过，反射让我们在运行时有了分析操作类的能力的同时，也增加了安全问题，比如：可以无视泛型参数的安全检查（泛型参数的安全检查发生在编译时）、访问类的私有成员。另外，反射的性能也比较差，不过，对于框架来说实际是影响不大的。

### 3. 反射的应用场景？

#### 代理

像咱们平时大部分时候都是在写业务代码，很少会接触到直接使用反射机制的场景。但是！这并不代表反射没有用。相反，正是因为反射，你才能这么轻松地使用各种框架。像 Spring/Spring Boot、MyBatis 等等框架中都大量使用了反射机制。

这些框架中大量使用了动态代理，而动态代理的实现也依赖反射。

#### 注解

另外，像 Java 中的一大利器**“注解”**的实现也用到了反射。

为什么你使用 Spring 的时候 ，一个 `@Component` 注解就声明了一个类为 Spring Bean 呢？为什么你通过一个 `@Value` 注解就读取到配置文件中的值呢？究竟是怎么起作用的呢？

这些都是因为你可以基于反射分析类，然后获取到类/属性/方法/方法的参数上的注解。你获取到注解之后，就可以做进一步的处理。

`Annotation`（注解）是 Java 5 开始引入的新特性，可以看作是一种特殊的注释，主要用于修饰类、方法或者变量，提供某些信息供程序在编译或者运行时使用。

注解本质是一个继承了 `Annotation` 的特殊接口。JDK 提供了很多内置的注解（比如 `@Override` 、`@Deprecated`），我们也可以自定义注解。

注解只有被解析之后才会生效，常见的解析方法有两种：

- **编译期直接扫描**：编译器在编译 Java 代码的时候扫描对应的注解并处理，比如某个方法使用 `@Override` 注解，编译器在编译的时候就会检测当前的方法是否重写了父类对应的方法。
- **运行期通过反射处理**：像框架中自带的注解（比如 Spring 框架的 `@Value` 、`@Component`）都是通过反射来进行处理的。

> 参考资料：
>
> - [Java 反射机制详解 | JavaGuide](https://javaguide.cn/java/basis/reflection.html#何为反射)

## 代理

使用代理对象来代替对真实对象（real object）的访问，这样就可以在不修改原目标对象的前提下，提供额外的功能操作，扩展目标对象的功能。

代理模式的主要作用是扩展目标对象的功能，比如说在目标对象的某个方法执行前后你可以增加一些自定义的操作。

### 1. 静态代理？

**静态代理中，我们对目标对象的每个方法的增强都是手动完成的，非常不灵活（比如接口一旦新增加方法，目标对象和代理对象都要进行修改）且麻烦（需要对每个目标类都单独写一个代理类）。**

 实际应用场景非常非常少，日常开发几乎看不到使用静态代理的场景。

上面我们是从实现和应用角度来说的静态代理，从 JVM 层面来说， **静态代理在编译时就将接口、实现类、代理类这些都变成了一个个实际的 class 文件。**

静态代理实现步骤:

- 定义一个接口及其实现类；
- 创建一个代理类同样实现这个接口
- 将目标对象注入进代理类，然后在代理类的对应方法调用目标类中的对应方法。这样的话，我们就可以通过代理类屏蔽对目标对象的访问，并且可以在目标方法执行前后做一些自己想做的事情。

### 2. 动态代理？

相比于静态代理来说，动态代理更加灵活。我们不需要针对每个目标类都单独创建一个代理类，并且也不需要我们必须实现接口，我们可以直接代理实现类（CGLIB 动态代理机制：基于继承关系）。

**从 JVM 角度来说，动态代理是在运行时动态生成类字节码，并加载到 JVM 中的。**

动态代理在我们日常开发中使用的相对较少，但是在框架中（Spring AOP、RPC）几乎是必用的一门技术。学会了动态代理之后，对于我们理解和学习各种框架的原理也非常有帮助。

实现方式（Java）：

- JDK 动态代理（基于接口）
- CGLIB 动态代理（基于继承）

#### JDK 动态代理

使用步骤：

- 定义一个接口及其实现类。
- 自定义 `InvocationHandler` 并重写 `invoke` 方法，在 `invoke` 方法中我们会调用原生方法（被代理类的方法）并自定义一些处理逻辑。
- 通过 `Proxy.newProxyInstance(ClassLoader loader, Class<?>[] interfaces, InvocationHandler h)` 方法创建代理对象。

`Proxy` 类中使用频率最高的方法是：`newProxyInstance()` ，这个方法主要用来生成一个代理对象。

```java
public static Object newProxyInstance(ClassLoader loader, Class<?>[] interfaces, InvocationHandler h) throws IllegalArgumentException {
    // ...
}
```

`newProxyInstance()` 参数含义：

- **loader**：类加载器，用于加载代理对象。
- **interfaces**：被代理类实现的一些接口。
- **h**：实现了 `InvocationHandler` 接口的对象。

还必须实现 `InvocationHandler` 来自定义处理逻辑。当我们的动态代理对象调用一个方法时，这个方法的调用就会被转发到实现 `InvocationHandler` 接口类的 `invoke` 方法来调用。

```java
public interface InvocationHandler {
    // 当你使用代理对象调用方法的时候实际会调用到这个方法
    public Object invoke(Object proxy, Method method, Object[] args) throws Throwable;
}
```

`invoke()` 参数含义：

- **proxy**：动态生成的代理类。
- **method**：与代理类对象调用的方法相对应。
- **args**：当前 method 方法的参数。

总结：**通过 `Proxy` 类的 `newProxyInstance()` 创建的代理对象在调用方法的时候，实际会调用到实现 `InvocationHandler` 接口的类的 `invoke()` 方法。** 你可以在 `invoke()` 方法中自定义处理逻辑，比如在方法执行前后做什么事情。

示例：

```java
// 接口
public interface SmsService {
    String send(String message);
}

// 实现类（被代理对象）
public class SmsServiceImpl implements SmsService {
    public String send(String message) {
        System.out.println("send message:" + message);
        return message;
    }
}

// 动态代理类
public class DebugInvocationHandler implements InvocationHandler {
    // 代理类中的真实对象
    private final Object target;

    public DebugInvocationHandler(Object target) {
        this.target = target;
    }

    // 当我们的动态代理对象调用原生方法的时候，最终实际上调用到的是 invoke() 方法，然后 invoke() 方法代替我们去调用了被代理对象的原生方法
    public Object invoke(Object proxy, Method method, Object[] args) throws InvocationTargetException, IllegalAccessException {
        //调用方法之前，我们可以添加自己的操作
        System.out.println("before method " + method.getName());
        Object result = method.invoke(target, args);
        //调用方法之后，我们同样可以添加自己的操作
        System.out.println("after method " + method.getName());
        return result;
    }
}

// 获取代理对象的工厂类
public class JdkProxyFactory {
    public static Object getProxy(Object target) {
        return Proxy.newProxyInstance(
            // 目标类的类加载器
            target.getClass().getClassLoader(),
            // 代理需要实现的接口，可指定多个
            target.getClass().getInterfaces(), 
            // 代理对象对应的自定义 InvocationHandler
            new DebugInvocationHandler(target)   
        );
    }
}

// 创建代理对象
SmsService smsService = (SmsService) JdkProxyFactory.getProxy(new SmsServiceImpl());
// 代理对象调用原生方法 -> 实际调用的是增强后的方法
smsService.send("java");
```

#### CGLIB 动态代理

……

### 总结

#### JDK 动态代理和 CGLIB 动态代理对比

- **JDK 动态代理只能代理实现了接口的类或者直接代理接口，而 CGLIB 可以代理未实现任何接口的类。**
- CGLIB 动态代理是通过生成一个被代理类的子类来拦截被代理类的方法调用，因此不能代理声明为 final 类型的类和方法。
- 就二者的效率来说，大部分情况都是 Jdk 动态代理更优秀，随着 Jdk 版本的升级，这个优势更加明显。

#### 静态代理和动态代理的对比

- **灵活性**：动态代理更加灵活，不需要必须实现接口，可以直接代理实现类，并且可以不需要针对每个目标类都创建一个代理类。另外，静态代理中，接口一旦新增加方法，目标对象和代理对象都要进行修改，这是非常麻烦的！
- **JVM 层面**：静态代理在编译时就将接口、实现类、代理类这些都变成了一个个实际的 class 文件。而动态代理是在运行时动态生成类字节码，并加载到 JVM 中的。

> 参考资料：
>
> - [Java 代理模式详解 | JavaGuide](https://javaguide.cn/java/basis/proxy.html#_1-代理模式)

## IO

### 1. 什么是序列化?什么是反序列化?

如果我们需要持久化 Java 对象比如将 Java 对象保存在文件中，或者在网络传输 Java 对象，这些场景都需要用到序列化。

简单来说：

- **序列化**：将数据结构或对象转换成二进制字节流的过程。
- **反序列化**：将在序列化过程中所生成的二进制字节流转换成数据结构或者对象的过程。

**序列化的主要目的是通过网络传输对象或者说是将对象存储到文件系统、数据库、内存中。**

![img](%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0%20-%20%E7%94%B3%E6%9D%89%E6%9D%89.assets/a478c74d-2c48-40ae-9374-87aacf05188c.png)

### 2. 如果有些字段不想进行序列化怎么办？

对于不想进行序列化的变量，使用 `transient` 关键字修饰。

`transient` 关键字的作用是：阻止实例中被该关键字修饰的变量被序列化；当对象被反序列化时，被 `transient` 修饰的变量值不会被持久化和恢复。

关于 `transient` 还有几点注意：

- `transient` 只能修饰变量，不能修饰类和方法。
- `transient` 修饰的变量，在反序列化后变量值将会被置成类型的默认值。例如，如果是修饰 `int` 类型，那么反序列后结果就是 `0`。
- `static` 变量因为不属于任何对象（Object），所以无论有没有 `transient` 关键字修饰，均不会被序列化。

### 3. Java IO 流了解吗？

IO 即 `Input/Output`，输入和输出。数据输入到计算机内存的过程即输入，反之输出到外部存储（比如数据库、文件、远程主机）的过程即输出。数据传输过程类似于水流，因此称为 IO 流。IO 流在 Java 中分为输入流和输出流，而根据数据的处理方式又分为字节流和字符流。

Java IO 流的 40 多个类都是从如下 4 个抽象类基类中派生出来的。

- `InputStream`/`Reader`：所有的输入流的基类，前者是字节输入流，后者是字符输入流。
- `OutputStream`/`Writer`：所有输出流的基类，前者是字节输出流，后者是字符输出流。

> 参考资料：
>
> - [Java IO基础知识总结 | JavaGuide](https://javaguide.cn/java/io/io-basis.html#io-流简介)

### 4. I/O 流为什么要分为字节流和字符流呢?

该问题本质上是想问：不管是文件读写还是网络发送接收，信息的最小存储单元都是字节，那为什么 I/O 流操作要分为字节流操作和字符流操作呢？

主要有两点原因：

- 字符流是由 Java 虚拟机将字节转换得到的，这个过程是比较耗时的。
- 如果我们不知道编码类型的话，使用字节流的过程中很容易出现乱码问题。

字符流 = 字节流 + 编码表（Unicode、UTF-8）

### 5. Java IO 中的设计模式有哪些？

> 参考资料：
>
> - [Java IO设计模式总结 | JavaGuide](https://javaguide.cn/java/io/io-design-patterns.html#装饰器模式)

### 6. BIO、NIO 和 AIO 的区别？

#### 何为 I/O?

I/O（Input/Outpu）即输入／输出。

**从计算机结构的视角来看的话， I/O 描述了计算机系统与外部设备之间通信的过程。**

输入设备（比如键盘）和输出设备（比如显示器）都属于外部设备。网卡、硬盘这种既可以属于输入设备，也可以属于输出设备。输入设备向计算机输入数据，输出设备接收计算机输出的数据。

#### 用户态、内核态

为了保证操作系统的稳定性和安全性，一个进程的地址空间划分为**用户空间（User space）**和**内核空间（Kernel space）**。

像我们平常运行的应用程序都是运行在用户空间，只有内核空间才能进行系统态级别的资源有关的操作，比如**文件管理**、**进程通信**、**内存管理**等。也就是说，我们想要进行 IO 操作，就必须要依赖内核空间的能力。

用户空间的程序不能直接访问内核空间。当想要执行 IO 操作时，由于没有执行这些操作的权限，只能发起“**系统调用**”请求操作系统帮忙完成（间接访问内核空间）。

我们在平常开发过程中接触最多的就是**磁盘 IO（读写文件）**和**网络 IO（网络请求和响应）**。

从应用程序的视角来看，我们的应用程序对操作系统的内核发起 IO 调用（系统调用），操作系统负责的内核执行具体的 IO 操作。也就是说，我们的应用程序实际上只是发起了 IO 操作的调用而已，具体 IO 的执行是由操作系统的内核来完成的。

当应用程序发起 I/O 调用后，会经历两个步骤：

- 内核等待 I/O 设备准备好数据
- 内核将数据从内核空间拷贝到用户空间

#### IO 模型

UNIX 系统下， IO 模型一共有 5 种： **同步阻塞 I/O**、**同步非阻塞 I/O**、**I/O 多路复用**、**信号驱动 I/O** 和**异步 I/O**。

Java 中常见的 IO 模型：BIO、NIO、AIO。

##### BIO (Blocking I/O)

**BIO 属于同步阻塞 IO 模型** 。

同步阻塞 IO 模型中，应用程序发起 read 调用后，会一直阻塞，直到内核把数据拷贝到用户空间。

![图源：《深入拆解Tomcat & Jetty》](%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0%20-%20%E7%94%B3%E6%9D%89%E6%9D%89.assets/6a9e704af49b4380bb686f0c96d33b81tplv-k3u1fbpfcp-watermark.png)

在客户端连接数量不高的情况下，是没问题的。但是，当面对十万甚至百万级连接的时候，传统的 BIO 模型是无能为力的。因此，我们需要一种更高效的 I/O 处理模型来应对更高的并发量。

BIO 总结：

- 含义：每个线程对应每个连接（客户端）。
- 原理：
  - 服务器创建 socket，绑定并监听端口，每 accept 一个客户端连接，就抛出一个线程去进行 recv。
  - 单一线程不能处理多个客户端并发，accept 是阻塞式的，recv 也是阻塞式的，它们不能放到同一个线程中，否则只能同时接收一个客户端。
  - 每个 CPU 读取线程的栈是独立的，但是堆是共享的。
- 特点：阻塞。
- 缺点：会创建大量线程（线程间的调度会消耗大量的 CPU 资源）。

##### NIO (Non-blocking/New I/O)

Java 中的 NIO 于 Java 1.4 中引入，对应 `java.nio` 包，提供了 `Channel` , `Selector`，`Buffer` 等抽象。NIO 中的 N 可以理解为 Non-blocking，不单纯是 New。它是支持面向缓冲的，基于通道的 I/O 操作方法。 对于高负载、高并发的（网络）应用，应使用 NIO 。

![图源：《深入拆解Tomcat & Jetty》](%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0%20-%20%E7%94%B3%E6%9D%89%E6%9D%89.assets/bb174e22dbe04bb79fe3fc126aed0c61tplv-k3u1fbpfcp-watermark.png)

同步非阻塞 IO 模型中，应用程序会一直发起 read 调用，等待数据从内核空间拷贝到用户空间的这段时间里，线程依然是阻塞的，直到在内核把数据拷贝到用户空间。

相比于同步阻塞 IO 模型，同步非阻塞 IO 模型确实有了很大改进。通过轮询操作，避免了一直阻塞。

但是，这种 IO 模型同样存在问题：**应用程序不断进行 I/O 系统调用轮询数据是否已经准备好的过程是十分消耗 CPU 资源的。**

这个时候，**I/O 多路复用模型** 就上场了。

![img](%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0%20-%20%E7%94%B3%E6%9D%89%E6%9D%89.assets/88ff862764024c3b8567367df11df6abtplv-k3u1fbpfcp-watermark.png)

IO 多路复用模型中，线程首先发起 select 调用，询问内核数据是否准备就绪，等内核把数据准备好了，用户线程再发起 read 调用。read 调用的过程（数据从内核空间 -> 用户空间）还是阻塞的。

目前支持 IO 多路复用的系统调用，有 select，epoll 等。select 系统调用，目前几乎在所有的操作系统上都有支持。

- select 调用：内核提供的系统调用，它支持一次查询多个系统调用的可用状态。几乎所有的操作系统都支持。
- epoll 调用：linux 2.6 内核，属于 select 调用的增强版本，优化了 IO 的执行效率。

**IO 多路复用模型，通过减少无效的系统调用，减少了对 CPU 资源的消耗。**

Java 中的 NIO ，有一个非常重要的 **选择器 (Selector)** 的概念，也可以被称为 **多路复用器**。通过它，只需要一个线程便可以管理多个客户端连接。当客户端数据到了之后，才会为其服务。

![img](%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0%20-%20%E7%94%B3%E6%9D%89%E6%9D%89.assets/0f483f2437ce4ecdb180134270a00144tplv-k3u1fbpfcp-watermark.png)

NIO 总结：

- 含义：一个线程处理多个连接以及读写。
- 同步非阻塞模型：
  - 含义：轮询客户端连接是否有数据发来。
  - 原理：
    - 服务端用 open( ) 开启监听，接收客户端。
    - 绑定端口。
    - `configureBlocking(false)`：设置接收客户端的 accept 为非阻塞模式。在循环接收 client 的 accept 处，当没有客户端连接进来时，BIO 会一直卡着；而 NIO 会返回 -1，并继续往下执行
    - 判断 client 是否为 null，若有客户端连接进来（不为 null），则再将接收数据（recv）设置为非阻塞：`client.configureBlocking(false)`，并将该 client 添加进客户端列表。
    - 遍历已经连接进来的客户端能不能读写数据（read 时也不会阻塞），并根据返回结果做相应的处理。
  - 缺点：当并发比较大时，每次循环会有 O(n) 的系统调用，但可能只有一个 client 发来了数据，造成了资源的浪费。
  - 封装在 Netty 中，一般通过 Netty 使用，工作中一般不会直接写。
- 多路复用器：
  - 基本概念：
    - Channel：全双工通道，可以同时读写。
    - Selector：选择器，会不断的轮询，看哪里有客户端连上来。
  - 原理：将 Selector 注册（register）到对应的 Channel 上，并让其只关注 OP_ACCEPT 事件。

举例对比：

- BIO：派 4 个人，每人盯着一条路。
- NIO：派 1 个人，每一次循环都要看从第一条路到第四条路有没有来车，来回跑。
- 多路复用器：派 1 个人，每次先给收费站打个电话，看哪个路有来车，然后只用跑到有车来的那一路去（最后还是要由自己去发起读写的行为）。电话：select，poll。

##### AIO (Asynchronous I/O)

AIO 也就是 NIO 2。Java 7 中引入了 NIO 的改进版 NIO 2，它是**异步 IO 模型**。

异步 IO 是基于事件和回调机制实现的，也就是应用操作之后会直接返回，不会堵塞在那里，当后台处理完成，操作系统会通知相应的线程进行后续的操作。

![img](%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0%20-%20%E7%94%B3%E6%9D%89%E6%9D%89.assets/3077e72a1af049559e81d18205b56fd7tplv-k3u1fbpfcp-watermark.png)

目前来说 AIO 的应用还不是很广泛。Netty 之前也尝试使用过 AIO，不过又放弃了。这是因为，Netty 使用了 AIO 之后，在 Linux 系统上的性能并没有多少提升。

##### 总结

最后，来一张图，简单总结一下 Java 中的 BIO、NIO、AIO。

![img](%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0%20-%20%E7%94%B3%E6%9D%89%E6%9D%89.assets/33b193457c928ae02217480f994814b6.png)

> 参考资料：
>
> - [Java IO模型详解 | JavaGuide](https://javaguide.cn/java/io/io-model.html#前言)

## 多线程

### 1. 线程池使用？核心线程数怎么调整？

线程池的底层实现：ThreadPoolExecutor。（7 个参数）

常用线程池：

- SingleThreadPool
- CathedThreadPool
- FixedThreadPool

### 2. synchronized 和 volatile 的区别？实现原理？ABA 问题和解决方法？

volatile 主要应用在多个线程对实例变量更改的场合，刷新主内存共享变量的值从而使得各个线程可以获得最新的值，线程读取变量的值需要从主存中读取。

synchronized 则是锁定当前变量，只有当前线程可以访问该变量，其他线程被阻塞住。另外，synchronized 还会创建一个内存屏障，内存屏障指令保证了所有 CPU 操作结果都会直接刷到主存中（即释放锁前），从而保证了操作的内存可见性。

区别：

- synchronized 解决的是多个线程之间访问资源的同步性；而 volatile 主要用于解决变量在多个线程之间的可见性。
- synchronized 保证可见性、原子性；volatile 保证可见性、有序性。
- synchronized 可能会造成线程阻塞；volatile 更轻量级，性能更好，访问被 volatile 修饰的变量时不会上锁，因此不会造成线程阻塞。
- synchronized 可以作用于方法、代码块；volatile 只能作用于变量。
- synchronized 可以被编译器优化；volatile 禁止编译器优化，即禁止指令重排，保证有序性。

实现原理：

- synchronized：四种锁升级过程：无锁 -> 偏向锁 -> 自旋锁（轻量级锁）-> 重量级锁。
  - 自旋锁：采用 CAS 实现。
  - 重量级锁：底层加锁实现。
  - ABA 问题：
    - 普通数据类型不用管，只针对引用类型，别的线程多次修改后值不变。
    - 解决：通过时间戳、版本号标记来做区分。
- volatile：内存屏障。
  - volatile 读：loadload + loadstore
  - volatile 写：storestore + storeload

> 参考资料：
>
> - [JAVA并发编程（三）volatile与synchronized的实现原理及区别_wxcperfect的博客-CSDN博客](https://blog.csdn.net/Hello_mengkebao/article/details/119826436)
> - [volatile与synchronized实现原理 - 百度文库 (baidu.com)](https://wenku.baidu.com/view/30657c4c551252d380eb6294dd88d0d233d43ce2.html)

### 3. Java 线程池参数、作用？参数如何配置？

ThreadPoolExecutor 的 7 个参数：

- 核心线程数
- 最大线程数
- 存活时间（空闲的非核心线程的最大存活时间，核心线程不会死亡）
- 存活时间的单位
- 任务队列
- 线程工厂
- 拒绝策略

### 4. synchronized 和 ReentrantLock 的区别？

#### 相同点

两者都是可重入锁。

**「可重入锁」**指的是自己可以再次获取自己的内部锁。比如一个线程获得了某个对象的锁，此时这个对象锁还没有释放，当其再次想要获取这个对象的锁的时候还是可以获取的，如果是不可重入锁的话，就会造成死锁。同一个线程每次获取锁，锁的计数器都自增 1，所以要等到锁的计数器下降为 0 时才能释放锁。

#### synchronized

- 自动实现加锁和解锁。
- `synchronized` 是依赖于 JVM 实现的，JDK 6 以后出现的四种锁升级都属于虚拟机层面，并没有直接暴露给我们。

#### ReentrantLock

- 需要手动加锁和解锁。
- `ReentrantLock` 是 JDK 层面实现的（也就是 API 层面，需要 `lock()` 和 `unlock()` 方法配合 `try`/`finally` 语句块来完成），所以我们可以通过查看它的源代码，来看它是如何实现的。
- 相比 `synchronized`，`ReentrantLock` 增加了一些高级功能：
  - **等待可中断**：`ReentrantLock` 提供了一种能够中断等待锁的线程的机制，通过 `lock.lockInterruptibly()` 来实现这个机制。也就是说正在等待的线程可以选择放弃等待，改为处理其他事情。
  - **可实现公平锁**：`ReentrantLock` 可以指定是公平锁还是非公平锁。而 `synchronized` 只能是非公平锁。所谓的**「公平锁」**就是先等待的线程先获得锁。`ReentrantLock` 默认情况是非公平的，可以通过 `ReentrantLock` 类的 `ReentrantLock(boolean fair)` 构造方法来制定是否是公平的。
  - **可实现选择性通知（锁可以绑定多个条件）**：`synchronized` 关键字与 `wait()` 和 `notify()`/`notifyAll()` 方法相结合可以实现等待/通知机制。`ReentrantLock` 类当然也可以实现，但是需要借助于 `Condition` 接口与 `newCondition()` 方法。


#### 补充

一个锁对象可以有一个或多个相关联的条件对象，可以用 `锁对象.newCondition()` 获得一个条件对象。

- `condition.await()`：当前线程暂停，并放弃锁。一旦一个线程调用了 `await()` 方法，它就进入了这个条件的等待集（wait set）。当锁可用时，该线程并不会变为可运行状态，而是仍保持非活动状态，直到另一个线程在同一条件（condition 对象）上调用 `signal()`/`signalAll()` 方法。
- `condition.signalAll()`：会重新激活等待这个条件的所有线程。它不会立即激活一个等待的线程，它只是解除等待线程的阻塞，使这些线程可以在当前线程释放锁之后竞争访问对象。
- `condition.signal()`：随机选择等待集中的一个线程，并解除这个线程的阻塞状态。更高效，但是可能会造成死锁。

`Condition` 是 JDK 1.5 之后才有的，它具有很好的灵活性，比如可以实现多路通知功能也就是在一个 `Lock` 对象中可以创建多个 `Condition` 实例（即对象监视器），**线程对象可以注册在指定的 `Condition` 中，从而可以有选择性的进行线程通知，在调度线程上更加灵活。在使用 `notify()/notifyAll()` 方法进行通知时，被通知的线程是由 JVM 选择的，用 `ReentrantLock` 类结合 `Condition` 实例可以实现「选择性通知」**，这个功能非常重要，而且是 Condition 接口默认提供的。

而 `synchronized` 关键字就相当于整个 Lock 对象中只有一个 `Condition` 实例，所有的线程都注册在它一个身上。如果执行 `notifyAll()` 方法的话就会通知所有处于等待状态的线程这样会造成很大的效率问题，而 `Condition` 实例的 `signalAll()` 方法 只会唤醒注册在该 `Condition` 实例中的所有等待线程。

> 参考资料：
>
> - 《Java 核心技术卷一》 572 页

### 5. 说一下 synchronized 的原理？

#### 同步代码块

synchronized 关键字的底层原理属于 JVM 层面。

```java
public class SynchronizedDemo {
    public void method() {
        synchronized (this) {
            System.out.println("synchronized 代码块");
        }
    }
}
```

**`synchronized` 同步语句块的实现使用的是 `monitorenter` 和 `monitorexit` 指令，其中 `monitorenter` 指令指向同步代码块的开始位置，`monitorexit` 指令则指明同步代码块的结束位置。**

当执行 `monitorenter` 指令时，线程试图获取锁也就是获取**对象监视器 `monitor`** 的持有权。

> 在 Java 虚拟机(HotSpot)中，Monitor 是基于 C++实现的，由 [ObjectMonitor](https://github.com/openjdk-mirror/jdk7u-hotspot/blob/50bdefc3afe944ca74c3093e7448d6b889cd20d1/src/share/vm/runtime/objectMonitor.cpp) 实现。每个对象中都内置了一个 `ObjectMonitor`对象。
>
> 另外，`wait/notify` 等方法也依赖于 `monitor` 对象，这就是为什么只有在同步的块或者方法中才能调用 `wait/notify` 等方法，否则会抛出 `java.lang.IllegalMonitorStateException` 的异常的原因。

在执行 `monitorenter` 时，会尝试获取对象的锁，如果锁的计数器为 0 则表示锁可以被获取，获取后将锁计数器设为 1 也就是加 1。

对象锁的的拥有者线程才可以执行 `monitorexit` 指令来释放锁。在执行 `monitorexit` 指令后，将锁计数器设为 0，表明锁被释放，其他线程可以尝试获取锁。

如果获取对象锁失败，那当前线程就要阻塞等待，直到锁被另外一个线程释放为止。

#### 同步方法

```java
public class SynchronizedDemo2 {
    public synchronized void method() {
        System.out.println("synchronized 方法");
    }
}
```

`synchronized` 修饰的方法并没有 `monitorenter` 指令和 `monitorexit` 指令，取而代之的是 `ACC_SYNCHRONIZED` 标识，该标识指明了该方法是一个同步方法。JVM 通过该 `ACC_SYNCHRONIZED` 访问标志来辨别一个方法是否声明为同步方法，从而执行相应的同步调用。

如果是实例方法，JVM 会尝试获取实例对象的锁。如果是静态方法，JVM 会尝试获取当前 class 的锁。

**同步代码块和同步方法的本质都是对「对象监视器」的获取。**

#### 锁升级

JDK 1.6 对锁的实现引入了大量的优化，如偏向锁、轻量级锁、自旋锁、适应性自旋锁、锁消除、锁粗化等技术来减少锁操作的开销。

锁主要存在四种状态，依次是：无锁状态、偏向锁状态、轻量级锁状态、重量级锁状态，他们会随着竞争的激烈而逐渐升级。注意锁可以升级不可降级，这种策略是为了提高获得锁和释放锁的效率。

锁升级过程：

- 给普通对象（无锁）加上 synchronized 后，会升级为偏向锁。
- 偏向锁如果存在轻度竞争，则会升级为轻量级锁（自旋锁）。
- 竞争加剧后，轻量级锁会升级为重量级锁（需要向 OS 申请）。
  - 竞争加剧：有线程超过 10 次自旋（可通过参数 PreBlockSpin 控制），或自旋线程数超过 CPU 核数的一半。
  - 为什么需要升级：自旋是需要消耗 CPU 的，如果锁的时间长，或者自旋线程多，CPU 会被大量消耗。
  - 升级为重量级锁后，将等待的线程加入到 waitSet 队列中，这些线程不再消耗 CPU 的资源。

![Image](E:\编程学习\学习笔记\面试笔记\img\Image-16576293263879.png)

Hotspot 的实现（markword）：

![Image](E:\编程学习\学习笔记\面试笔记\img\Image-165762934067810.png)

用户态的锁：

- 偏向锁：
  - 含义：在多数情况下，被 synchronized 包含的代码段实际只有一个线程在运行，因此不需要设计锁竞争机制，直接偏向这一个线程即可。
  - 需要将当前线程的指针（代表线程 ID）加到锁对象的 markword 中。
- 自旋锁（轻量级锁）：
  - 需要先撤销偏向锁。
  - 多个线程在自己的线程栈中生成 LR（LockRecord：锁记录）。
  - 不同线程间以自旋的方式竞争，将自己的 LR 指针赋给锁后，代表争抢到了锁。
  - 没有竞争到锁的线程以自旋的方式一直在用户空间等待，不断去查看当前上锁的线程是否解锁，然后自己再去加这把锁。

偏向锁是否一定比自旋锁效率高？（不一定）

- 在明确知道会有多线程竞争的情况下，偏向锁肯定会涉及锁的撤销，这时候应直接使用自旋锁。
- 在 JVM 的启动过程中，会有很多线程竞争（明确），所以默认情况启动时不打开偏向锁，过一段儿时间再打开。

什么时候使用轻/重量级锁？

- 执行时间短（加锁代码），线程数少，用自旋锁（轻量级锁）。
- 执行时间长（加锁代码），线程数多，用系统锁（重量级锁）。

锁重入：

- 含义：对某个方法上锁后，被该方法调用的方法也上了同一个锁（即：同一个锁被上了两次）。
- synchronized 是可重入锁。
- 重入次数必须记录，因为要解锁几次必须得对应。

> 参考资料：
>
> - [Java锁与线程的那些事 (youzan.com)](https://tech.youzan.com/javasuo-yu-xian-cheng-de-na-xie-shi/)
> - [Java6及以上版本对synchronized的优化 - 蜗牛大师 - 博客园 (cnblogs.com)](https://www.cnblogs.com/wuqinglong/p/9945618.html)

### 6. 线程池的原理？为什么要创建线程池？创建线程池的方式？

#### 实现原理

- 在 HotSpot VM 的模型中，Java 线程被一对一映射为本地操作系统线程。Java 线程启动时会创建一个本地操作系统线程，当 Java 线程终止时，对应的操作系统线程也被销毁回收，而操作系统会调度所有线程并将它们分配给可用的 CPU。
- 在 Executor 框架中，将工作单元与执行机制分离开来。
  - Runnable 和 Callable 是工作单元（也就是俗称的任务）。
  - 而执行机制由 Executor 来提供。
  - 这样一来 Executor 是基于生产者消费者模式的，提交任务的操作相当于生产者，执行任务的线程相当于消费者。

#### 执行原理

- 提交一个任务到线程池。
- 判断核心线程是否都在工作，如果核心线程还有空闲，则交由核心线程来执行该任务。
- 判断任务队列是否已满，若队列还有空闲，则将任务加入队列。
- 判断最大线程数是否已满，若还未满，则创建一个新的线程（非核心）来执行该任务。
- 若最大线程数也满了，执行拒绝策略。
  - AbortPolicy：直接抛出异常（默认）。
  - CallerRunsPolicy：只用调用所在的线程运行任务。
  - DiscardOldestPolicy：丢弃队列里最近的一个任务，并执行当前任务。
  - DiscardPolicy：不处理，丢弃掉。

#### 使用原因

- **降低资源消耗**：通过重复利用已创建的线程降低线程创建和销毁造成的消耗。
- **提高响应速度**：当任务到达时，任务可以不需要等到线程创建就能立即执行。
- **提高线程的可管理性**：线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。

#### 继承体系

Executor 接口 -> ExecutorService 接口 -> 两个实现类：ThreadPoolExecutor、ScheduledThreadPoolExecutor。

- ThreadPoolExecutor 是线程池的核心实现类，用来执行被提交的任务。
- ScheduledThreadPoolExecutor 可以在给定的延迟后运行任务，或者定期执行命令。

ForkJoinPool：

![Image](E:\编程学习\学习笔记\面试笔记\img\Image-165762976471311.png)

创建方式：

- 使用 ThreadPoolExecutor 来通过给定不同的参数从而创建自己所需的线程池（不推荐）。
- 使用 Exectuors 工厂方法来创建线程池（实际工作中常用）。

Executors 可以创建 3 种类型的 ThreadPoolExecutor：

SingleThreadExecutor：

- 单线程线程池
- 也是通过 ThreadPoolExecutor 创建，里面的核心线程数和线程数都是 1，并且工作队列使用的是无界队列。
- 由于是单线程工作，每次只能处理一个任务，所以后面所有的任务都被阻塞在工作队列中，只能一个个任务执行。

```java
ExecutorService threadPool = Executors.newSingleThreadExecutor();

public static ExecutorService newSingleThreadExecutor() {
	return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue<Runnable>()));
}
```

FixedThreadPool：

- 固定大小线程池
- 与单线程线程池类似

```java
ExecutorService threadPool = Executors.newFixedThreadPool(5);

public static ExecutorService newFixedThreadPool(int nThreads) {
	return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue<Runnable>());
}
```

CachedThreadPool：

- 无界线程池（缓存线程池）
- 没有工作队列，任务进来就执行，线程数量不够就创建，与前面两个的区别是：空闲的线程会被回收掉，空闲的时间是60s。
- 适用于执行很多短期异步的小程序或者负载较轻的服务器。

```java
ExecutorService threadPool = Executors.newCachedThreadPool();

public static ExecutorService newCachedThreadPool() { 		return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue<Runnable>());
}
```

> 参考资料：
>
> - [JAVA线程池原理详解一 - 冬瓜蔡 - 博客园 (cnblogs.com)](https://www.cnblogs.com/dongguacai/p/6030187.html)
> - [JAVA线程池原理详解二 - 冬瓜蔡 - 博客园 (cnblogs.com)](https://www.cnblogs.com/dongguacai/p/6038960.html)

### 7. 线程的生命周期？什么时候会出现僵死进程？

### 8. 什么是线程安全？如何实现线程安全？

多线程内存模型：

- Java 的内存模型中有主内存和线程的工作内存之分。
- 主内存上存放的是线程共享的变量（实例字段，静态字段和构成数组的元素）。
- 线程的工作内存是线程私有的空间，存放的是线程私有的变量（方法参数与局部变量）。
- 线程在工作的时候如果要操作主内存上的共享变量，为了获得更好的执行性能并不是直接去修改主内存而是会在线程私有的工作内存中创建一份变量的拷贝（缓存），在工作内存上对变量的拷贝修改之后再把修改的值刷回到主内存的变量中去。

![Image](E:\编程学习\学习笔记\面试笔记\img\Image-165763899459012.png)

线程安全：

- 如果有多个线程同时操纵主内存中的共享变量，就可能会出现多线程的安全问题。
- 线程安全：多线程执行过程中不会产生共享资源的冲突。

实现方式：

- 互斥同步锁（悲观锁）：
  - 阻塞没有获得锁的线程。
  - 操作系统提供了很多互斥机制来控制在某一个时刻只能有一个或者一组线程访问同一个资源，比如：
    - 信号量
    - 互斥量
    - 临界区资源（synchronized、reentrantlock）
  - 互斥同步锁都是可重入锁，好处是可以保证不会死锁。但是因为涉及到核心态和用户态的切换，因此比较消耗性能。
- 非阻塞同步锁（乐观锁）：
  - CAS（Compare And Swap）：先进行资源在工作内存中的更新，然后根据与主存中旧值的对比来确定在此期间是否有其他线程对共享资源进行了更新，如果旧值与期望值相同，就认为没有更新，可以把新值写回内存，否则就一直重试直到成功。
- 不同步：
  - ThreadLocal / Volatile：线程本地的变量，每个线程获取一份共享变量的拷贝，单独进行处理。

> 参考资料：
>
> - [Java 多线程安全机制_JackieeeCheng的博客-CSDN博客](https://blog.csdn.net/jackieeecheng/article/details/69779824)

### 9. 如何合理配置线程池的大小？

根据任务类型分类：

- CPU 密集型：
  - 尽量使用较小的线程池，一般为 CPU 核数 + 1。
  - 对于 CPU 密集型任务，CPU 的使用率很高，若开过多的线程，只能增加线程上下文的切换次数，带来额外的开销。
- IO 密集型：
  - 可以使用较大的线程池，一般为 CPU 核数 * 2。
  - 对于 IO 密集型任务，CPU 使用率不高，可以让 CPU 等待 IO 的时候处理别的任务，充分利用 CPU 时间。

> 参考资料：
>
> - [java线程池如何合理的设置大小 - 提拉没有米苏 - 博客园 (cnblogs.com)](https://www.cnblogs.com/cherish010/p/8334952.html)

### 10. volatile 和 ThreadLocal 的使用场景和原理？

#### volatile

保证可见性、有序性。

原理：

- 可见性：线程每一次使用被 volatile 修饰的变量时，都需要去内存中重新读取一遍该变量的值。
- 有序性：volatile 变量进行写操作时，JVM 会向处理器发送一条 Lock 前缀的指令（相当于一个内存屏障），并将这个变量所在缓存行的数据写到系统内存。

![Image](E:\编程学习\学习笔记\面试笔记\img\Image-165763963037013.png)

使用场景：

- 布尔类型状态标记。
- DCL 单例问题：对象引用在没有同步的情况下进行读操作，可能会看到一个更新的引用，但是仍然会通过该引用看到不完全构造的对象。如果不用 volatile（保证有序性），则因为内存模型允许所谓的“无序写入”，某个线程可能会获得一个未完全初始化的实例。
- 观察变量、统计信息等。

DCL 单例代码：

```Java
// 注意 volatile！！！！！！！！！！！！！！！！！    
private volatile static Singleton instace;     
    
public static Singleton getInstance() {     
    // 第一次null检查       
    if(instance == null) {              
        synchronized(Singleton.class) {           
            // 第二次null检查         
            if(instance == null) {              
                instance = new Singleton();   
            }    
        }             
    }    
    return instance;
}
```

#### threadlocal

原理：

ThreadLocal 提供一个线程局部（私有）变量，访问到某个变量的每一个线程都拥有自己的局部变量。这种变量在线程的生命周期内起作用，减少同一个线程内多个函数或者组件之间一些公共变量的传递的复杂度。

当使用 ThreadLocal 维护变量时，ThreadLocal 为每个使用该变量的线程提供独立的变量副本，所以每一个线程都可以独立地改变自己的副本，而不会影响其它线程所对应的副本，从而隔离了线程和线程，避免了线程访问实例变量发生安全问题。

Thread 中的 threadLocals 就是 ThreadLocal 中的 ThreadLocalMap：

![Image](E:\编程学习\学习笔记\面试笔记\img\Image-165763986984214.png)

一个 Thread 可以依附有多个 ThreadLocal 对象：

![Image](E:\编程学习\学习笔记\面试笔记\img\Image-165763992479115.png)

示例：

![Image](E:\编程学习\学习笔记\面试笔记\img\Image-165764006640116.png)

可能会存在的问题：

- 共享变量的并发问题：
  - ThreadLocal 是用来维护本线程的变量的，并不能解决共享变量的并发问题。
  - ThreadLocal 让访问某个变量的线程都拥有自己的局部变量，但是如果这个局部变量都指向同一个对象呢？这个时候 ThreadLocal 就失效了（并没有达到线程隔离的效果）。
  - ThreadLocal 是各线程将值存入该线程的 map 中，以 ThreadLocal 自身作为 key，value 为线程的私有对象，需要用时获得的是该线程之前存入的值。如果存入的是共享变量，那取出的也是共享变量，并发问题还是存在的。
- 内存泄露问题：
  - threadLocal 的 map 中的 key 指向 threadlocal 变量的引用为弱引用。
  - 如果把 stack 中的 ThreadLocal 的引用置为 null，那么意味着 Heap 中的 ThreadLocal 实例不再有强引用指向，只有弱引用存在，因此 GC 是可以回收这部分空间的，也就是 key 是可以回收的。
  - 但是 value 却存在一条从 Current Thread 过来的强引用链。因此只有当 Current Thread 销毁时，value 才能得到释放。因此，只要这个线程对象被 gc 回收，就不会出现内存泄露，但在 threadLocal 设为 null 和线程结束这段时间内，value 是不会被回收的，这就发生了我们认为的内存泄露。更可怕的是线程对象不被回收的情况，比如使用线程池的时候，线程结束后不会被销毁，这也会导致内存泄露。
  - 解决：在 ThreadLocalMap 中的 set/getEntry 方法中，会对 key 为 null 进行判断，如果为 null 的话，则会将 value 置为 null。我们也可以通过调用 ThreadLocal 的 remove 方法进行释放。

![Image](E:\编程学习\学习笔记\面试笔记\img\Image-165764046831217.png)

使用场景：

- 数据库连接
- Session 管理

> 参考资料：
>
> - [volatile的使用场景_hgc0907的博客-CSDN博客](https://blog.csdn.net/hgc0907/article/details/79664102)
> - [对ThreadLocal实现原理的一点思考 - 简书 (jianshu.com)](https://www.jianshu.com/p/ee8c9dccc953)

### 11. ThreadLocal 什么时候会出现 OOM 的情况？为什么？

ThreadLocal 变量是维护在 Thread 内部的，这样的话只要我们的线程不退出，对象的引用就会一直存在。当线程退出时，Thread 类会进行一些清理工作，其中就包含 ThreadLocalMap。

ThreadLocal 在没有线程池使用的情况下，正常情况下不会存在内存泄露，但是如果使用了线程池的话，就依赖于线程池的实现，如果线程池不销毁线程的话，那么就会存在内存泄露。

当我们使用线程池的时候，就意味着当前线程未必会退出（比如固定大小的线程池，线程总是存在的）。如果这样的话，将一些很大的对象设置到 ThreadLocal 中（这个很大的对象实际保存在 Thread 的 threadLocals 属性中），这样的话就可能会出现内存溢出的情况。

> 参考资料：
>
> - [Java多线程编程-（8）-多图深入分析ThreadLocal原理_徐刘根的博客-CSDN博客_threadlocal传递到子线程](https://blog.csdn.net/xlgen157387/article/details/78297568)

### 12. synchronized 锁粒度？模拟死锁场景？

对象锁：

- synchronized(this)，或在方法上加 synchronized。
- 创建同一个类的不同对象来调用加了对象锁的方法，不会造成阻塞。

类锁：

- synchronized(Xxx.class)，或在静态方法上加 synchronized。
- 创建同一个类的不同对象来调用加了类锁的方法，会发生阻塞，不能同时执行。

死锁举例：

- 准备两个类 A、B，每个类分别有一个加了类锁的方法 test1、test2，其中 test1 最后会调用 test2，test2 最后会调用 test1（即相互调用）。
- 使用线程 1 执行 A.test1()，用线程 2 执行 B.test2()，最后两个线程会互相等待对方释放类锁，即发生了死锁。

> 参考资料：
>
> - [三大性质总结：原子性，有序性，可见性 - 简书 (jianshu.com)](https://www.jianshu.com/p/cf57726e77f2)
> - [基于synchronized的对象锁，类锁以及死锁模拟_nc-sf的博客-CSDN博客](https://blog.csdn.net/u013925989/article/details/50208839)

### 13. 一个线程对象只能调用一次 start() 方法吗？通过 start() 方法调用 run() 是异步执行的吗？

只能调用一次 start() 方法：

- Java 的线程是不允许启动两次的，第二次调用必然会抛岀 IllegalThreadStateEXception，这是一种运行时异常，多次调用 start 被认为是编程错误。
- 在第二次调用 start() 方法的时候，线程可能处于终止或者其他（非 NEW）状态，但是不论如何，都是不可以再次启动的。
- 如果一个线程的 run() 方法执行结束或者调用 stop() 方法后，该线程就会死亡。对于已经死亡的线程，无法再使用 start() 方法令其进入就绪。

是异步调用：

- start() 方法用于启动一个线程，真正实现了多线程运行。
- 这时无需等待 run() 方法体代码执行完毕，可以直接继续执行下面的代码。

### 14. Java 线程中 start() 和 run() 的区别？

调用 start() 后，线程会被放到等待队列，等待 CPU 调度，并不一定要马上开始执行，只是将这个线程置于可动行状态。然后通过 JVM，线程 Thread 会调用 run() 方法，执行本线程的线程体。

#### start()

- start() 的作用是启动一个新线程。
- 当用 start() 开始一个线程后，线程就进入就绪状态，使线程所代表的虚拟处理机处于可运行状态，这意味着它可以由 JVM 调度并执行。但是这并不意味着线程就会立即运行。只有当 cpu 分配时间片，这个线程获得时间片时，才开始执行 run() 方法。
- start() 不能被重复调用，它调用 run() 方法，run() 方法是你必须重写的方法。

#### run()

- run() 就和普通的成员方法一样，可以被重复调用。
- 如果直接调用 run() 方法，并不会启动新线程，程序中依然只有主线程这一个线程，其程序执行路径还是只有一条，还是要顺序执行，还是要等待 run() 方法体执行完毕后才可继续执行下面的代码，这样就没有达到多线程的目的。
- 调用 start() 方法方可启动线程，而 run() 方法只是 thread 的一个普通方法调用，还是在主线程里执行。

> 参考资料：
>
> - [java线程中start和run的区别详解_java_脚本之家 (jb51.net)](https://www.jb51.net/article/171518.htm)
> - [Java线程——run()与start()的区别_冷冷~~的博客-CSDN博客_java线程 直接调用start和run的区别](https://blog.csdn.net/sinat_39634657/article/details/81449122)

### 15. Runnable 接口和 Callable 接口的区别？

`Runnable` 接口不会返回结果或抛出检查异常，但是 `Callable` 接口可以。所以，如果任务不需要返回结果或抛出异常推荐使用 `Runnable` 接口 ，这样代码看起来会更加简洁。

```java
@FunctionalInterface
public interface Runnable {
   /**
    * 被线程执行，没有返回值也无法抛出异常
    */
    public abstract void run();
}

@FunctionalInterface
public interface Callable<V> {
    /**
     * 计算结果，或在无法这样做时抛出异常。
     * @return 计算得出的结果
     * @throws 如果无法计算结果，则抛出异常
     */
    V call() throws Exception;
}
```

### 16. Thread、Runnable、Callable、Future 的关系？

#### Thread 和 Runnable

我们先看一下 Thread 最简单的使用姿势：

```java
public class MyThread extends Thread {
    public MyThread(String name) {
        super(name);
    }
    @Override
    public void run() {
        String name = Thread.currentThread().getName();
        System.out.println(name + "已经运行");

    }
    public static void main(String[] args) {
        new MyThread("线程一").start();
    }
}
```

线程包含 4 个状态：创建 -> 就绪 -> 运行 -> 结束。

当执行 start() 后，线程进入就绪状态，当对应的线程抢占到 cpu 调度资源之后，进入运行状态，此时调用的是 run 方法，执行完毕之后就结束了。

我们看一下 Runnable 最简单的使用姿势：

```java
public class MyTask implements Runnable {
    @Override
    public void run() {
        String name = Thread.currentThread().getName();
        System.out.println(name + "已经运行");
    }
    public static void main(String[] args) {
        new Thread(new MyTask(),"线程二").start();
    }
}
```

这里 MyTask 就是一个 Runnable，实现了 run() 方法，作为 Thread() 的入参。

Thread 和 Runnable 的关系：

- 如果一个对象实现了 Runnable 接口并重写了 run() 方法，那么当线程 start() 后，会在该线程中单独执行该对象的 run() 方法。
- Thread 中 run() 方法的内部实现，其实是 MyTask 的 run() 方法。

源码分析：

- 在 Thread 初始化时，MyTask 作为入参 target，最后赋值给 Thread.target。
- 当执行 Thread.run() 时，其实是执行的 target.run()，即 MyTask.run()，这个是典型的策略模式。

![image-20220729214857195](%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0%20-%20%E7%94%B3%E6%9D%89%E6%9D%89.assets/image-20220729214857195.png)

#### Callable、Future 和 FutureTask

关系图谱：

![image-20220729215124845](%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0%20-%20%E7%94%B3%E6%9D%89%E6%9D%89.assets/image-20220729215124845.png)

对于 Thread 和 Runable，其 run() 都是无返回值的，并且无法抛出异常，所以当你需要返回多线程的数据，就需要借助 Callable 和 Future。

Callable：

- Callable 是一个接口，里面有个 V call() 方法，这个 V 就是我们的返回值类型。
- 我们一般会用匿名类的方式使用 Callable，call() 中是具体的业务逻辑。

FutureTask：

- FutureTask 继承了 RunnableFuture，RunnableFuture 继承了 Runnable 和 Future，所以 FutureTask 也是个 Runnable 。
- 既然 FutureTask 是个 Runnable，肯定就需要实现 FutureTask.run() 方法，那么 FutureTask 也可以作为 Thread 的初始化入参。
- 所以当执行 Thread.run() 时，其实是执行的 FutureTask.run()。

Callable 和 FutureTask 的关系：

- FutureTask 初始化时，Callable 必须作为 FutureTask 的初始化入参。![image-20220729220250721](%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0%20-%20%E7%94%B3%E6%9D%89%E6%9D%89.assets/image-20220729220250721.png)
- 当执行 FutureTask.run() 时，其实执行的是 Callable.call()。![image-20220729220322050](%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0%20-%20%E7%94%B3%E6%9D%89%E6%9D%89.assets/image-20220729220322050.png)

#### 总结

- Thread.run() 执行的是 Runnable.run()。
- FutureTask 实现了 Runnable 接口，并实现了 FutureTask.run()，FutureTask.run() 实际执行的是 Callable.run()。
- 因此，依次传递，最后 Thread.run() 其实执行的是 Callable.run()。

所以整个设计方法，其实就是 2 个策略模式：

- Thread 和 Runnable 是一个策略模式。
- FutureTask 和 Callable 是一个策略模式。

最后通过 Runnable 和 FutureTask 的继承关系，将这 2 个策略模式组合在一起。

#### Future

为什么要有 Future 呢？

我们通过 FutureTask，借助 Thread 执行线程后，结果数据我们怎么获取到呢？这里就需要借助到 Future。

Future 接口：

```java
public interface Future<V> {
    // 取消任务，如果任务正在运行，mayInterruptIfRunning为true时，表明这个任务会被打断的，并返回true；为false时，会等待这个任务执行完，返回true；若任务还没执行，取消任务后返回true，如任务执行完，返回false
    boolean cancel(boolean mayInterruptIfRunning);
    // 判断任务是否被取消了,正常执行完不算被取消
    boolean isCancelled();
    // 判断任务是否已经执行完成，任务取消或发生异常也算是完成，返回true
    boolean isDone();
    // 获取任务返回结果，如果任务没有执行完成则等待完成将结果返回，如果获取的过程中发生异常就抛出异常，
    // 比如中断就会抛出InterruptedException异常等异常
    V get() throws InterruptedException, ExecutionException;
    // 在规定的时间如果没有返回结果就会抛出TimeoutException异常
    V get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException;
}
```

对于 FutureTask，Callable 就是他的任务，而 FutureTask 内部维护了一个任务状态，所有的状态都是围绕这个任务来进行的，随着任务的进行，状态也在不断的更新。

FutureTask 继承了 Future，实现对任务的取消、数据获取、任务状态判断等功能。

比如我们经常会调用 get() 方法获取数据，如果任务没有执行完成，会将当前线程放入阻塞队列等待，当任务执行完后，会唤醒阻塞队列中的线程。

#### 具体实例

- 先将数据按照 batchSize 分成 N 批；
- 启动 N 个线程，去执行任务；
- 通过 futureTask.get() 获取每个线程数据，并汇总输出。

```java
private static List<String> processByMultiThread(Integer batchSize) throws ExecutionException, InterruptedException {
    List<String> output = new ArrayList<>();

    // 获取分批数据
    List<List<Integer>> batchProcessData = getProcessData(batchSize);

    // 启动线程
    List<FutureTask<List<String>>> futureTaskList = new ArrayList<>();
    for (List<Integer> processData : batchProcessData) {
        Callable<List<String>> callable = () -> processOneThread(processData);
        FutureTask<List<String>> futureTask = new FutureTask<>(callable);
        // 启动线程
        new Thread(futureTask).start();  
        futureTaskList.add(futureTask);
    }

    // 获取线程返回的数据
    for (FutureTask futureTask : futureTaskList) {
        List<String> processData = (List<String>) futureTask.get();
        output.addAll(processData);
    }
    return output;
}
```

> 参考资料：
>
> - [美团一面：Thread、Runnable、Callable、Future ... 的关系？ (qq.com)](https://mp.weixin.qq.com/s/lRttJjY9bHdS4QZaBBE1iw)

### 16. execute() 方法和 submit() 方法的区别？

- `execute()` 方法用于提交不需要返回值的任务，所以无法判断任务是否被线程池执行成功与否。
- `submit()` 方法用于提交需要返回值的任务。线程池会返回一个 `Future` 类型的对象，通过这个 `Future` 对象可以判断任务是否执行成功，并且可以通过 `Future` 的 `get()` 方法来获取返回值，`get()` 方法会阻塞当前线程直到任务完成，而使用 `get(long timeout，TimeUnit unit)` 方法则会阻塞当前线程一段时间后立即返回，这时候有可能任务没有执行完。

### 17. AtomicInteger 的原理？

#### 基本概念

作用：保证操作的原子性，不用加锁也可以保证线程安全。

使用原子的方式更新基本类型：

- `AtomicInteger`：整型原子类
- `AtomicLong`：长整型原子类
- `AtomicBoolean`：布尔型原子类

还有对应的数组类型、引用类型等。

`AtomicInteger` 类常用方法：

```java
// 获取当前的值
public final int get()
    
// 获取当前的值，并设置新的值
public final int getAndSet(int newValue)
    
// 获取当前的值，并自增
public final int getAndIncrement()
    
// 获取当前的值，并自减
public final int getAndDecrement()
    
// 获取当前的值，并加上预期的值
public final int getAndAdd(int delta)
    
// 如果输入的数值等于预期值，则以原子方式将该值设置为输入值（update）
boolean compareAndSet(int expect, int update)
    
// 最终设置为 newValue，使用 lazySet 设置之后可能导致其他线程在之后的一小段时间内还是可以读到旧的值。
public final void lazySet(int newValue)
```

#### 实现原理

`AtomicInteger` 位于 `java.util.concurrent.atomic` 包下，是对 `int` 的封装，提供原子性的访问和更新操作，其原子性操作的实现是基于 CAS。

**CAS（compare-and-swap）**提供原子化的读写能力，是 Java 并发中所谓 lock-free 机制的基础。底层是基于 CPU 的 CAS 指令来实现的。基于 CAS 的操作可认为是无阻塞的，一个线程的失败或挂起不会引起其它线程也失败或挂起。并且由于 CAS 操作是 CPU 原语，所以性能比较好。

CAS 的思想很简单：三个参数，一个当前内存值 V、旧的预期值 A、即将更新的值 B，当且仅当预期值 A 和内存值 V 相同时，将内存值修改为 B 并返回 true，否则什么都不做，并返回 false。

可能会有面试官问 CAS 底层到底是如何实现的，在 Java 中，CAS 是通过调用 C++ 库，再由 C++ 库去调用 CPU 指令集来实现的。在大多数处理器上 CAS 都是个非常轻量级的操作，这也是其优势所在。

CAS 的缺点：

- **ABA 问题**：如果某个线程在 CAS 操作时发现，内存值和预期值都是 A，就能确定期间没有线程对值进行修改吗？答案未必，如果期间发生了 A -> B -> A 的更新，仅仅判断数值是 A，可能导致不合理的修改操作。针对这种情况，Java 提供了 `AtomicStampedReference` 工具类，通过为引用建立类似版本号（stamp）的方式，来保证 CAS 的正确性。
- **循环时间长、开销大**：CAS 中使用的失败重试机制，隐藏着一个假设，即竞争情况是短暂的。在大多数应用场景中，确实大部分重试只会发生一次就获得了成功。但是总有意外情况，所以在有需要的时候，还是要考虑限制自旋的次数，以免过度消耗 CPU。
- **只能保证一个共享变量的原子操作**：当对一个共享变量执行操作时，我们可以使用循环 CAS 的方式来保证原子操作，但是对多个共享变量操作时，循环 CAS 就无法保证操作的原子性。这个时候可以用锁，或者把多个共享变量合并成一个共享变量来操作。从 Java 1.5 开始 JDK 提供了 `AtomicReference` 类来保证引用对象之间的原子性，你可以把多个变量放在一个对象里来进行 CAS 操作。

> 参考资料：
>
> - [JavaArchitecture/浅谈AtomicInteger实现原理.md at master · summerHearts/JavaArchitecture · GitHub](https://github.com/summerHearts/JavaArchitecture/blob/master/Concurrent/浅谈AtomicInteger实现原理.md)
> - [Java实现CAS的原理 | Java 程序员进阶之路 (tobebetterjavaer.com)](https://tobebetterjavaer.com/thread/cas.html)

### 18. 锁机制？

#### 悲观锁

如果写的场景比较多，那么冲突的可能性会很多，此时应该使用悲观锁。

- synchronized
- ReentrantLock
- MySQL 行锁（排他锁）

#### 乐观锁

如果读的场景比较多，那么冲突会很少，使用乐观锁十分的合适，因为没有上锁，仅仅使用了版本号，十分的轻量级。

- CAS

#### 公平锁

如果在业务中需要保证某个操作的公平性，那么就应该使用公平锁。

- ReentrantLock

#### 非公平锁

在业务中没有公平性需求的情况下使用非公平锁，因为公平锁需要去实现公平，会带来性能开销。

- synchronized
- ReentrantLock

#### 独占锁

独占锁保证任何时候都只有一个线程能得到锁。

- synchronized
- ReentrantLock

独占锁其实是一种悲观锁，由于每次访问资源都要先加上互斥锁，这限制了并发性，因为读操作并不会影响数据的一致性，而独占锁只允许在同一时间由一个线程读取数据，其他线程必须等待当前线程释放锁才能进行读取。

#### 共享锁

共享锁则同时可以由多个线程持有，它允许一个资源可以被多个线程同时进行操作。

- ReadWriteLock（读写锁）

共享锁其实是一种乐观锁，它放宽了加锁的条件，允许多个线程同时进行读操作。

#### 可重入锁

当一个线程获取其他线程持有的独占锁时，该线程会被阻塞，那么当一个线程再次获取它自己已经获取的锁时会否会被阻塞呢？如果不被阻塞，那该锁就是可冲入锁，也就是只要获得了该锁的线程，那么可以无限次数（严格来说其实有次数）地进入该锁锁住的代码。

- synchronized
- ReentrantLock

可重入锁的原理是在锁内部维护了一个线程标示，用来标示该锁目前被哪个线程所持有，然后关联一个计数器。一开始计数器为 0（即该锁未被占用），当一个线程获得了该锁后，计数器的值会 +1，这时其他线程再来获取该锁时，会发现锁的持有者不是自己而被阻塞挂起。但是当获得了该锁的线程再次获取锁时发现锁的拥有者是自己，就会把计数器值 +1（变成 2、3、4、5…），当释放锁后计数器 -1，当计数器值为 0 时，锁里面的线程标示被重置为 null，这时候被阻塞的线程会被唤醒来竞争获取该锁。

```java
public class Hello {
    Object o = new Object();
    public void reentrant() {
        synchronized(o) {
            System.out.println("线程已获得锁");
            synchronized(o) {
                System.out.println("线程再次获得了该锁");
            }
        }
    }
}
```

#### 自旋锁

由于 Java 中的线程与操作系统中的线程是一一对应的，所以当一个线程在获取锁（比如独占锁）失败后，会被**切换到内核态而被挂起**。当该线程**获取到锁时又需要将其切换到用户态**而唤醒该线程。从用户状态切换到内核态的开销是比较大的，在一定程度上会影响并发性能。

自旋锁：当前线程在获取锁时，如果发现锁已经被其他线程占有，它不会马上阻塞自己，在不放弃 CPU 使用权的前提下，多次尝试获取（默认次数为 10），很有可能在后面几次尝试中其他线程已经释放了锁。如果尝试指定的次数后仍然没有获取到锁当前线程才会被阻塞挂起。由此看来自旋锁是**使用了 CPU 时间来换取上下文切换和线程调度的开销**，但是很有可能这些 CPU 时间白白浪费了。

> 参考资料：
>
> - [悲观锁、乐观锁、公平锁、非公平锁、独占锁、共享锁、可冲入锁和自旋锁你懂了吗？_NoGirlException的博客-CSDN博客_共享锁是乐观锁吗](https://blog.csdn.net/a15294758662/article/details/120851526)

## JVM

### 1. jvm 垃圾回收？怎么调优？

#### 追踪垃圾回收

通过根对象（静态变量、全局变量、常量等），寻找不可达的对象并清除。

- 标记清除算法：
  - 含义：标记死亡对象，清除死亡对象。
  - 缺点：两遍扫描，效率低；会产生内存碎片。
- 复制算法：
  - 含义：将存活对象复制到另一块内存区域，然后直接清空该内存区域。
  - 优点：效率高；不会产生内存碎片。
  - 缺点：内存利用率 < 100%；只适用于年轻代的对象（不会存活太长时间），否则会造成对象的来回复制，消耗资源。
- 标记压缩算法：
  - 含义：将当前内存区域的存活对象整理到当前内存区域的头部，然后直接清理剩下的内存空间。
  - 适用于老年代对象。

#### 引用计数

每一个对象都有一个关联到该对象的引用数目，当引用数目减少到 0 时该对象会被回收。

#### 内存分代模型

研究发现，大多数对象都是“朝生夕死”的，即生命周期非常短。也就是说，在发生 GC 的时侯，其实大多数对象已经是待回收的了，还处于正常状态的对象很少。因为存活的特别少，所以在进行复制的时候，复制的对象就特别少，占用的空间也就特别小，完全不需要 1:1 划分内存空间。

但是也有一部分对象生命周期特别长，比如缓存中的对象，还有一些别的对象等等。对于这些对象如果每次都要复制移动的话，就显的特别麻烦。另外如果某些对象特别大，如果复制的话，也放不下。

因此根据对象的特点进行了分治，将整个堆划分为两大块：新生代和老年代，分别用于存放不同特点的对象，并且对新生代和老年代采用不同的垃圾回收算法。

年轻代：

- 存放生命周期短、体积小的对象。
- 将整个新生代按照 8:1:1 的比例划分为三块，最大的称为 Eden（伊甸园）区，较小的两块分别称为 To Survivor 和 From Survivor 区。
- 采用复制算法：
  - 首次 GC 时，只需要将 Eden 存活的对象复制到 To。然后将 Eden 区整体回收。
  - 再次 GC 时，将 Eden 和 To 存活的复制到 From，循环往复这个过程（Eden 和 From -> To）。（来回复制）
  - 这样每次新生代中可用的内存就占整个新生代的 90%，大大提高了内存利用率。

![Image](E:\编程学习\学习笔记\面试笔记\img\Image-165768141393122.png)

老年代：

- 存放生命周期长、体积大的对象。
- 分配担保：由于不能保证每次存活的对象都永远少于新生代整体的10%，此时复制过去是存不下的，因此就会用到老年代，存不下的话将对象存储到老年代。若还不够，就会抛出 OOM。
- 采用标记-整理算法
- 对象如何进入老年代？
  - 提升：当对象足够老的时候，会晋升到老年代。
    - 怎么才算足够老呢？对象在多次垃圾回收（GC）后，依然存活，也就是多次从 from -> to 又从 to -> from 这样多次来回。
    - JVM 认为无需让这样的对象继续这样复制，因此将其晋升到老年代。
  - 大对象直接进入老年代。
  - 分配担保：默认的 Survivor 只占整个年轻代的 10%，当从 eden 区复制到 from / to Survivor 的时候，存不下了，这个时候对象就会被移动到老年代。
  - 动态年龄判定：若某个年龄的对象已经超过 Eden 区的一半，则大于等于该年龄的对象直接被回收。

调优：

- ‐XX:+MaxTenuringThreshold：控制进入老年代需要经历的 GC 次数。（最大值为 15，由对象头中的 4 个 bit 存放）
- -XX:PretenureSizeThreshold：默认的 Survivor 只占整个年轻代的 10%，当从 eden 区复制到 from / to 的时候，存不下了，这个时候对象会被移动到老年代。

> 参考资料：
>
> - [JVM垃圾回收算法_你的酒窝里有酒的博客-CSDN博客_jvm垃圾回收算法](https://blog.csdn.net/weixin_43213517/article/details/89853530)

### 2. jvm 内存模型？

#### 线程私有区域

- 虚拟机栈：又叫 Java 栈，一个线程对应一个虚拟机栈（线程栈），其中有栈帧，与执行的每一个方法对应，包括局部变量表等信息。
- 本地方法栈：用于虚拟机执行 Native 方法。
- 程序计数器：一个线程对应一个程序计数器，是当前线程所执行的字节码的行号指示器，用于线程切换时准确定位到程序执行的位置。

#### 线程共享区域

- 方法区：存储虚拟机加载的类信息、常量、静态变量。（jdk 8 以后叫做元空间）
- 堆：包含常量池、对象实例、数组、ThreadLocalAllocationBuffer 等。可以分为年轻代（Eden、From Survivor、To Survivor）、老年代。

![Image](E:\编程学习\学习笔记\面试笔记\img\Image-16576279176367.png)

### 3. GC 分哪两种？Minor GC 和 Full GC 有什么区别？什么时候会触发 Full GC？分别采用什么算法？

GC 类型：

- Minor GC：年轻代内存不足时触发，会清理整个年轻代。
- Major GC：老年代内存不足时触发。
- Full GC：清理整个堆空间，包括年轻代和老年代。

### **4.** JVM 里有几种 classloader？为什么会有多种？

### **5.** 什么是双亲委派机制？介绍一些运作过程，双亲委派模型的好处?

### **6.** 常见的 JVM 调优方法有哪些？可以具体到调整哪个参数，调成什么值？

### **7.** JVM 虚拟机内存划分、类加载器、垃圾收集算法、垃圾收集器、class 文件结构是如何解析的？

垃圾收集算法：

- 标记清除算法
- 复制算法
- 标记整理算法

垃圾收集器：

-  Serial 收集器
- ParNew 收集器
- Parallel Scavenge 收集器
- Serial Old 收集器
- Parallel Old 收集器
- CMS 收集器
- G1 收集器
- Z 垃圾收集器

### 8. Java 类加载的过程？

加载过程：

- 加载：通过类的全限定名获取该类的二进制流，经过转换后，在内存中创建该类的 class 对象，作为该类的数据访问入口。
- 连接：
  - 验证：验证 class 文件字节流中的信息，确保虚拟机的安全。
  - 准备：为类的静态变量分配内存（方法区），并初始化为默认值。该阶段不会为类中的实例变量分配内存，实例变量会在该类对象创建的时候，一起分配到堆内存中。
  - 解析：符号引用 -> 直接引用。
- 初始化：执行类中定义的 Java 代码（类的构造方法）。

### 9. Java 对象的初始化？

初始化过程：

- 先用 new 为对象申请内存空间，此时内存中对象成员变量的值为默认值（0），此时为半初始化状态。
- 调用构造方法，初始化变量的值。
- 建立关联，将对象（this 指针）指向对应的内存空间。

### 10. Java 对象在内存中的存储结构？

对象的结构：

- 对象头：
  - markword（标记字）：对象的 hashcode、分代年龄、锁标记位。
  - class pointer（类型指针）
- 实例数据
- 对齐

### 11. Java 对象在内存中是怎么进行分配的？

分配方式：

- 优先考虑在栈上分配内存，效率更高，但需要满足一定的条件。
- 大对象直接分配到堆中的老年区。
- TLAB（Thread Local Allocation Buffer）：线程本地分配缓冲区，在内存（Eden）中为每一个线程分配一块内存空间，由该线程独享（不用与其他线程竞争内存），可以在这块空间上 new 对象。
- 年龄太老的对象会进入 Old（老年区），通过 FGC 清除回收。

![Image](E:\编程学习\学习笔记\面试笔记\img\Image-16576284012528.png)

### 12. Object o = new Object() 在内存中占用多少字节？

内存占用情况：

- markword：8 字节
- class pointer：4 字节（压缩）或 8 字节（未压缩）
- padding：4 字节
- o 本身：4 字节

### 13. 触发 Full GC 的条件？

#### System.gc()

建议 JVM 进行 Full GC，只是建议，不是一定会发生，但一般情况下，JVM 也会进行 Full GC，进行 Full GC 时会让用户线程暂停执行，建议能不使用此方法就不使用，让虚拟机自己去管理它的内存。

#### 老年代空间不足

老年代空间只有在新生代对象转入、创建大对象、大数组时才会出现不足的现象，若执行 Full GC 后空间仍然不足，则抛出如下错误：`java.lang.OutOfMemoryError: Java heap space`。

为避免以上两种状况引起的 FullGC，调优时应尽量做到让对象在 Minor GC 阶段被回收、让对象在新生代多存活一段时间及不要创建过大的对象及数组。

#### 方法区空间不足

主要回收的是废弃常量和无用的类，当空间不足时，也会发生 full GC。

> 参考资料：
>
> - [什么情况下会发生Full GC？_安安静静的学习579的博客-CSDN博客_什么时候fullgc](https://blog.csdn.net/weixin_45608849/article/details/109078114?ops_request_misc=&request_id=&biz_id=102&utm_term=什么时候会发生full gc&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-0-109078114.142^v47^pc_rank_34_1,201^v3^control_2&spm=1018.2226.3001.4187)
> - [什么时候会触发FullGC_陈努力丶的博客-CSDN博客_cms什么时候fullgc](https://blog.csdn.net/o_o814222198/article/details/109191616?ops_request_misc=%7B%22request%5Fid%22%3A%22166321223816782412548581%22%2C%22scm%22%3A%2220140713.130102334..%22%7D&request_id=166321223816782412548581&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-2-109191616-null-null.142^v47^pc_rank_34_1,201^v3^control_2&utm_term=什么时候会发生full gc&spm=1018.2226.3001.4187)

## 其它

### 1. Java 和 C 的区别？

- C 语言容易内存泄露。
- Java 不容易，因为有 JVM 自动进行垃圾回收，但是也有可能出现内存泄露（threadlocal）。

### 2. Java 和 C++ 的区别？

- Java 不提供指针来直接访问内存，程序内存更加安全。
- Java 的类是单继承的，C++ 支持多重继承；虽然 Java 的类不可以多继承，但是接口可以多继承。
- Java 有自动内存管理垃圾回收机制（GC），不需要程序员手动释放无用内存。
- C ++同时支持方法重载和操作符重载，但是 Java 只支持方法重载（操作符重载增加了复杂性，这与 Java 最初的设计思想不符）。
- ……

### 3. 面向对象和面向过程的区别？

两者的主要区别在于解决问题的方式不同：

- 面向过程把解决问题的过程拆成一个个方法，通过一个个方法的执行解决问题。
- 面向对象会先抽象出对象，然后用对象执行方法的方式解决问题。面向对象开发的程序一般更易维护、易复用、易扩展。

### 4. 什么是语法糖？Java中有哪些语法糖？

#### 语法糖

语法糖，指在计算机语言中添加的某种语法，这种语法对语言的功能并没有影响，但是更方便程序员使用。简而言之，语法糖让程序更加简洁，有更高的可读性。

很多人说 Java 是一个“低糖语言”，但其实从 Java 7 开始 Java 语言层面上一直在添加各种糖。

#### 解语法糖

语法糖的存在主要是方便开发人员使用。但其实，Java虚拟机并不支持这些语法糖。这些语法糖在编译阶段就会被还原成简单的基础语法结构，这个过程就是解语法糖。

#### 糖块

##### （1）switch 支持 String 与枚举。

Java 中的 swith 原本就支持基本类型，比如 int、char 等。对于 int 类型，直接进行数值的比较；对于 char 类型则是比较其 ascii 码。

所以，对于编译器来说，switch 中其实只能使用整型，任何类型的比较都要转换成整型。比如 byte。short，char（ackii 码是整型）以及 int。

字符串的 switch 是通过 equals() 和 hashCode() 方法来实现的。

示例：

```java
public class switchDemoString {
    public static void main(String[] args) {
        String str = "world";
        switch (str) {
        case "hello":
            System.out.println("hello");
            break;
        case "world":
            System.out.println("world");
            break;
        default:
            break;
        }
    }
}
```

反编译后内容如下：

```java
public class switchDemoString
{
    public static void main(String args[])
    {
        String str = "world";
        String s;
        switch((s = str).hashCode())
        {
        default:
            break;
        case 99162322:
            if(s.equals("hello"))
                System.out.println("hello");
            break;
        case 113318802:
            if(s.equals("world"))
                System.out.println("world");
            break;
        }
    }
}
```

##### （2）泛型

我们都知道，很多语言都是支持泛型的，但是很多人不知道的是，不同的编译器对于泛型的处理方式是不同的。

通常情况下，一个编译器处理泛型有两种方式：Code specialization 和 Code sharing。

C++ 和 C# 是使用 Code specialization 的处理机制，而 Java 使用的是 Code sharing 的机制。

Code sharing 方式为每个泛型类型创建唯一的字节码表示，并且将该泛型类型的实例都映射到这个唯一的字节码表示上。将多种泛型类形实例映射到唯一的字节码表示是通过类型擦除（type erasue）实现的。

也就是说，对于 Java 虚拟机来说，它根本不认识 Map<String, String> map 这样的语法，需要在编译阶段通过类型擦除的方式进行解语法糖。

类型擦除的主要过程如下：

- 将所有的泛型参数用其最左边界（最顶级的父类型）类型替换。
- 移除所有的类型参数。

示例：

```java
public static <A extends Comparable<A>> A max(Collection<A> xs) {
    Iterator<A> xi = xs.iterator();
    A w = xi.next();
    while (xi.hasNext()) {
        A x = xi.next();
        if (w.compareTo(x) < 0)
            w = x;
    }
    return w;
}
```

类型擦除后会变成：

```java
// 类型擦除后，会在方法的入口、出口处添加类型转换
public static Comparable max(Collection xs){
    Iterator xi = xs.iterator();
    Comparable w = (Comparable)xi.next();
    while(xi.hasNext())
    {
        Comparable x = (Comparable)xi.next();
        if(w.compareTo(x) < 0)
            w = x;
    }
    return w;
}
```

虚拟机中没有泛型，只有普通类和普通方法，所有泛型类的类型参数在编译时都会被擦除，泛型类并没有自己独有的 Class 类对象。比如并不存在 `List<String>.class` 或是 `List<Integer>.class`，而只有 `List.class`。

##### （3）自动装箱与拆箱

自动装箱就是 Java 自动将原始类型值转换成对应的对象，比如将 int 的变量转换成 Integer 对象，这个过程叫做装箱；反之将 Integer 对象转换成 int 类型值，这个过程叫做拆箱。因为这里的装箱和拆箱是自动进行的（非人为转换），所以就称作为自动装箱和拆箱。

原始类型 byte、short、char、int、long、float、double 和 boolean 对应的包装类为 Byte、Short、Character、Integer、Long、Float、Double、Boolean。

示例：

```java
public static void main(String[] args) {
    Integer i = 10;
    int n = i;
}
```

反编译后代码如下：

```java
public static void main(String args[])
{
    Integer i = Integer.valueOf(10);
    int n = i.intValue();
}
```

从反编译得到的内容可以看出，在装箱的时候自动调用的是 `valueOf(int)` 方法。而在拆箱的时候自动调用的是 `intValue` 方法。

##### （4）方法变长参数

可变参数（variable arguments）是在 Java 5 中引入的一个特性，它允许一个方法把任意数量的值作为参数。

从反编译后的代码可以看出，可变参数在被使用的时候，他首先会创建一个数组，数组的长度就是调用该方法时传递的实参个数，然后再把参数值全部放到这个数组当中，然后再把这个数组作为参数传递到被调用的方法中。

##### （5）枚举

关键字 `enum` 可以将一组具名的值的有限集合创建为一种新的类型，而这些具名的值可以作为常规的程序组件使用，这是一种非常有用的功能。

enum 就和 class 一样，只是一个关键字，他并不是一个类。

示例：

```java
public enum T {
    SPRING, SUMMER;
}
```

反编译后的内容如下：

```java
public final class T extends Enum
{
    private T(String s, int i)
    {
        super(s, i);
    }
    
    public static T[] values()
    {
        T at[];
        int i;
        T at1[];
        System.arraycopy(at = ENUM$VALUES, 0, at1 = new T[i = at.length], 0, i);
        return at1;
    }

    public static T valueOf(String s)
    {
        return (T)Enum.valueOf(demo/T, s);
    }

    public static final T SPRING;
    
    public static final T SUMMER;
    
    private static final T ENUM$VALUES[];
    
    static
    {
        SPRING = new T("SPRING", 0);
        SUMMER = new T("SUMMER", 1);
        ENUM$VALUES = (new T[] {
            SPRING, SUMMER
        });
    }
}
```

当我们使用 `enum` 来定义一个枚举类型的时候，编译器会自动帮我们创建一个 final 类型的类继承 Enum 类，所以枚举类型不能被继承。

##### （6）内部类

内部类又称为嵌套类，可以把内部类理解为外部类的一个普通成员。

内部类之所以也是语法糖，是因为它仅仅是一个编译时的概念。

比如 `outer.java` 里面定义了一个内部类 `inner`，一旦编译成功，就会生成两个完全不同的 .class 文件，分别是 `outer.class` 和 `outer$inner.class`。所以内部类的名字完全可以和它的外部类名字相同。

##### （7）条件编译

—般情况下，程序中的每一行代码都要参加编译。但有时候出于对程序代码优化的考虑，希望只对其中一部分内容进行编译，此时就需要在程序中加上条件，让编译器只对满足条件的代码进行编译，将不满足条件的代码舍弃，这就是条件编译。

Java 语法的条件编译，是直接通过判断条件为常量的 if 语句实现的。根据 if 判断条件的真假，编译器直接把分支为 false 的代码块消除。通过该方式实现的条件编译，必须在方法体内实现，而无法在正整个 Java 类的结构或者类的属性上进行条件编译。

这与 C/C++ 的条件编译相比，确实更有局限性。在 Java 语言设计之初并没有引入条件编译的功能，虽有局限，但是总比没有更强。

##### （8）断言

在 Java 中，`assert` 关键字是从 Java 4 引入的，执行的时候默认是不启动断言检查的。如果要开启断言检查，则需要用开关 `-enableassertions` 或 `-ea` 来开启。

断言的底层实现就是 if 语言，如果断言结果为 true，则什么都不做，程序继续执行，如果断言结果为 false，则程序抛出 `AssertError` 来打断程序的执行。

示例：

```java
public class AssertTest {
    public static void main(String args[]) {
        int a = 1;
        int b = 1;
        assert a == b;
        System.out.println("公众号：Hollis");
        assert a != b : "Hollis";
        System.out.println("博客：www.hollischuang.com");
    }
}
```

##### （9）数值字面量

在 java 7 中，数值字面量，不管是整数还是浮点数，都允许在数字之间插入任意多个下划线。这些下划线不会对字面量的数值产生影响，目的就是方便阅读。

示例：

```java
public class Test {
    public static void main(String... args) {
        int i = 10_000; // 相当于 10000
        System.out.println(i);
    }
}
```

##### （10）for-each

即增强 for 循环，其实现原理就是使用了普通的 for 循环和迭代器。

##### （11）try-with-resource

Java 里，对于文件操作 IO 流、数据库连接等开销非常昂贵的资源，用完之后必须及时通过 close 方法将其关闭，否则资源会一直处于打开状态，可能会导致内存泄露等问题。

关闭资源的常用方式就是在 finally 块里释放，即调用 close 方法。

示例：

```java
public static void main(String[] args) {
    BufferedReader br = null;
    try {
        String line;
        br = new BufferedReader(new FileReader("d:\\hollischuang.xml"));
        while ((line = br.readLine()) != null) {
            System.out.println(line);
        }
    } catch (IOException e) {
        // handle exception
    } finally {
        try {
            if (br != null) {
                br.close();
            }
        } catch (IOException ex) {
            // handle exception
        }
    }
}
```

从 Java 7 开始，jdk 提供了一种更好的方式关闭资源，使用 try-with-resources 语句，如下所示：

```java
public static void main(String... args) {
    try (BufferedReader br = new BufferedReader(new FileReader("d:\\ hollischuang.xml"))) {
        String line;
        while ((line = br.readLine()) != null) {
            System.out.println(line);
        }
    } catch (IOException e) {
        // handle exception
    }
}
```

其背后的原理也很简单，那些我们没有做的关闭资源的操作，编译器都帮我们做了。

##### （12）Lambda 表达式

……

> 参考资料：
>
> - [阿里云面试：什么是语法糖？Java中有哪些语法糖？ (qq.com)](https://mp.weixin.qq.com/s/o4XdEMq1DL-nBS-f8Za5Aw)

# C/C++

## 基础知识

### 1. C++ 虚函数和纯虚函数的区别？

父类对象调用子类对象的方法时，这个被调用的方法必须在父类中声明为虚函数，因此虚函数是实现多态的一个中介。

纯虚函数是将父类上升为一个抽象类，抽象类无法实例化，只有方法的声明，其实现由其子类完成。

![Image](E:\编程学习\学习笔记\面试笔记\img\Image-16576265706996.png)

区别：

- 类如果声明了虚函数，这个函数是实现了的，即使是空实现，它的作用就是为了能让这个函数在它的子类里面可以被覆盖，这样编译器就可以使用动态绑定来达到多态的目的（即父类指针指向子类对象，调用子类方法）；而纯虚函数只是在基类中的一个函数定义，即是一个函数声明而已，具体的实现需要留到子类当中。
- 虚函数在子类里面也可以不进行重写（只有虚方法和抽象方法才能够被重写）；但纯虚函数必须在子类去实现。
- 虚函数的类用于“实作继承”，也就是说继承接口的同时也继承了父类的实现。当然，子类也可以进行覆写，从而完成自己关于此函数的实现。纯虚函数的类用于“介面继承”，即纯虚函数关注的是接口的统一性，实现由子类去完成。
- 带纯虚函数的类叫做抽象类，这种类不能直接生成对象，而只有被继承，并重写其虚函数后，才能使用。

> 参考资料：
>
> - [C++中虚函数和纯虚函数的区别_JunJie_1107的博客-CSDN博客_c++虚函数和纯虚函数的区别](https://blog.csdn.net/weixin_43869898/article/details/111436474)
> - [C++中虚函数和纯虚函数的区别_糖果Autosar的博客-CSDN博客_c++虚函数和纯虚函数的区别](https://blog.csdn.net/huihuige092/article/details/122749093)
> - [C++ 多态 | 菜鸟教程 (runoob.com)](https://www.runoob.com/cplusplus/cpp-polymorphism.html)

# Go

## 基础知识

### 1. GO Routine 为什么能实现上下文的快速切换？.

### 2. differ 函数有什么用？有什么好处？

# 计算机网络

## TCP

### 1. TCP 四次挥手？close_wait、time_wait？如果 close_wait 太多怎么办，会一直处于这个状态吗？

四次挥手的过程：

- 客户端发送一个 FIN，用来关闭客户端到服务器的数据传送。
- 服务器收到这个 FIN，它发回一个 ACK，确认序号为收到的序号加 1。和 SYN 一样，一个 FIN 将占用一个序号。
- 服务器关闭与客户端的连接，发送一个 FIN 给客户端。
- 客户端发回 ACK 确认，并将确认序号设置为收到序号加 1。

![Image](E:\编程学习\学习笔记\面试笔记\img\Image-16575444426204.png)

为什么需要四次挥手？

- 任何一方都可以在数据传送结束后发出连接释放的通知，待对方确认后进入半关闭状态。当另一方也没有数据再发送的时候，则发出连接释放通知，对方确认后就完全关闭了TCP连接。
- 举个例子：
  - A 和 B 打电话，通话即将结束后，A 说“我没啥要说的了”。
  - B 回答“我知道了”，但是 B 可能还会有要说的话，A 不能要求 B 跟着自己的节奏结束通话。
  - 于是 B 可能又巴拉巴拉说了一通，最后 B 说“我说完了”。
  - A 回答“知道了”，这样通话才算结束。

close_wait：

- 含义：主动关闭方发出 FIN 后，收到 FIN 的被动关闭方就会进入 close_wait 状态。
- 原因：
  - 服务端没有写关闭连接的代码。
  - 客户端先于服务端发送 FIN，此时需要服务端主动关闭 TCP，否则会出现大量的 close_wait，从而造成系统崩溃。
- 解决：若 TCP 连接一直处于空闲状态，系统经过 tcp_keepalive_time 后，会主动探查对方是否还活着（心跳包），经过多次试探后若对方没有任何回应，则系统会自动关闭该 TCP 连接，并释放相关资源。

time_wait：

- 含义：主动关闭方在收到被动关闭方发来的 FIN 后，会进入 time_wait 状态。

> 参考资料：
>
> - [TCP连接CLOSE_WAIT和TIME_WAIT状态学习总结_cgs1999的博客-CSDN博客_closewait超时时间](https://blog.csdn.net/cgs1999/article/details/105388428)
> - [TCP连接状态：CLOSE_WAIT和TIME_WAIT_恰得福来的博客-CSDN博客](https://blog.csdn.net/ceo158/article/details/9272725)

### 2. time_wait 过多怎么办？可不可以不要 time_wait？

结论：

- TIME_WAIT 没有不行（会使 TCP 不可靠）。
- 太多了也不行（占用系统资源）。

主动关闭的一方会进入 TIME_WAIT 状态，并且在此状态停留两倍的 MSL 时长。

MSL 指的是报文段的最大生存时间，如果报文段在网络活动了 MSL 时间，还没有被接收，那么会被丢弃。

网络是不可靠的，你无法保证你最后发送的 ACK 报文会一定被对方收到，比如丢包或者延迟到达，因此对方处于 LAST_ACK 状态下的 SOCKET 可能会因为超时未收到 ACK 报文，而重发 FIN 报文，所以这个 TIME_WAIT 状态的作用就是用来重发可能丢失的 ACK 报文。

![Image](E:\编程学习\学习笔记\面试笔记\img\Image-16575451533465.png)

存在的问题：

- 客户端：
  - 对 Client 而言，每个连接都需要占用一个端口，而系统允许的可用端口数不足 65000 个。
  - 如果 Client 发起过多的连接并主动关闭（假设没有重用端口或者连接多个 Server），就会有大量的连接在关闭后处于 TIME_WAIT 状态，等待 2MSL 的时间后才能释放网络资源（包括端口），于是 Client 会由于缺少可用端口而无法新建连接。
- 服务端：
  - 对 Server 而言（特别是处理高并发短连接的 Server），Server 端与 Client 建立的连接是使用同一个端口的。
    - 每个连接通过一个五元组区分，包括：
      - 源 IP 地址
      - 源端口
      - 传输层协议号（协议类型）
      - 目的 IP 地址
      - 目的端口
    - 因而在理论上，Server 不受系统端口数的限制。
  - 但是，Server 对每个端口上的连接数是有限制的，它要使用哈希表记录端口上的每个连接，并受到文件描述符的最大打开数的限制。所以，如果 Server 主动关闭连接，同样会有大量的连接在关闭后处于 TIME_WAIT 状态，等待 2MSL 的时间后才能释放网络资源（包括哈希表上的连接记录和文件描述符），于是 Server 会由于达到哈希表和文件描述符的限制而无法接受新连接，造成性能的急剧下滑，性能曲线会持续产生严重的波动。

解决 time_wait 过多的问题：

- 尽量让 Client 主动关闭连接，由于每个 Client 的并发量都比较低，因而不会产生性能瓶颈。
- 优化 Server 的系统 Tcp 参数：
  - 快速回收：通过修改参数启用快速回收，此时 time_wait 只有一个 rto 的时间。
  - 连接重用：有两个条件：（1）新连接的初始序列号比 TW 老连接的末序列号大；（2）如果使用了时间戳，那么新到来的连接的时间戳比老连接的时间戳大。并且同一个 ip 和端口号的才能重用。

> 参考资料：
>
> - [TIME_WAIT过多解决方法_圆的九的博客-CSDN博客_timewait状态过多解决方案](https://blog.csdn.net/moumouren2016/article/details/106609125)
> - [解决TIME_WAIT过多造成的问题_其实系一个须刨的博客-CSDN博客_time_wait连接过多的原因](https://blog.csdn.net/lianggx3/article/details/118498840)
> - [TCP连接的问题以及TIME_OUT状态_weixin_30360497的博客-CSDN博客](https://blog.csdn.net/weixin_30360497/article/details/95625116)

### 3. Tcp 和 Udp 在服务端能同时使用吗？

可以。

原因：

- TCP 的端口和 UDP 的端口是两个东西，互不影响。
- TCP 和 UDP 协议监听同一个端口后，接收到的数据并不会产生影响，因为接收数据是按照五元组 { 传输协议，源 IP，目的 IP，源端口号，目的端口号 } 来判断接收者的。
- 对于同一个端口，如果服务器要同时处理该端口上的 TCP 和 UDP 请求，需要创建两个不同的 socket：一个是流 socket，一个是数据报 socket，并将它们都绑定在该端口上。

> 参考资料：
>
> - [tcp和udp可以一起用么 - CSDN](https://www.csdn.net/tags/NtzaggwsNjY1NjMtYmxvZwO0O0OO0O0O.html)
> - [域名服务器是使用tcp协议传输数据的,DNS同时使用TCP和UDP协议_风华秋实的博客-CSDN博客](https://blog.csdn.net/weixin_31321851/article/details/119291170)
> - [同时处理TCP、UDP的服务_qq_34132502的博客-CSDN博客_同时使用tcp和udp](https://blog.csdn.net/qq_34132502/article/details/117498144)

### **4.** TCP 的 timeout 状态？时长是多少？

timewait：

根据 TCP 协议定义的 3 次握手断开连接规定，发起 socket 主动关闭的一方 socket 将进入 TIME_WAIT 状态，TIME_WAIT 状态将持续 2 个 MSL (Max Segment Lifetime)，在 Windows 下默认为 4 分钟，即 240 秒，TIME_WAIT 状态下的 socket 不能被回收使用。

具体现象是对于一个处理大量短连接的服务器，如果是由服务器主动关闭客户端的连接，将导致服务器端存在大量的处于 TIME_WAIT 状态的 socket，甚至比处于 Established 状态下的 socket 多的多，严重影响服务器的处理能力，甚至耗尽可用的 socket，停止服务。

tcp_fin_timeout ：

- 类型：INTEGER
- 默认值：60
- 含义：对于本端断开的 socket 连接，TCP 保持在 FIN_WAIT_2 状态的时间。

如何解决 Linux 服务器 Tcp 连接的 Timeout 过长？如何解决系统中存在大量的 TIME_WAIT 状态的连接？

调整内核参数：vi /etc/sysctl.conf

加入以下内容：

- net.ipv4.tcp_syncookies = 1
  - 开启 SYN Cookies
  - 当出现 SYN 等待队列溢出时，启用 cookies 来处理，可防范少量 SYN 攻击，默认为 0，表示关闭。
- net.ipv4.tcp_tw_reuse = 1
  - 开启重用
  - 允许将 TIME-WAIT sockets 重新用于新的 TCP 连接，默认为  0，表示关闭。
- net.ipv4.tcp_tw_recycle = 1
  - 开启快速回收
  - 允许将 TCP 连接中的 TIME-WAIT sockets 快速回收，默认为 0，表示关闭。
- net.ipv4.tcp_fin_timeout = 30
  - 修改系統默认的 TIMEOUT 时间。
  - 默认为 60 秒。执行 /sbin/sysctl -p 让参数生效。

### 5. TCP 和 UDP 可以同时监听相同的端口吗？

#### TCP 和 UDP 可以同时监听相同的端口吗？

答案：可以。

其实「TCP 和 UDP 可以同时监听相同的端口吗？」表述有问题，这个问题应该表述成「TCP 和 UDP 可以同时绑定相同的端口吗？」

因为「监听」这个动作是在 TCP 服务端网络编程中才具有的，而 UDP 服务端网络编程中是没有「监听」这个动作的，但是它们都会调用 bind 绑定端口。

TCP：

![image-20220730112727526](%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0%20-%20%E7%94%B3%E6%9D%89%E6%9D%89.assets/image-20220730112727526.png)

UDP：

![image-20220730112943710](%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0%20-%20%E7%94%B3%E6%9D%89%E6%9D%89.assets/image-20220730112943710.png)

在数据链路层中，通过 MAC 地址来寻找局域网中的主机。在网际层中，通过 IP 地址来寻找网络中互连的主机或路由器。在传输层中，需要通过端口进行寻址，来识别同一计算机中同时通信的不同应用程序。

所以，传输层的「端口号」的作用，是为了区分同一个主机上不同应用程序的数据包。

传输层有两个传输协议分别是 TCP 和 UDP，在内核中是两个完全独立的软件模块。

当主机收到数据包后，可以在 IP 包头的「协议号」字段知道该数据包是 TCP/UDP，所以可以根据这个信息确定送给哪个模块（TCP/UDP）处理，送给 TCP/UDP 模块的报文根据「端口号」确定送给哪个应用程序处理。

![image-20220730113543303](%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0%20-%20%E7%94%B3%E6%9D%89%E6%9D%89.assets/image-20220730113543303.png)

因此， TCP/UDP 各自的端口号也相互独立，如 TCP 有一个 80 号端口，UDP 也可以有一个 80 号端口，二者并不冲突。

#### 示例

![image-20220730114046988](%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0%20-%20%E7%94%B3%E6%9D%89%E6%9D%89.assets/image-20220730114046988.png)

运行这两个程序后，通过 netstat 命令可以看到，TCP 和 UDP 是可以同时绑定同一个端口号的。

![image-20220730114349057](%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0%20-%20%E7%94%B3%E6%9D%89%E6%9D%89.assets/image-20220730114349057.png)

netstat 命令：

- 用于显示网络状态。
- 格式：`netstat [-acCeFghilMnNoprstuvVwx][-A<网络类型>][--ip]`
- -n或--numeric：直接使用 IP 地址，而不通过域名服务器。
- -a或--all：显示所有连线中的 Socket，用于显示详细的网络状况。
- -p或--programs：显示正在使用 Socket 的程序识别码和程序名称。

> 参考资料：
>
> - [字节一面：TCP 和 UDP 可以使用同一个端口吗？ (qq.com)](https://mp.weixin.qq.com/s/rD0Fe4nqWjNAe9hGPrzBEQ)

### 6. 多个 TCP 服务进程可以绑定同一个端口吗？

#### 多个 TCP 服务进程可以绑定同一个端口吗？

答案：可以，前提是绑定的 ip 不同。

两个 TCP 服务进程同时绑定地址和端口：

- 运行第一个  TCP 服务进程之后，netstat 命令可以查看，8888 端口已经被一个 TCP 服务进程绑定并监听了。
- 接着，运行第二个 TCP 服务进程的时候，就报错了“Address already in use”。

如果两个 TCP 服务进程绑定的 IP 地址不同，而端口相同的话，也是可以绑定成功的。

特别注意：

- 如果 TCP 服务进程 A 绑定的地址是 0.0.0.0 和端口 8888，而如果 TCP 服务进程 B 绑定的地址是 192.168.1.100 地址（或者其它地址）和端口 8888，那么执行 bind() 时候也会出错。
- 这是因为 0.0.0.0  地址比较特殊，它代表任意地址，如果绑定了 0.0.0.0  地址，就相当于把主机上的所有 IP 地址都绑定了。

#### 重启 TCP 服务进程时，为什么会有“Address already in use”的报错信息？

TCP 服务进程需要绑定一个 IP 地址和一个端口，然后就监听在这个地址和端口上，等待客户端连接的到来。然后在实践中，我们可能会经常碰到一个问题，当 TCP 服务进程重启之后，总是碰到“Address in use”的报错信息，TCP 服务进程不能很快地重启，而是要过一会才能重启成功。这是为什么呢？

- 当我们重启 TCP 服务进程的时候，意味着通过服务器端发起了关闭连接操作，于是就会经过四次挥手，而对于主动关闭方，会在 TIME_WAIT 这个状态里停留一段时间，这个时间大约为 2MSL。
- 当 TCP 服务进程重启时，服务端会出现 TIME_WAIT 状态的连接，TIME_WAIT 状态的连接使用的 IP+PORT 仍然被认为是一个有效的 IP+PORT 组合，相同机器上不能够在该 IP+PORT 组合上进行绑定，那么执行 bind() 函数的时候，就会返回了 Address already in use 的错误。
- 而等 TIME_WAIT 状态的连接结束后，再重启 TCP 服务进程就能成功了。

如何避免？

- 我们可以在调用 bind 前，对 socket 设置 SO_REUSEADDR 属性。
- SO_REUSEADDR 作用是：如果当前启动进程绑定的 IP+PORT 与处于 TIME_WAIT 状态的连接占用的 IP+PORT 存在冲突，但是新启动的进程使用了 SO_REUSEADDR 选项，那么该进程就可以绑定成功。
- 因此，在所有 TCP 服务器程序中，调用 bind 之前最好对 socket 设置 SO_REUSEADDR 属性，这不会产生危害，相反，它会帮助我们在很快时间内重启服务端程序。

```c++
int on = 1;
setsockopt(listenfd, SOL_SOCKET, SO_REUSEADDR, &on, sizeof(on));
```

对于前面提到的这个问题：「如果 TCP 服务进程 A 绑定的地址是  0.0.0.0 和端口 8888，而如果 TCP 服务进程 B 绑定的地址是 192.168.1.100 地址（或者其他地址）和端口 8888，那么执行 bind() 时候也会出错」。

该问题也可以由 SO_REUSEADDR 解决，因为它的另外一个作用是：绑定 IP 地址 + 端口时，只要 IP 地址不是正好（完全）相同，那么就允许绑定。

比如对于 0.0.0.0:8888 和 192.168.1.100:8888，虽然逻辑意义上前者包含了后者，但是 0.0.0.0 泛指所有本地 IP，而 192.168.1.100 特指某一IP，两者并不是完全相同，所以在对 socket 设置 SO_REUSEADDR 属性后，那么执行 bind() 时候也会绑定成功。

SO_REUSEADDR 总结

- 如果当前启动进程绑定的 IP+PORT 与处于 TIME_WAIT 状态的连接占用的 IP+PORT 存在冲突，但是新启动的进程使用了 SO_REUSEADDR 选项，那么该进程就可以绑定成功。
- 当多个进程绑定的 IP+PORT 存在冲突时，只要 IP 地址不是正好（完全）相同，那么就允许绑定。

> 参考资料：
>
> - [字节一面：TCP 和 UDP 可以使用同一个端口吗？ (qq.com)](https://mp.weixin.qq.com/s/rD0Fe4nqWjNAe9hGPrzBEQ)

### 7. 客户端的端口可以重复使用吗？

#### 客户端的端口可以重复使用吗？

答案：可以。

客户端在执行 connect 函数的时候，会在内核里随机选择一个端口，然后向服务端发起 SYN 报文，然后与服务端进行三次握手。

![image-20220730130131005](%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0%20-%20%E7%94%B3%E6%9D%89%E6%9D%89.assets/image-20220730130131005.png)

所以，客户端的端口选择的发生在 connect 函数，内核在选择端口的时候，会从 `net.ipv4.ip_local_port_range` 这个内核参数指定的范围来选取一个端口作为客户端端口。

该参数的默认值是 32768 - 61000，意味着端口总可用的数量是 61000 - 32768 = 28232 个。

当客户端与服务端完成 TCP 连接建立后，我们可以通过 `netstat -napt` 命令查看 TCP 连接。

那问题来了，如果客户端已经用了 64992 端口，那么还可以继续使用该端口发起连接吗？

对于这个问题，很多同学都会说不可以继续使用该端口了，如果按这个理解的话， 默认情况下客户端可以选择的端口是 28232 个，那么意味着客户端只能最多建立  28232 个 TCP 连接，如果真是这样的话，那么这个客户端并发连接也太少了吧，所以这是错误理解。

正确的理解是：

- TCP 连接是由四元组（源 IP 地址，源端口，目的 IP 地址，目的端口）唯一确认的，那么只要四元组中其中一个元素发生了变化，那么就表示不同的 TCP 连接。
- 所以如果客户端已使用端口 64992 与服务端 A 建立了连接，那么客户端要与服务端 B 建立连接，还是可以使用端口 64992 的，因为内核是通过四元组信息来定位一个 TCP 连接的，并不会因为客户端的端口号相同，而导致连接冲突的问题。

#### 多个客户端可以 bind 同一个端口吗？

bind 函数虽然常用于服务端网络编程中，但是它也是用于客户端的。

前面我们知道，客户端是在调用 connect 函数的时候，由内核随机选取一个端口作为连接的端口。

而如果我们想自己指定连接的端口，就可以用 bind 函数来实现：客户端先通过 bind 函数绑定一个端口，然后调用 connect 函数就会跳过端口选择的过程了，转而使用 bind 时确定的端口。

那么可以 bind 同一个端口吗？

- 要看多个客户端绑定的 IP + PORT 是否都相同，如果都是相同的，那么在执行 bind() 时候就会出错，错误是“Address already in use”。
- 如果一个绑定在 192.168.1.100:6666，一个绑定在 192.168.1.200:6666，因为 IP 不相同，所以执行 bind() 的时候，能正常绑定。

一般而言，客户端不建议使用 bind 函数，应该交由 connect 函数来选择端口会比较好，因为客户端的端口通常都没什么意义。

#### 客户端 TCP 连接 TIME_WAIT 状态过多，会导致端口资源耗尽而无法建立新的连接吗？

针对这个问题要看，客户端是否都是与同一个服务器（目标地址和目标端口一样）建立连接。

- 如果客户端都是与同一个服务器（目标地址和目标端口一样）建立连接，那么如果客户端 TIME_WAIT 状态的连接过多，当端口资源被耗尽，就无法与这个服务器再建立连接了。
- 但是，只要客户端连接的服务器不同，那么端口的资源就是可以重复使用的。
- 所以，如果客户端都是与不同的服务器建立连接，即使客户端端口资源只有几万个， 客户端发起百万级连接也是没问题的（当然这个过程还会受限于其他资源，比如文件描述符、内存、CPU 等）。

#### 如何解决客户端 TCP 连接 TIME_WAIT 过多，导致无法与同一个服务器建立连接的问题？

前面我们提到，如果客户端都是与同一个服务器（目标地址和目标端口一样）建立连接，那么如果客户端 TIME_WAIT 状态的连接过多，当端口资源被耗尽，就无法与这个服务器再建立连接了。

针对这个问题，也是有解决办法的，那就是打开 `net.ipv4.tcp_tw_reuse` 这个内核参数。

因为开启了这个内核参数后，客户端调用 connect  函数时，如果选择到的端口，已经被相同四元组的连接占用的时候，就会判断该连接是否处于 TIME_WAIT 状态，如果该连接处于 TIME_WAIT 状态并且 TIME_WAIT 状态持续的时间超过了 1 秒，那么就会重用这个连接，然后就可以正常使用该端口了。

- 如果没有开启 `net.ipv4.tcp_tw_reuse` 内核参数，那么内核就会选择下一个端口，然后继续判断，直到找到一个没有被相同四元组的连接使用的端口， 如果端口资源耗尽还是没找到，那么 connect 函数就会返回错误。
- 如果开启了 `net.ipv4.tcp_tw_reuse` 内核参数，就会判断该四元组的连接状态是否处于 TIME_WAIT 状态，如果连接处于 TIME_WAIT 状态并且该状态持续的时间超过了 1 秒，那么就会重用该连接，这时 connect 就会返回成功。

注意：开启 `net.ipv4.tcp_tw_reuse` 内核参数后，是客户端（连接发起方） 在调用 connect() 函数时才起作用，所以在服务端开启这个参数是没有效果的。

#### 客户端端口选择的流程总结

![image-20220730132226308](%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0%20-%20%E7%94%B3%E6%9D%89%E6%9D%89.assets/image-20220730132226308.png)

> 参考资料：
>
> - [字节一面：TCP 和 UDP 可以使用同一个端口吗？ (qq.com)](https://mp.weixin.qq.com/s/rD0Fe4nqWjNAe9hGPrzBEQ)

## UDP

### 1. udp 头的大小？包含的内容？

大小：8 个字节。

内容：

- 源端口号：16 bit
- 目的端口号：16 bit
- 数据包长度：16 bit
- 校验和：16 bit

![Image](E:\编程学习\学习笔记\面试笔记\img\Image-16575475736606.png)

### 2. udp 的使用场景？视频面试使用的是 tcp 还是 udp？wireshark 抓包分析一下？

UDP 的特点：

- 面向报文：
  - 发送方的 UDP 对应用程序交下来的报文，在添加首部后就向下交付 IP 层。
  - UDP 对应用层交下来的报文，既不合并，也不拆分，而是保留这些报文的边界。因此，应用程序必须选择合适大小的报文。
- 没有拥塞控制：
  - 网络出现的拥塞不会使源主机的发送速率降低。
  - 很多的实时应用（如 IP 电话、实时视频会议等）要求源主机以恒定的速率发送数据，并且允许在网络发生拥塞时丢失一些数据，但却不允许数据有太多的时延。UDP 正好符合这种要求。
- ……

使用场景（实时性）：

- 音视频通话（尽力可靠）
- 文件传输、迅雷下载文件、分片下载（无序可靠）
- 金融转账（有序可靠）
- 网络游戏

视频会议使用的是 RUDP：

- 同时保证可靠性 + 实时性。
- 常见的 RUDP 协议：QUIC、WebRTC、Aeron。

> 参考资料：
>
> - [UDP的主要特点及其使用场景-电子发烧友网 (elecfans.com)](https://www.elecfans.com/d/1696374.html)
> - [udp三大高并发应用场景_Bluce-orancle的博客-CSDN博客_udp应用场景](https://blog.csdn.net/bluce_orancle/article/details/113856752)
> - [视频面试传输协议到底是TCP还是UDP - 掘金 (juejin.cn)](https://juejin.cn/post/6867043669682651143)

### 3. QUIC 协议？

#### 基本介绍

QUIC（Quick UDP Internet Connection）是由 Google 公司提出的基于 UDP 的高效可靠协议，属于应用层协议。其主要目的，是为了整合 TCP 协议的可靠性和 UDP 协议的速度和效率。

- 高效：无连接。
- 可靠：在应用层上模仿 TCP 来保证可靠性。

QUIC 非常类似于在 UDP 上实现的 TCP（可靠性）+ TLS（安全性）+ HTTP/2.0（并发性）。

- 由于 TCP 是在操作系统内核和中间件固件中实现的，因此对 TCP 进行重大更改几乎是不可能的。
- 而 QUIC 建立在 UDP 之上，因此没有这种限制。QUIC 可以实现可靠传输，而且相比于 TCP，它的流控功能在用户空间而不在内核空间。

#### 特点

利用缓存快速建立连接：

- 减少了 TCP 三次握手及 TLS 握手时间，可以 0 RTT 建立连接。
- RTT：round-trip time（往返时延）。
- 首次建立连接需要 1 RTT 用于协商秘钥。

更好的拥塞控制：

- 拥塞控制从内核空间转到用户空间，可以根据应用场景自由调整和优化。
- 可以针对不同业务，不同网络制式，甚至不同的 RTT，使用不同的拥塞控制算法。

更好的重传机制：

- 前向纠错，减少重传。

没有队头阻塞的多路复用：

- 对于 HTTP 2.0，如果访问同一个服务器只会有一个 TCP 连接，所有的请求都会走这条连接。每个请求在 Connection 中叫做 Stream，一个 Connection 中可以有多个 Stream，这里有个问题是在 TCP 中的包是保证时序的，如果某个 Stream 丢了一个包，他同时也会影响其他的 Stream，在更为严重的时候反而多路复用还不如 HTTP 1.1 的多个链接。
- 而在 QUIC 中，因为底层是基于 UDP，UDP 不需要保证包的时序，只会在接收包的时候对包进行重组，所以不会存在这个问题。这也就是为什么 Google 提议在 HTTP 3 中使用 QUIC 的原因。

更好的流量控制：

- QUIC 是多路复用的，在 QUIC 中可以针对 Stream 和 Connection 都进行流量控制。
- QUIC 的流量控制和 TCP 有点区别，TCP 为了保证可靠性，窗口左边沿向右滑动时的长度取决于已经确认的字节数。如果中间出现丢包，就算接收到了更大序号的 Segment，窗口也无法超过这个序列号。
- 但 QUIC 不同，就算此前有些 packet 没有接收到，它的滑动只取决于接收到的最大偏移字节数。

连接平滑迁移：

- 一条 TCP 连接是由四元组标识的（源 IP，源端口，目的 IP，目的端口）。什么叫连接迁移呢？就是当其中任何一个元素发生变化时，这条连接依然维持着，能够保持业务逻辑不中断。当然这里面主要关注的是客户端的变化，因为客户端不可控并且网络环境经常发生变化，而服务端的 IP 和端口一般都是固定的。
  - 比如使用手机在 WIFI 和 4G 移动网络切换时，客户端的 IP 肯定会发生变化，需要重新建立和服务端的 TCP 连接。
  - 又比如大家使用公共 NAT 出口时，有些连接竞争时需要重新绑定端口，导致客户端的端口发生变化，同样需要重新建立 TCP 连接。
- 那 QUIC 是如何做到连接迁移呢？
  - 很简单，任何一条 QUIC 连接不再以 IP 及端口四元组标识，而是以一个 64 位的随机数作为 ID 来标识，这样就算 IP 或者端口发生变化时，只要 ID 不变，这条连接依然维持着，上层业务逻辑感知不到变化，不会中断，也就不需要重连。
  - 由于这个 ID 是客户端随机产生的，并且长度有 64 位，所以冲突概率非常低。

#### 协议栈结构

QUIC 底层通过 UDP 协议替代了 TCP，上层只需要一层用于和远程服务器交互的 HTTP/2 API。这是因为 QUIC 协议已经包含了多路复用和连接管理，HTTP API 只需要完成 HTTP 协议的解析即可。

![Image](E:\编程学习\学习笔记\面试笔记\img\Image-16575491097737.png)

七层模型：

![Image](E:\编程学习\学习笔记\面试笔记\img\Image-16575491251048.png)

#### 连接建立流程

耗时对比：

![Image](E:\编程学习\学习笔记\面试笔记\img\Image-16575492712889.png)

TCP 三次握手：1 RTT

![Image](E:\编程学习\学习笔记\面试笔记\img\Image-165754936764010.png)

TCP + TLS：1 RTT + 2 RTT

![Image](E:\编程学习\学习笔记\面试笔记\img\Image-165754942428711.png)

QUIC：0 RTT

![Image](E:\编程学习\学习笔记\面试笔记\img\Image-165754946626312.png)

#### 可靠性

可靠性的含义：

- 完整性：发送端发出的数据包，接收端都能收到。
- 有序性：接收端能按序组装数据包，解码得到有效的数据。

发送端怎么知道发出的包是否被接收端收到了？（完整性）

- 通过包号（PKN）和确认应答（SACK）保证。
- QUIC 的数据包号是单调递增的。也就是说，之前发送的数据包（PKN=2）和重传的数据包（PKN=4），虽然数据一样，但包号不同。

![Image](E:\编程学习\学习笔记\面试笔记\img\Image-165754963734913.png)

既然包号是单调递增的，那接收端怎么保证数据的顺序呢？（有序性）

- 通过数据偏移量 offset 保证。
- 每个数据包都有一个 offset 字段，表示在整个数据中的偏移量。
- 接收端根据 offset 字段就可以对异步到达的数据包进行排序了。

![Image](E:\编程学习\学习笔记\面试笔记\img\Image-165754975227214.png)

为什么 QUIC 要将 PKN 设计为单调递增？

- 解决 TCP 的重传歧义问题。
- 由于原始包和重传包的序列号是一样的，客户端不知道服务器返回的 ACK 包到底是原始包的，还是重传包的。但 QUIC 的原始包和重传包的序列号是不同的，也就可以判断 ACK 包的归属。

> 参考资料：
>
> - [视频面试传输协议到底是TCP还是UDP - 掘金 (juejin.cn)](https://juejin.cn/post/6867043669682651143)
> - [QUIC协议是如何做到0RTT加密传输的(addons)_dog250的博客-CSDN博客_quic连接建立](https://blog.csdn.net/dog250/article/details/80935534)
> - [网络编程懒人入门(十)：一泡尿的时间，快速读懂QUIC协议-网络编程/专项技术区 - 即时通讯开发者社区! (52im.net)](http://www.52im.net/thread-2816-1-1.html)
> - [技术扫盲：新一代基于UDP的低延时网络传输层协议——QUIC详解-网络编程/专项技术区 - 即时通讯开发者社区! (52im.net)](http://www.52im.net/thread-1309-1-1.html)
> - [QUIC协议的分析，性能测试以及在QQ会员实践 - 腾讯WeTest - 博客园 (cnblogs.com)](https://www.cnblogs.com/wetest/p/9022214.html)
> - [QUIC 协议详解 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/405387352)

## HTTP

### 1. Http 报文组成？里面分别有什么？

#### 请求报文

- 请求行：
  - 包含：请求方法、URL、HTTP 协议版本。
  - 示例：GET  /data/info.html  HTTP/1.1。
  - 请求方法：
    - GET
    - POST
    - ……
  - URL：
    - 对于 GET 方法，参数直接置于 URL 中（不安全），报文体则为空。
    - 对于 POST 方法，URL 中不带参数，参数放于报文体中。
  - HTTP 协议版本：
    - HTTP 1.0 是短连接，每个连接都只传送一个请求和响应，然后连接就会关闭。
    - HTTP 1.1 是长连接，可以同时传送多个请求和响应。
- 请求头：![Image](E:\编程学习\学习笔记\面试笔记\img\Image-16576136599741.png)
- 空行：告诉服务器请求头到此为止。
- 请求数据：
  - 对于 GET 方法，此项为空，没有数据。
  - 对于 POST 方法，此处为要提交的数据。
- 结构：![Image](E:\编程学习\学习笔记\面试笔记\img\Image-16576137927612.png)

#### 响应报文

- 响应行：
  - 包含：协议版本、状态码及其描述。
  - 示例：HTTP/1.1  200 OK。
  - 状态码：![Image](E:\编程学习\学习笔记\面试笔记\img\Image-16576138470113.png)
- 响应头：
  - 响应头用于描述服务器的基本信息，以及数据的描述，服务器通过这些数据的描述信息，可以通知客户端如何处理等一会儿它回送的数据。
  - 设置 HTTP 响应头往往和状态码结合起来。
  - 响应头可以用来完成：设置 Cookie、指定修改日期、指示浏览器按照指定的间隔刷新页面等。
- 响应体：
  - 就是响应的消息体，如果是纯数据就是返回纯数据，如果请求的是 HTML 页面，那么返回的就是 HTML 代码，如果是 JS 就是 JS 代码。
- 结构：![Image](E:\编程学习\学习笔记\面试笔记\img\Image-16576139721714.png)

> 参考资料：
>
> - [HTTP请求包及应答包报文主要结构组成_资深程序员的转型渗透之路的博客-CSDN博客_http请求包](https://blog.csdn.net/Jerry_GuJY/article/details/123562809)

### 2. Http 状态码 502、503 是什么意思？

5XX：

- 500：服务器出错
- 502：网关错误
- 503：服务不可用
- ……

> 参考资料：
>
> - [常见的HTTP状态码及HTTP状态码大全-太平洋IT百科 (pconline.com.cn)](https://product.pconline.com.cn/itbk/software/llq/1508/6862518.html)

### 3. Https 网站发送给客户端的证书是什么？

#### 为什么需要证书？

![image-20220712170229233](E:\编程学习\学习笔记\面试笔记\img\image-20220712170229233.png)

#### 数字证书原理

https 即超文本传输安全协议，是在 http 基础上加入了 SSL 层，也就是在 http 协议上部署了 SSL 证书，所以 https 协议证书就是 SSL 证书。

SSL 证书是数字证书（数字证书包括：SSL 证书、客户端证书、代码签名证书等）的一种，因为配置在服务器上也称为服务器 SSL 证书。SSL 证书就是遵守 SSL 协议，由受信任的数字证书颁发机构 CA 在验证服务器身份后颁发的一种数字证书。

![image-20220712170445746](E:\编程学习\学习笔记\面试笔记\img\image-20220712170445746.png)

证书申请：

- 制作 CSR 文件（证书请求文件），系统会产生 2 个秘钥：公钥（CSR 文件）、私钥（放到服务器上）。
- CA 认证：将 CSR 提交给 CA，收到 CA 的证书后，可以将证书部署到服务器上。

![image-20220712170623792](E:\编程学习\学习笔记\面试笔记\img\image-20220712170623792.png)

![image-20220712170722209](E:\编程学习\学习笔记\面试笔记\img\image-20220712170722209.png)

验证流程：

- 先验证证书的合法性
- 再验证信息的完整性

![image-20220712170809938](E:\编程学习\学习笔记\面试笔记\img\image-20220712170809938.png)

![image-20220712171202083](E:\编程学习\学习笔记\面试笔记\img\image-20220712171202083.png)

> 参考资料：
>
> - [https证书是什么？https证书怎么申请？-新网 (xinnet.com)](https://www.xinnet.com/knowledge/2142335974.html)

### 4. Cookie 和 Session 的区别？

> 参考资料：
>
> - [彻底了解Cookie和Session的区别（面试）_辰兮要努力的博客-CSDN博客_session和cookie的区别](https://blog.csdn.net/weixin_45393094/article/details/104747360?ops_request_misc=%7B%22request%5Fid%22%3A%22166320736216782388050564%22%2C%22scm%22%3A%2220140713.130102334.pc%5Fall.%22%7D&request_id=166320736216782388050564&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_ecpm_v1~pc_rank_34-1-104747360-null-null.142^v47^pc_rank_34_1,201^v3^control_2&utm_term=彻底了解cookie和session的区别&spm=1018.2226.3001.4187)

## NAT

### 1. 什么是私网 ip 和公网 ip？NAT 原理？内网的主机是如何与公网上的主机进行通信的？

- 私网：本地网络
- 公网：互联网

NAT/NAPT：

NAT 路由器会在内网主机与外网主机的 TCP 连接建立时，自动生成并动态维护一张表，这张表用于保存映射关系：内网中的不同 ip，相同端口 -> 同一个公网 ip，不同端口。 

扩展：

NAT-PT：将 IPv6 的首部 -> IPv4 的首部。

## 密码学

### 1. 说一说知道的对称加密、非对称加密算法？

#### 基本概念

密钥的度量单位是位 bit，如，秘钥长度 128，就是 16 字节的二进制串。

按照密钥的使用方式，加密可以分为两大类：

- 对称加密
- 非对称加密

#### 对称加密

![image-20220712163720925](E:\编程学习\学习笔记\面试笔记\img\image-20220712163720925.png)

AES 加密算法：密钥长度 128、192 或 256，安全强度很高，性能很好。

#### 非对称加密

![image-20220712164047430](E:\编程学习\学习笔记\面试笔记\img\image-20220712164047430.png)

使用公钥加密后只能用私钥解密，反过来，私钥加密后也只能用公钥解密。

RSA 加密算法：最著名的非对称加密算法。

#### 总结

- 对称加密：
  - 优点：运算速度快
  - 缺点：秘钥需要双方共享，一旦被窃取，消息会被破解。
- 非对称加密：
  - 优点：私钥严格保密，公钥任意分发，黑客获取公钥无法破解密文。
  - 缺点：运算速度非常慢

### 2. 如何保证信件不被篡改，即信息的完整性？

#### 摘要算法

![image-20220712164809061](E:\编程学习\学习笔记\面试笔记\img\image-20220712164809061.png)

特点：

- 不可逆：只有算法，没有秘钥，只能加密，不能解密。
- 难题友好性：想要破解，只能暴力枚举。
- 发散性：只要对原文进行一点点改动，摘要就会发生剧烈变化。
- 抗碰撞性：原文不同，计算后的摘要也要不同。

常见摘要算法：MD5、SHA1、SHA2。

原理：

![image-20220712165821296](E:\编程学习\学习笔记\面试笔记\img\image-20220712165821296.png)

#### 数字签名

![image-20220712165930465](E:\编程学习\学习笔记\面试笔记\img\image-20220712165930465.png)

# 操作系统

## 线程、进程

### 1. 什么是僵尸进程和孤儿进程？

#### 基本概念

在 Unix/Linux 系统中，正常情况下，子进程是通过父进程创建的，且两者的运行是相互独立的，父进程永远无法预测子进程到底什么时候结束。当一个进程调用 `exit` 命令结束自己的生命时，其实它并没有真正的被销毁，内核只是释放了该进程的所有资源，包括打开的文件、占用的内存等，但是留下一个称为僵尸进程的数据结构，这个结构保留了一定的信息（包括进程号 the process ID，退出状态，运行时间），这些信息直到父进程通过 `wait()`/`waitpid()` 来取时才释放。这样设计的目的主要是保证只要父进程想知道子进程结束时的状态信息，就可以得到。

- **僵尸进程**：一个进程使用 `fork` 创建子进程，如果子进程退出，而父进程并没有调用 `wait` 或 `waitpid` 获取子进程的状态信息，那么子进程的进程描述符仍然保存在系统中，这种进程称之为僵尸进程。
- **孤儿进程**：一个父进程退出，而它的一个或多个子进程还在运行，那么这些子进程将成为孤儿进程。孤儿进程将被 `init` 进程（进程号为 1）所收养，并由 `init` 进程对它们完成状态收集工作。

> 每个 Linux 进程在进程表里都有一个进入点（entry），核心程序执行该进程时使用到的一切信息都存储在进入点。当用 `ps` 命令察看系统中的进程信息时，看到的就是进程表中的相关数据。当以 `fork()` 系统调用建立一个新的进程后，核心进程就会在进程表中给这个新进程分配一个进入点，然后将相关信息存储在该进入点所对应的进程表内。这些信息中有一项是其父进程的识别码。当这个进程走完了自己的生命周期后，它会执行 `exit()` 系统调用，此时原来进程表中的数据会被该进程的退出码（exit code）、执行时所用的 CPU 时间等数据所取代，这些数据会一直保留到系统将它传递给它的父进程为止。由此可见，`defunct` 进程的出现时间是在子进程终止后，但是父进程尚未读取这些数据之前。

僵尸进程就是已经结束了的进程，但是没有从进程表中删除。太多了会导致进程表里面条目满了，进而导致系统崩溃，倒是不占用其他系统资源。在使用 `top` 打印的进程信息中，如果某个进程最后有 `defunct` 的标记，就表明是僵尸进程。

#### 解决方法

可以使用 `top` 命令来查看服务器当前是否有僵尸进程：

**![image-20221217115719471](%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0%20-%20%E7%94%B3%E6%9D%89%E6%9D%89.assets/image-20221217115719471.png)**

查找僵尸进程：

```shell
ps -A -ostat,ppid,pid,cmd | grep -e '^[Zz]'
```

注解：

- `-A`：列出所有进程
- `-o`：自定义输出字段，我们设定显示字段为 stat（状态）、ppid（父进程 pid）、pid（进程 pid）、cmd（命令行）这四个参数
- 状态为 `z` 或者 `Z` 的进程为僵尸进程

结果如下：

![image-20221217120110481](%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0%20-%20%E7%94%B3%E6%9D%89%E6%9D%89.assets/image-20221217120110481.png)

这里直接杀死僵尸进程的父进程：

```shell
kill -9 31112
```

> 参考资料：
>
> - [僵尸进程以及如何处理僵尸进程_Just_Goer~的博客-CSDN博客_僵尸进程](https://blog.csdn.net/m0_46571920/article/details/122085156)
> - [什么是僵尸进程与孤儿进程_张维鹏的博客-CSDN博客_僵尸进程](https://blog.csdn.net/a745233700/article/details/120715371)

## 内存管理

### 1. 操作系统是如何进行内存管理的？

内存管理系统：

- 早期的：
  - 内存不够
  - 互相打扰
- 现在的：
  - 分页装入
  - 虚拟地址
  - 软硬件结合寻址

#### 内存分页

解决内存满了的问题。

- 内存中分成固定大小的页框（4k）。
- 把程序（硬盘上）分成 4k 大小的块，用到哪一块，就加载哪一块。
- 若加载的过程中，内存满了，会把最不常用的一块放到 swap 分区，把最新的一块加载进来（LRU 算法）。

![Image](E:\编程学习\学习笔记\面经整理\img\Image-16581956171661.png)

LRU 算法：

- LRU：Least Recently Used（清除最不常用的缓存）。
- 题目链接：[146. LRU 缓存 - 力扣（LeetCode）](https://leetcode.cn/problems/lru-cache/)（要求手撕）。

实现：

- 哈希表：
  - key 存键值，value 存要查询的对象（链表节点）。
  - 保证查找操作 O(1)。
- 双向链表：
  - key 存键值，value 存具体的数据。
  - 保证排序操作、新增操作都是 O(1)。
- get 方法：
  - 根据 id 从 map 中拿对象。
  - 将该对象从链表中移动到链表头部。
- set 方法：
  - 判断当前要 set 的 key 在缓存中是否存在？
    - 若存在：
      - 通过 map 的 key 获取该节点，并修改其值。
      - 将该节点移动到链表的头部。
    - 若不存在：
      - 为当前元素创建新节点，并分别添加到 map 中，以及链表的头部。
      - 缓存的 size 加 1。
      - 判断缓存的容量有没有满？
        - 满了：移除链表末尾的元素（最久未使用的），并在 map 中也移除。

代码：

```java
public class LRUCache {
    
    // 双向链表
    class DLinkedNode {
        int key;
        int value;
        DLinkedNode prev;
        DLinkedNode next;
        public DLinkedNode() {}
        public DLinkedNode(int _key, int _value) {
            key = _key; 
            value = _value;
        }
    }

    private Map<Integer, DLinkedNode> cache = new HashMap<Integer, DLinkedNode>();
    
    // 缓存当前的大小
    private int size;
    // 缓存的最大容量
    private int capacity;
    
    // 哑结点：便于头尾节点的插入、删除操作
    private DLinkedNode head, tail;

    public LRUCache(int capacity) {
        this.size = 0;
        this.capacity = capacity;
        // 创建伪头部和伪尾部节点
        head = new DLinkedNode();
        tail = new DLinkedNode();
        head.next = tail;
        tail.prev = head;
    }

    public int get(int key) {
        DLinkedNode node = cache.get(key);
        if (node == null) {
            return -1;
        }
        // 如果 key 存在，先通过哈希表定位，再移到头部
        moveToHead(node);
        return node.value;
    }

    public void put(int key, int value) {
        DLinkedNode node = cache.get(key);
        if (node == null) {
            // 如果 key 不存在，创建一个新的节点
            DLinkedNode newNode = new DLinkedNode(key, value);
            // 添加进哈希表
            cache.put(key, newNode);
            // 添加至双向链表的头部
            addToHead(newNode);
            ++size;
            if (size > capacity) {
                // 如果超出容量，删除双向链表的尾部节点
                DLinkedNode tail = removeTail();
                // 删除哈希表中对应的项
                cache.remove(tail.key);
                --size;
            }
        }
        else {
            // 如果 key 存在，先通过哈希表定位，再修改 value，并移到头部
            node.value = value;
            moveToHead(node);
        }
    }

    private void addToHead(DLinkedNode node) {
        node.prev = head;
        node.next = head.next;
        head.next.prev = node;
        head.next = node;
    }

    private void removeNode(DLinkedNode node) {
        node.prev.next = node.next;
        node.next.prev = node.prev;
    }

    private void moveToHead(DLinkedNode node) {
        removeNode(node);
        addToHead(node);
    }

    private DLinkedNode removeTail() {
        DLinkedNode res = tail.prev;
        removeNode(res);
        return res;
    }
}
```

#### 虚拟地址

解决互相打扰的问题。

含义：

- 让进程工作在虚拟空间，程序中用到的空间地址不再是直接的物理地址，而是虚拟的地址，这样 A 进程永远不可能访问到 B 进程的空间。
- 站在虚拟的角度，进程独享整个系统和 CPU。
- 虚拟地址需要经过操作系统的映射才能找到相应的物理地址。

虚拟空间的大小：

- 寻址空间：64 位系统是 2 ^ 64 位。
- 比物理空间大很多。

虚拟空间的格式固定，进程内部分段：数据段、代码段 ……。

![Image](E:\编程学习\学习笔记\面试笔记\img\Image-16581967233102.png)

优点：

- 隔离应用程序：
  - 每个程序都认为自己有连续可用的内存。
  - 突破物理内存限制。
  - 应用程序不需要考虑物理内存是否够用，是否能够分配等底层问题。
- 安全：保护物理内存，不被恶意程序访问。

# 数据结构

## 二叉树

### 1. 红黑树的实现原理和应用场景？

红黑树的特点：

- 每个结点要么是红的，要么是黑的。
- 根结点是黑的。
- 每个叶结点，即空结点是黑的。
- 如果一个结点是红的，那么它的两个儿子都是黑的。
- 对每个结点，从该结点到其子结点的所有路径上包含相同数目的黑结点。

应用场景：

- Java 中的 TreeSet、TreeMap。

## 哈希表

### 1. 哈希表为什么查询、插入的时间复杂度是 O(1)？

通过哈希函数将存入的每一个对象映射为一个 hashcode，可以直接到这个 hashcode 对应的位置上去找对应的 value。

> 参考资料：
>
> - [【数据结构】什么是哈希表？为什么哈希表的查询时间复杂度是O(1)?_我是一棵卷心菜的博客-CSDN博客](https://blog.csdn.net/weixin_59654772/article/details/124577098)

### 2. HashMap 在 jdk1.7 的多线程下会发生什么？在 jdk1.8 下会发生吗？

#### jdk1.7 与 jdk1.8 对比

- jdk1.7 中底层是由数组 + 链表实现；jdk1.8 中底层是由数组 + 链表（长度达到 8 时 -> 红黑树）实现。
- 可以存储 null 键和 null 值，线程不安全。
- 初始 size 为 16，扩容：newsize = oldsize*2，size 一定为 2 的 n 次幂。
- 扩容针对整个 Map，每次扩容时，原来数组中的元素依次重新计算存放位置，并重新插入元素后才判断该不该扩容，有可能无效扩容（插入后如果扩容，如果没有再次插入，就会产生无效扩容）。
- 当 Map 中元素总数超过 Entry 数组的 75%，触发扩容操作，为了减少链表长度，元素需分配更均匀。
- 1.7 中是先扩容后插入新值，1.8 中是先插值再扩容。

#### 为什么说 HashMap 是线程不安全的？

HashMap 的扩容机制就是重新申请一个容量是当前的 2 倍的桶数组，然后将原先的记录逐个重新映射到新的桶里面，然后将原先的桶逐个置为 null 使得引用失效。HashMap 之所以线程不安全，就是 resize 这里出的问题。

- 在接近临界点时，若此时两个或者多个线程进行 put 操作，都会进行 resize（扩容）和 reHash（为 key 重新计算所在位置），而 reHash 在并发的情况下可能会形成链表环。
- 总结来说就是在多线程环境下，使用 HashMap 进行 put 操作后再进行 get 操作时可能会引起死循环，导致 CPU 利用率接近 100%，所以在并发情况下不能使用 HashMap。
- 为什么在并发执行 put 操作会引起死循环？是因为多线程会导致 HashMap 的 Entry 链表形成环形数据结构，一旦形成环形数据结构，Entry 的 next 节点永远不为空，就会产生死循环获取 Entry。
- jdk1.7 的情况下，并发扩容时容易形成链表环，此情况在 1.8 时就好太多太多了。因为在 1.8 中当链表长度大于阈值（默认长度为 8）时，链表会被改成树形（红黑树）结构。

#### 几种 Map 的对比

- HashMap 是线程不安全的。
- HashTable 是线程安全的，它使用 synchronize 来做线程安全，全局只有一把锁，在线程竞争比较激烈的情况下 hashtable 的效率是比较低下的。
- ConcurrentHashMap 使用了分段锁技术来提高了并发度，不在同一段的数据互相不影响，多个线程对多个不同的段的操作是不会相互影响的。每个段使用一把锁。所以在需要线程安全的业务场景下，推荐使用 ConcurrentHashMap。

> 参考资料：
>
> - [HashMap为什么在多线程操作下不安全（jdk1.7和jdk1.8原因不同）_柯南二号的博客-CSDN博客_hashmap 多线程下有什么问题](https://blog.csdn.net/qq_41688840/article/details/109345455)
> - [HashMap在JDK1.7和1.8中的实现_星海少年的博客-CSDN博客](https://blog.csdn.net/weixin_45606067/article/details/107167819)
> - [老生常谈，HashMap的死循环 - 简书 (jianshu.com)](https://www.jianshu.com/p/1e9cf0ac07f4)

### 3. HashMap 指定数组大小为什么必须是 2 的 n 次幂？

保证数据均匀的插入（分配），减少数据之间的哈希碰撞。

为什么 hashcode % length -> hashcode & (length-1)？

- 因为通过 % 来确定位置效率远远不如 & 运算。
- 但前提是 length 必须是 2 的 n 次幂。2^4 = 10000，2^4 - 1 = 1111。
- 如果 length 不是 2 的幂次方，则计算出的索引特别容易相同，可能数组的一些位置永远也不会插入数据，这样就浪费了数组的空间还加大了 hash 冲突。hash 冲突越大，代表数组中的一个链表或者红黑树长度越大，这样会降低 hashmap 的性能。

> 参考资料：
>
> - [HashMap指定数组大小为什么必须是2的n次幂_哇塞大嘴好帅(我爱大嘴网)的博客-CSDN博客_hashmap的大小为什么指定为2的幂次](https://blog.csdn.net/qq_40102411/article/details/124200136)

### 4. HashMap 的原理？红黑树按照什么排序的？

HashMap 的原理：……

红黑树的排序方式：

- 如果 key 实现了 compareable 接口，那可以利用 compare 排序。
- 如果没有实现接口，根据类名排序。
- 类名一样就按照 hashcode 排序。

### **5.** HashMap 和 HashTable？

相同点：都实现了 map、cloneable、serializable 接口。

#### HashTable

- 底层结构：数组 + 链表。
- key、value 都不能为 null。
- 线程安全，修改数据时锁住整个表，效率低。
- 初始 size = 11，扩容 capacity * 2 + 1。

#### HashMap

- 底层结构：数组 + 链表/红黑树。
- key、value 都可以为 null。
- 线程不安全，适用于单线程环境（此时比 HashTable 效率更高）。
- 初始 size = 16，扩容 capacity * 2。
  - 扩容（resize）针对整个 map，每次扩容时，重新计算元素的位置并插入（rehash），然后再判断是否需要扩容。
  - 若原元素重新插入后，map 发生了扩容，却没有新元素插入，则产生了无效扩容。
  - 当元素总数 > 数组的 75% 时，会触发扩容操作。阈值 = 容量 * 加载因子（0.75）。
- 存数据：
  - 对 key 计算 hash 值，找到对应位置。
  - 插入对应位置的链表头。
- 读数据：
  - 找到对应位置。
  - 遍历链表，依次通过 equals 判断目标元素。

> 参考资料：
>
> - [HashMap和Hashtable的区别(绝对经典)_棉花糖one.的博客-CSDN博客_hashmap和hashtable](https://blog.csdn.net/qq_42848910/article/details/107779037)
> - [Hashtable和HashMap的区别_yanwendonge的博客-CSDN博客_hashtable和hashmap的区别](https://blog.csdn.net/yanwendonge/article/details/114527169)

### 6. concurrentHashMap 底层实现？1.8 优化了什么？

底层实现：

- 分段的数组 + 链表。
- 线程安全，每一段数组之间的数据互相不干扰，每一段数组使用不同的锁（锁分离技术），效率更高。
- 对于跨段方法（size、containsValue 等），需要锁住整个表，而不仅是某个段。
- 段内扩容：段内元素数目超过该段数组长度的 75% 时触发扩容，而不会对整个 map 进行扩容。
- 插入前判断是否需要扩容，可以避免无效扩容。
- 默认将表分为 16 个桶，使用 get、put、remove 等操作只需要锁住当前需要用到的桶，能够允许 16 个线程同时执行。

ConcurrentHashMap 1.7：

- 数据结构：
  - Segment 数组由多个 Segment 元素组成。
  - 每个 Segment 元素（是一个 table）由一个 HashEntry 数组和链表组成。
  - ![Image](E:\编程学习\学习笔记\面试笔记\img\Image-16575434883253.png)
- put：
  - 第一次计算 key 的 hash，找到 segment 的位置。若该 segment 元素还未初始化，则通过 CAS 进行初始化。
  - 第二次计算 key 的 hash，找到 hashEntry 的位置。使用 tryLock() 获取锁，如果锁定成功，就将元素插入到该 hashEntry 链表的末尾；如果锁已经被其它线程获取，则会通过自旋尝试获取锁，经过一定次数后若还未获得锁，当前线程就会被挂起，等待被唤醒。
- get：
  - 两次计算 key 的 hash，找到对应的 hashEntry。
  - 遍历该 hashEntry 上的链表，返回匹配的元素，否则返回 null。
- size：
  - 方式一：不加锁，多次计算 count，若结果都相同，就返回，否则不返回结果。
  - 方式二：加锁，对所有 segment 加锁（全局锁），计算 count 并返回。
- 总结：
  - Segment + HashEntry + ReentrantLock。
  - 锁粒度：Segment。

ConcurrentHashMap 1.8：

- 数据结构：
  - 取消 segment 结构，直接使用 HashEntry 数组，将每一个 table 数组元素作为锁，进一步减少了并发冲突的概率。
  - 使用 table 数组 + 单向链表/红黑树（链表长度 > 8 时转化）。
- put：
  - 如果没有 hash 冲突，直接 CAS 插入。
  - 如果存在 hash 冲突，加锁（synchronized）保证线程安全。
  - 判断是都需要转为红黑树、是否需要扩容。
- get
- size
- 总结：
  - HashEntry + 红黑树 + CAS + synchronized。
  - 锁粒度：HashEntry。

> 参考资料：
>
> - [Hashtable和HashMap的区别_yanwendonge的博客-CSDN博客_hashtable和hashmap的区别](https://blog.csdn.net/yanwendonge/article/details/114527169)
> - [concurrenthashmap1.7和1.8的区别 (baidu.com)](https://baijiahao.baidu.com/s?id=1725723554905771171)
> - [ConcurrentHashMap1.7 和 1.8的区别_xuxinyuan8895的博客-CSDN博客_concurrenthashmap1.7和1.8的区别](https://blog.csdn.net/xuxinyuande/article/details/105738873)
> - [Java并发编程总结4——ConcurrentHashMap在jdk1.8中的改进 - everSeeker - 博客园 (cnblogs.com)](https://www.cnblogs.com/everSeeker/p/5601861.html)
> - [谈谈ConcurrentHashMap1.7和1.8的不同实现 - 简书 (jianshu.com)](https://www.jianshu.com/p/e694f1e868ec)
> - [深入分析ConcurrentHashMap1.8的扩容实现 - 简书 (jianshu.com)](https://www.jianshu.com/p/f6730d5784ad)
> - [深入浅出ConcurrentHashMap1.8 - 简书 (jianshu.com)](https://www.jianshu.com/p/c0642afe03e0)
> - [ConcurrentHashMap的红黑树实现分析 - 简书 (jianshu.com)](https://www.jianshu.com/p/23b84ba9a498)

# 算法

## 链表

### 1. K个一组翻转链表

```java
class Solution {
    public ListNode reverseKGroup(ListNode head, int k) {
        ListNode dummy = new ListNode(0);
        dummy.next = head;

        // 记录上一组 k 个节点的末尾
        ListNode last = dummy;

        while (last.next != null) {
            // 找到当前这一组的头和尾
            ListNode start = last.next;
            ListNode end = last;
            int count = k;
            while (end != null && count > 0) {
                end = end.next;
                count--;
            }

            // 最后凑不够 k 个
            if (end == null) {
                break;
            }

            // 能够凑满 k 个
            ListNode pre = end.next;
            end.next = null;
            ListNode cur = start;

            // 反转链表
            while (cur != null) {
                ListNode next = cur.next;
                cur.next = pre;
                pre = cur;
                cur = next;
            }

            // 拼接
            last.next = pre;

            // 更新末尾
            last = start;
        }

        return dummy.next;
    }
```

> 题目链接：[25. K 个一组翻转链表 - 力扣（LeetCode）](https://leetcode.cn/problems/reverse-nodes-in-k-group/)

## 二叉树

### 1. 二叉搜索树转为双向链表，要求额外空间复杂度 O(1)，且不使用全局变量

> 题目链接：[剑指 Offer 36. 二叉搜索树与双向链表 - 力扣（LeetCode）](https://leetcode.cn/problems/er-cha-sou-suo-shu-yu-shuang-xiang-lian-biao-lcof/)
>

### 2. 二叉树的层序遍历

```java
class Solution {
    public List<List<Integer>> levelOrder(TreeNode root) {
        List<List<Integer>> ret = new ArrayList<>();
        
        if (root == null) {
            return ret;
        }

        Queue<TreeNode> queue = new LinkedList<>();
        queue.offer(root);
        
        while (!queue.isEmpty()) {
            // 记录当前层的所有节点
            List<Integer> level = new ArrayList<Integer>();
            // 记录当前层的节点个数
            int currentLevelSize = queue.size();
            for (int i = 1; i <= currentLevelSize; ++i) {
                TreeNode node = queue.poll();
                level.add(node.val);
                if (node.left != null) {
                    queue.offer(node.left);
                }
                if (node.right != null) {
                    queue.offer(node.right);
                }
            }
            ret.add(level);
        }

        return ret;
    }
}
```

> 题目链接：[102. 二叉树的层序遍历 - 力扣（LeetCode）](https://leetcode.cn/problems/binary-tree-level-order-traversal/)

### 3. 二叉树的锯齿形（Z 字形）层序遍历

#### 方法一：栈

```java
class Solution {
    public List<List<Integer>> zigzagLevelOrder(TreeNode root) {
        List<List<Integer>> ans = new ArrayList<>();

        if (root == null) {
            return ans;
        }

        Stack<TreeNode> stack = new Stack<>();
        stack.push(root);

        boolean flag = true;

        while (!stack.isEmpty()) {
            List<Integer> list = new ArrayList<>();

            int len = stack.size();
            Stack<TreeNode> nextLayer = new Stack<>();

            while (len > 0) {
                TreeNode cur = stack.pop();
                list.add(cur.val);

                if (flag) {
                    // 先加入左节点，再加入右节点
                    if (cur.left != null) {
                        nextLayer.push(cur.left);
                    }
                    if (cur.right != null) {
                        nextLayer.push(cur.right);
                    }
                } else {
                    // 先加入右节点，再加入左节点
                    if (cur.right != null) {
                        nextLayer.push(cur.right);
                    }
                    if (cur.left != null) {
                        nextLayer.push(cur.left);
                    }
                }

                len--;
            }

            ans.add(list);
            flag = !flag;
            stack = nextLayer;
        }

        return ans;
    }
}
```

#### 方法二：双端队列

```java
class Solution {
	public List<List<Integer>> zigzagLevelOrder(TreeNode root) {
        List<List<Integer>> ans = new LinkedList<List<Integer>>();
        
        if (root == null) {
            return ans;
        }

        Queue<TreeNode> nodeQueue = new ArrayDeque<TreeNode>();
        nodeQueue.offer(root);
        
        boolean isOrderLeft = true;

        while (!nodeQueue.isEmpty()) {
            Deque<Integer> levelList = new LinkedList<Integer>();
            
            int size = nodeQueue.size();
            for (int i = 0; i < size; ++i) {
                TreeNode curNode = nodeQueue.poll();
                if (isOrderLeft) {
                    levelList.offerLast(curNode.val);
                } else {
                    levelList.offerFirst(curNode.val);
                }
                if (curNode.left != null) {
                    nodeQueue.offer(curNode.left);
                }
                if (curNode.right != null) {
                    nodeQueue.offer(curNode.right);
                }
            }
            
            ans.add(new LinkedList<Integer>(levelList));
            isOrderLeft = !isOrderLeft;
        }

        return ans;
    }
}
```

> 题目链接：[103. 二叉树的锯齿形层序遍历 - 力扣（LeetCode）](https://leetcode.cn/problems/binary-tree-zigzag-level-order-traversal/)

### 4. 二叉树的最近公共祖先

```java
class Solution {
    public TreeNode lowestCommonAncestor(TreeNode root, TreeNode p, TreeNode q) {
        if (root == null || root == p || root == q) {
            return root;
        }

        TreeNode left = lowestCommonAncestor(root.left, p, q);
        TreeNode right = lowestCommonAncestor(root.right, p, q);

        if (left != null && right != null) {
            return root;
        } else if (left == null && right != null) {
            return right;
        } else if(left != null && right == null) {
            return left;
        }
            
        return null;
    }
}
```

> 题目链接：[236. 二叉树的最近公共祖先 - 力扣（LeetCode）](https://leetcode.cn/problems/lowest-common-ancestor-of-a-binary-tree/)

### 5. 二叉搜索树的最近公共祖先

```java
class Solution {
    public TreeNode lowestCommonAncestor(TreeNode root, TreeNode p, TreeNode q) {

        if (root.val > p.val && root.val > q.val) {
            return lowestCommonAncestor(root.left, p, q);
        } else if (root.val < p.val && root.val < q.val) {
            return lowestCommonAncestor(root.right, p, q);
        }

        return root;
    }
}
```

> 题目链接：[235. 二叉搜索树的最近公共祖先 - 力扣（LeetCode）](https://leetcode.cn/problems/lowest-common-ancestor-of-a-binary-search-tree/)

## 排序算法

### 1. 冒泡、快排、归并的最坏时间复杂度和平均时间复杂度？稳定性的含义？是否稳定？

#### 冒泡排序

- 最好情况：所有元素已经有序，只需直接遍历一遍，最好时间复杂度：O(N)。
- 最坏情况：所有元素逆序排列，每一次循环的复杂度都是 O(N)，最坏时间复杂度：O(N²)。
- 平均时间复杂度：O(N²)。
- 稳定性：是。

原本的代码的时间复杂度确实应该是 O(N²)，但算法可以改进，使最佳情况时为O(n)。改进后的代码为：

```java
public void bubbleSort(int arr[]) {
    boolean didSwap;
    for(int i = 0, len = arr.length; i < len - 1; i++) {
        didSwap = false;
        for(int j = 0; j < len - i - 1; j++) {
            if(arr[j + 1] < arr[j]) {
                swap(arr, j, j + 1);
                didSwap = true;
            }
        }
        // 若在某一轮里没有发生交换，说明已经有序，提前跳出循环
        if(didSwap == false)
            return;
    }    
}
```

#### 快速排序

- 最好情况：每次都划分得很均匀，即每次都是对半分，最好时间复杂度：O(N*logN)。
- 最坏情况：原数组已经有序，每一次递归只能位移（确定）一个数字，即每一次划分得到的子序列只比划分前的序列少一个元素，最坏时间复杂度：O(N²)。

![Image](E:\编程学习\学习笔记\面试笔记\img\Image-16575407361842.png)

- 平均时间复杂度：O(N*logN)。
- 稳定性：否。

#### 归并排序

- 归并排序无论在什么情况下都需要将数组拆分 log(n) 次，并且每一次拆分后进行归并的时间复杂度都是 O(N)，因此最好和最坏的时间复杂度都是：O(N*logN)。*
- 平均时间复杂度：O(N*logN)。
- 稳定性：是。

#### 稳定性

多个某一属性具有相同值的元素（对象），经过排序后它们的相对次序不变。

常见的具有稳定性的排序算法：

- 冒泡排序
- 插入排序
- 归并排序

对于上面的这些算法，并不是说他们本来就是稳定的，而是我们可以把它实现成稳定的，主要取决于在判断相等元素时，是否进行交换。

- 若前面的元素 < 后面的元素就交换，那么就是稳定的。
- 若前面的元素 <= 后面的元素就交换，那么就不是稳定的。

#### 总结

![排序算法总结](E:\编程学习\学习笔记\面试笔记\img\排序算法总结.png)

归并、快排、堆排比较：

- 追求稳定性：归并。
- 追求速度快：快排（虽然这三种算法的时间复杂度都相同，但是快排的常数时间更小）。
- 追求空间小：堆排。

归并排序：二分、递归、归并。

快速排序：随机、分层、递归。

### 2. 数组中的第 K 个最大元素

#### 方法一：快速排序

在分解的过程当中，我们会对子数组进行划分，如果划分得到的 q（左右子区间的中点下标）正好就是我们需要的下标，就直接返回 a[q]；否则，如果 q 比目标下标小，就递归右子区间，否则递归左子区间。这样就可以把原来递归两个区间变成只递归一个区间，提高了时间效率。这就是**「快速选择」**算法。

- 时间复杂度：O(N)
- 空间复杂度：O(logN)

```java
class Solution {
    public int findKthLargest(int[] nums, int k) {
        return quickSort(nums, 0, nums.length - 1, nums.length - k);
    }

    public int quickSort(int[] arr, int start, int end, int target) {
        // 随机化
        swap(arr, start + (int) (Math.random() * (end - start + 1)), end);

        // 分层
        int pos = partition(arr, start, end);

        // 递归
        if (pos < target) {
            // 递归右子区间
            return quickSort(arr, pos + 1, end, target);
        } else if (pos > target) {
            // 递归左子区间
            return quickSort(arr, start, pos - 1, target);
        }

        // pos == target
        return arr[pos];
    }

    public int partition(int[] arr, int start, int end) {
        int ref = arr[end];

        int less = start - 1;
        int more = end;
        int i = start;

        while (i < more) {
            if (arr[i] <= ref) {
                swap(arr, ++less, i++);
            } else {
                swap(arr, --more, i);
            }
        }

        swap(arr, i, end);

        return i;
    }

    public void swap(int[] arr, int i, int j) {
        int tmp = arr[i];
        arr[i] = arr[j];
        arr[j] = tmp;
    }
}
```

#### 方法二：堆排序

建立一个大根堆，做 k - 1 次删除操作后堆顶元素就是我们要找的答案。

- 时间复杂度：O(NlogN)，建堆的时间代价是 O(N)，删除的总代价是 O(KlogN)，因为 k < n，故渐进时间复杂为 O(NlogN)？？？
- 空间复杂度：O(logN)

```java
class Solution {
    public int findKthLargest(int[] nums, int k) {
        int heapSize = nums.length;
        
        // 构建大根堆
        buildMaxHeap(nums, heapSize);
        
        // 弹出 k-1 次
        for (int i = nums.length - 1; i >= nums.length - k + 1; --i) {
            swap(nums, 0, i);
            heapSize--;
            // 调整堆依然为大根堆
            maxHeapify(nums, 0, heapSize);
        }
        
        // 返回堆顶元素
        return nums[0];
    }

    // 从下往上建堆
    // 先将节点全部加入数组，再从末尾的数开始，依次进行 heapify，即依次使从最底层到顶层的子树满足大根堆，时间复杂度：O(N)。
    public void buildMaxHeap(int[] a, int heapSize) {
        // 最底层可以跳过，直接从倒数第二层开始
        for (int i = heapSize / 2; i >= 0; i--) {
            maxHeapify(a, i, heapSize);
        } 
    }

    // 下沉
    // 时间复杂度：O(logN)
    public void maxHeapify(int[] a, int i, int heapSize) {
        int l = i * 2 + 1, r = i * 2 + 2, largest = i;
        if (l < heapSize && a[l] > a[largest]) {
            largest = l;
        } 
        if (r < heapSize && a[r] > a[largest]) {
            largest = r;
        }
        if (largest != i) {
            swap(a, i, largest);
            maxHeapify(a, largest, heapSize);
        }
    }

    public void swap(int[] a, int i, int j) {
        int temp = a[i];
        a[i] = a[j];
        a[j] = temp;
    }
}
```
> 题目链接：[215. 数组中的第K个最大元素 - 力扣（LeetCode）](https://leetcode.cn/problems/kth-largest-element-in-an-array/)

## 缓存

### 1. LRU 缓存

> 题目链接：[146. LRU 缓存 - 力扣（LeetCode）](https://leetcode.cn/problems/lru-cache/)
>

### 2. LFU 缓存

> 题目链接：[460. LFU 缓存 - 力扣（LeetCode）](https://leetcode.cn/problems/lfu-cache/)

# MySQL

## 事务

### 1. 数据库事务？什么是幻读？事务的隔离级别？

#### 事务

- 含义：一系列操作，要么全部执行，要么都不执行。
- 特性：ACID
  - 原子性（Atomicity）：事务是应用中不可再分的最小的逻辑执行体。使用事务对数据进行修改的操作序列，要么全部执行，要么全不执行。
  - 一致性（Consistency）：指事务执行的结果必须使数据库从一个一致性状态，变到另一个一致性状态。例如：在转账时，只有保证转出和转入的金额一致才能构成事务。
  - 隔离性（Isolation）：指各个事务的执行互不干扰，任意一个事务的内部操作对其他并发的事务，都是隔离的。
  - 持久性（Durability）：指事务一旦提交，对数据所做的任何改变，都要记录到永久存储器中，通常是保存进物理数据库，即使数据库出现故障，提交的数据也应该能够恢复。但如果是由于外部原因导致的数据库故障，如硬盘被损坏，那么之前提交的数据则有可能会丢失。

**只有保证了事务的持久性、原子性、隔离性之后，一致性才能得到保障。也就是说 A、I、D 是手段，C 才是目的！**

#### 并发问题

- 脏读：
  - 当一个事务正在访问数据并且对数据进行了修改，而这种修改还没有提交到数据库中，这时另外一个事务也访问了这个数据，然后使用了这个数据。
  - 因为这个数据是还没有提交的数据，那么另外一个事务读到的这个数据是“脏数据”，依据“脏数据”所做的操作可能是不正确的。

![image-20220711111558993](E:\编程学习\学习笔记\面试笔记\img\image-20220711111558993.png)

- 丢失修改：
  - 指在一个事务读取一个数据时，另外一个事务也访问了该数据，那么在第一个事务中修改了这个数据后，第二个事务也修改了这个数据。这样第一个事务内的修改结果就被丢失，因此称为丢失修改。
  - 例如：事务 1 读取某表中的数据 A=20，事务 2 也读取 A=20，事务 1 修改 A=A-1，事务 2 也修改 A=A-1，最终结果 A=19，事务 1 的修改被丢失。

- 不可重复读：
  - 指在一个事务内多次读同一数据。
  - 在这个事务还没有结束时，另一个事务也访问该数据。那么，在第一个事务中的两次读数据之间，由于第二个事务的修改导致第一个事务两次读取的数据可能不太一样。这就发生了在一个事务内两次读到的数据是不一样的情况，因此称为不可重复读。

![image-20220711111741252](E:\编程学习\学习笔记\面试笔记\img\image-20220711111741252.png)

- 幻读：
  - 幻读与不可重复读类似。它发生在一个事务（T1）读取了几行数据，接着另一个并发事务（T2）插入了一些数据时。
  - 在随后的查询中，第一个事务（T1）就会发现多了一些原本不存在的记录，就好像发生了幻觉一样，所以称为幻读。

![image-20220711111824872](E:\编程学习\学习笔记\面试笔记\img\image-20220711111824872.png)

**不可重复读和幻读有什么区别呢？**

- 不可重复读和幻读区别：不可重复读的重点是修改或者删除，幻读的重点在于新增。
- 幻读其实可以看作是不可重复读的一种特殊情况，单独区分出幻读的原因主要是解决幻读和不可重复读的方案不一样。
  - 解决不可重复读的问题只需锁住满足条件的行。
  - 解决幻读需要锁表，或者使用间隙锁。


举例：

- 执行 `delete` 和 `update` 操作的时候，可以直接对记录加锁，保证事务安全。
- 而执行 `insert` 操作的时候，由于记录锁（Record Lock）只能锁住已经存在的记录，为了避免插入新记录，需要依赖间隙锁（Gap Lock）。也就是说执行 `insert` 操作的时候需要依赖 Next-Key Lock（Record Lock + Gap Lock） 进行加锁来保证不出现幻读。

#### 隔离级别

隔离级别越低，越能支持高并发的数据库操作。

隔离级别：

- **读不提交**：最低的隔离级别，允许读取尚未提交的数据变更，可能会导致脏读、幻读或不可重复读。
- **读已提交**：允许读取并发事务已经提交的数据，可以阻止脏读，但是幻读或不可重复读仍有可能发生。
- **可重复读**：对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，可以阻止脏读和不可重复读，但幻读仍有可能发生。
- **序列化**：最高的隔离级别，完全服从 ACID 的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，该级别可以防止脏读、不可重复读以及幻读。

![image-20220711112523770](E:\编程学习\学习笔记\面试笔记\img\image-20220711112523770.png)

**MySQL 的隔离级别是基于锁实现的吗？**

- SERIALIZABLE 隔离级别，是通过锁来实现的。
- 除了 SERIALIZABLE 隔离级别，其他的隔离级别都是基于 MVCC 实现，不过也可能会用到锁机制。比如 REPEATABLE-READ 在当前读情况下需要使用加锁读来保证不会出现幻读。

**MySQL InnoDB 存储引擎的默认隔离级别是 repeatable read。**

```sql
-- 查看默认的事务隔离级别
select @@transaction_isolation;

-- 设置事务的隔离级别（设置当前会话的隔离级别）
set session transaction isolation level read uncommitted; 
set session transaction isolation level read committed;  
set session transaction isolation level repeatable read;  
set session transaction isolation level serializable; 
```

#### 隐式、显式事务

隐式事务：

- MySQL 中的事务默认都是隐式事务，即执行 insert、delete、update 的时候，数据库会自动开启事务、提交事务或回滚事务。
- 执行：mysql> show variables like 'autocommit'，若结果为 ON 则表示开启了自动提交。

显式事务：

- 需要手动开启、提交或回滚事务。
- 设置不自动提交事务：set autocommit = 0。

#### 补充

- 不能在两个事务中交叉更新同一条记录。第一个事务更新了某条记录之后，就会给这条记录加锁，另一个事务需要等待第一个事务提交以后，把锁释放了，才能继续操作该条数据。
- 事务在执行过程中，只有第一次真正修改记录时（insert、delete、update），才会被分配一个单独的事务 id，这个事务 id 是递增的。
- 在 repeatable read 隔离级别下，两个事务中的一个事务新增数据并提交后，该条数据虽然对另一个事务不可见，但是可以通过 update 修改。
  - 因为 MySQL 规定，修改操作是“当前读”，只要某条记录上没有锁就可以修改。
  - 这里的不可见指的是用 select 去读，select 查询是“快照读”，读的是版本链里的内容。
  - “当前读”会对数据加锁，可以看到其它事务的修改（读到的是数据最新的版本），属于“当前读”的操作有：select ... for update、select ... lock in share mode、insert、update、delete。

### 2. 乐观锁和悲观锁的区别？

- 乐观锁：会乐观地假定大概率不会发生并发更新冲突，访问、处理数据过程中不加锁，只在更新数据时再根据版本号或时间戳判断是否有冲突，有则处理，无则提交事务，即 CAS 机制。
- 悲观锁：会悲观地假定大概率会发生并发更新冲突，访问、处理数据前就加排他锁，在整个数据处理过程中锁定数据，事务提交或回滚后才释放锁。

### 3. MVCC？

MVCC 的含义：

- multi-version concurrency control：多版本并发控制。
- 主要针对 read commited、repeatable read 这两种隔离级别。

版本链：

- 对于 innodb 存储引擎的表来说，它的聚簇索引记录中都包含两个必要的隐藏列：
  - 事务 id
  - 指向上一个版本的指针
- 对于 insert 操作，第一次创建这一条数据，不存在更早的版本。
- 对于 update 操作，每一次更新后都会生成一个新的版本。

read view：

- 工作原理：
  - 每一次生成 read view，会将当前仍然活跃的（未提交的）事务的 id 加入到 read view 中。
  - 特殊情况：
    - 如果要访问的版本（事务 id）比 read view 中最小的版本都要小，说明在生成当前 read view 前，该事务已经提交，因此可以直接返回该条数据。
    - 如果要访问的版本（事务 id）比 read view 中最大的版本都要大，说明生成该版本的事务在生成该 read view 之后才生成。
  - 在进行 select 时，会从要查询的数据的版本链的最新的版本开始往下遍历，直到找到一个事务 id 在当前 read view 范围内，并且在 read view 中不存在（已提交）的版本，返回该版本的数据。
- 对于 read commited 模式，在开启一个事务后，每一次 select 查询之前都会生成一个新的 read view。
- 对于 repeatable read 模式，在开启一个事务后，只在第一次进行 select 查询时生成一个 read view，一直到最后该事务提交之前，都使用同一个 read view。

> 参考资料：
>
> - [MVCC到底是什么？这一篇博客就够啦_flying$的博客-CSDN博客_mvcc](https://blog.csdn.net/flying_hengfei/article/details/106965517?ops_request_misc=&request_id=&biz_id=102&utm_term=MVCC&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-1-106965517.nonecase&spm=1018.2226.3001.4187)

### 4. InnoDB 锁机制？

![image-20220710212225577](E:\编程学习\学习笔记\面试笔记\img\image-20220710212225577.png)

#### 乐观锁与悲观锁

- 乐观锁：会乐观地假定大概率不会发生并发更新冲突，访问、处理数据过程中不加锁，只在更新数据时再根据版本号或时间戳判断是否有冲突，有则处理，无则提交事务，即 CAS 机制。
- 悲观锁：会悲观地假定大概率会发生并发更新冲突，访问、处理数据前就加排他锁，在整个数据处理过程中锁定数据，事务提交或回滚后才释放锁。

#### 表锁与行锁

MyISAM 仅仅支持表级锁（table-level locking），一锁就锁整张表，这在并发写的情况下性能非常差。

InnoDB 不光支持表级锁（table-level locking），还支持行级锁（row-level locking），默认为行级锁。行级锁的粒度更小，仅对相关的记录上锁即可（对一行或者多行记录加锁），所以对于并发写入操作来说， InnoDB 的性能更高。

表级锁和行级锁对比 ：

- **表级锁：**MySQL 中锁定粒度最大的一种锁，是针对非索引字段加的锁，对当前操作的整张表加锁，实现简单，资源消耗也比较少，加锁快，不会出现死锁。其锁定粒度最大，触发锁冲突的概率最高，并发度最低，MyISAM 和 InnoDB 引擎都支持表级锁。
- **行级锁：**MySQL 中锁定粒度最小的一种锁，是针对索引字段加的锁，只针对当前操作的行记录进行加锁。 行级锁能大大减少数据库操作的冲突。其加锁粒度最小，并发度高，但加锁的开销也最大，加锁慢，会出现死锁。

InnoDB 支持多种锁粒度，默认使用行锁：

- 锁粒度最小
- 锁冲突发生的概率最低
- 支持的并发度最高
- 系统消耗成本相对较高

InnoDB 的行锁是针对索引字段加的锁，表级锁是针对非索引字段加的锁。当我们执行 `UPDATE`、`DELETE` 语句时，如果 `WHERE` 条件中字段没有命中唯一索引或者索引失效的话，就会导致扫描全表对表中的所有行记录进行加锁。这个在我们日常工作开发中经常会遇到，一定要多多注意！！！

不过，很多时候即使用了索引也有可能会走全表扫描，这是因为 MySQL 优化器的原因。

#### 共享锁与排他锁

不论是表级锁还是行级锁，都存在共享锁（Share Lock，S 锁）和排他锁（Exclusive Lock，X 锁）这两类。

- **共享锁（S 锁）**：又称读锁，事务在读取记录的时候获取共享锁，允许多个事务同时获取（锁兼容）。
- **排他锁（X 锁）**：又称写锁/独占锁，事务在修改记录的时候获取排他锁，不允许多个事务同时获取。如果一个记录已经被加了排他锁，那其他事务不能再对这条事务加任何类型的锁（锁不兼容）。

![image-20220710213815685](%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0%20-%20%E7%94%B3%E6%9D%89%E6%9D%89.assets/image-20220710213815685.png)

排他锁与任何的锁都不兼容，共享锁仅和共享锁兼容。

![image-20220822112410969](%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0%20-%20%E7%94%B3%E6%9D%89%E6%9D%89.assets/image-20220822112410969.png)

由于 MVCC 的存在，对于一般的 `SELECT` 语句，InnoDB 不会加任何锁。不过， 你可以通过以下语句显式加共享锁或排他锁。

```sql
# 共享锁
SELECT ... LOCK IN SHARE MODE;
# 排他锁
SELECT ... FOR UPDATE;
```

注意：

- 除了显式加锁的情况，其他情况下的加锁与解锁都无需人工干预。
- InnoDB 所有的行锁算法都是基于索引实现的，锁定的也都是索引或索引区间。

#### 意向锁

如果需要用到表锁的话，如何判断表中的记录没有行锁呢？一行一行遍历肯定是不行，性能太差。我们需要用到意向锁来快速判断是否可以对某个表使用表锁。

意向锁是表级锁，共有两种：

- **意向共享锁（Intention Shared Lock，IS 锁）**：事务有意向对表中的某些加共享锁（S 锁），加共享锁前必须先取得该表的 IS 锁。
- **意向排他锁（Intention Exclusive Lock，IX 锁）**：事务有意向对表中的某些记录加排他锁（X 锁），加排他锁之前必须先取得该表的 IX 锁。

意向锁是由数据引擎自己维护的，用户无法手动操作意向锁，在为数据行加共享 / 排他锁之前，InooDB 会先获取该数据行所在数据表的对应意向锁。

意向锁之间是互相兼容的。

![image-20220822112440403](%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0%20-%20%E7%94%B3%E6%9D%89%E6%9D%89.assets/image-20220822112440403.png)

意向锁与共享锁、排他锁互斥（这里指的是表级别的共享锁和排他锁，意向锁不会与行级的共享锁和排他锁互斥）。

![image-20220822112530605](%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0%20-%20%E7%94%B3%E6%9D%89%E6%9D%89.assets/image-20220822112530605.png)

#### 当前读与快照读

InnoDB 的默认隔离级别 RR（可重读）是可以解决幻读问题发生的，主要有下面两种情况：

- **快照读**（一致性非锁定读）：由 MVCC 机制来保证不出现不可重复读。
- **当前读**（一致性锁定读）： 使用 Next-Key Lock 进行加锁来保证不出现幻读。

当前读：

- 即加锁读，读取记录的最新版本，会加锁保证其他并发事务不能修改当前记录，直至获取锁的事务释放锁。
- 使用当前读的操作主要包括：显式加锁的读操作、插入/更新/删除等写操作。

```sql
# 读操作
# 加共享锁
select * from table where ? lock in share mode;
# 加排它锁
select * from table where ? for update;

# 增删改操作
insert into table values (…);
update table set ? where ?;
delete from table where ?;
```

快照读：

- 即不加锁读，读取记录的快照版本而非最新版本，通过 MVCC 实现。
- 快照读的情况下，如果读取的记录正在执行 UPDATE/DELETE 操作，读取操作不会因此去等待记录上 X 锁的释放，而是会去读取行的一个快照。
- 只有在事务隔离级别为 RC（读已提交）和 RR（可重复读）下，InnoDB 才会使用快照读。
  - 在 RC 级别下，总是读取被锁定行的最新一份快照数据。
  - 在 RR 级别下，总是读取本事务开始时的行数据版本。

- InnoDB 默认的 RR 事务隔离级别下，不显式加『lock in share mode』与『for update』的『select』操作都属于快照读，保证事务执行过程中只有第一次读之前提交的修改和自己的修改可见，其他的均不可见。
- 快照读比较适合对于数据一致性要求不是特别高且追求极致性能的业务场景。

#### MVCC

含义：多版本并发控制

作用：读不加任何锁，读写不冲突，对于读操作多于写操作的应用，极大的增加了系统的并发性能。

……

#### 锁算法

InnoDB 所有的行锁算法都是基于索引实现的，锁定的也都是索引或索引区间。

MySQL InnoDB 支持三种行锁定方式：

- **记录锁（Record Lock）**：也被称为记录锁，属于单个行记录上的锁。
- **间隙锁（Gap Lock）**：锁定一个范围，不包括记录本身。
- **临键锁（Next-key Lock）**：Record Lock + Gap Lock，锁定一个范围，包含记录本身。记录锁只能锁住已经存在的记录，为了避免插入新记录，需要依赖间隙锁。

InnoDB 对于行的查询加锁使用的是 next-key locking 这种算法，一定程度上解决了幻读的问题。

> 参考资料：
>
> - [MySQL InnoDB锁机制全面解析分享 - SegmentFault 思否](https://segmentfault.com/a/1190000014133576)

## 索引

### 1. 什么是索引？b+树的数据结构？回表查询？

#### 索引基本概念

索引（index）是指一类特殊的数据结构，它由索引键和指向数据文件中相应记录的记录指针（或记录号）组成。

索引键是记录的一个或一组数据项。索引用来提高数据查询效率，但同时引入存储代价和更新代价。

在关系数据库中，索引是一种单独的、物理的对数据库表中一列或多列的值进行排序的一种存储结构，它是某个表中一列或若干列值的集合和相应的指向表中物理标识这些值的数据页的逻辑指针清单。索引的作用相当于图书的目录，可以根据目录中的页码快速找到所需的内容。

索引是为了加速对表中数据行的检索而创建的一种分散的存储结构。索引是针对表而建立的，它是由数据页面以外的索引页面组成的，每个索引页面中的行都会含有逻辑指针，以便加速检索物理数据。

在数据库关系图中，可以在选定表的“索引键”属性页中创建、编辑或删除每个索引类型。当保存索引所附加到的表，或保存该表所在的关系图时，索引将保存在数据库中。

#### 索引的作用

在数据库系统中建立索引主要有以下作用：

- 快速取数据
- 保证数据记录的唯一性
- 实现表与表之间的参照完整性
- 在使用 order by、group by 子句进行数据检索时，利用索引可以减少排序和分组的时间

#### 索引的优缺点

优点：

- 加快数据的检索速度
- 创建唯一性索引，保证数据库表中每一行数据的唯一性
- 加速表和表之间的连接
- 在使用分组和排序子句进行数据检索时，可以显著减少查询中分组和排序的时间

缺点：

- 索引需要占物理空间
- 当对表中的数据进行增加、删除和修改的时候，索引也要动态的维护，降低了数据的维护速度

#### 索引的分类

##### 1. 普通索引

最基本的索引类型，没有唯一性之类的限制。

普通索引可以通过以下几种方式创建：

- 创建索引，例如：

  ```sql
  CREATE INDEX 索引的名字 ON tablename (列的列表)；
  ```

- 修改表，例如：

  ```sql
  ALTER TABLE tablename ADD INDEX 索引的名字 (列的列表)；
  ```

- 创建表的时候指定索引，例如：

  ```SQL
  CREATE TABLE tablename ([...], INDEX 索引的名字 (列的列表))；
  ```

##### 2. 唯一索引

唯一索引是不允许其中任何两行具有相同索引值的索引。

当现有数据中存在重复的键值时，大多数数据库不允许将新创建的唯一索引与表一起保存。数据库还可能防止添加将在表中创建重复键值的新数据。例如，如果在 employee 表中职员的姓 (lname) 上创建了唯一索引，则任何两个员工都不能同姓。

对某个列建立 UNIQUE 索引后，插入新记录时，数据库管理系统会自动检查新纪录在该列上是否取了重复值，在 CREATE TABLE 命令中的 UNIQE 约束将隐式创建 UNIQUE 索引。

创建唯一索引的几种方式：

- 创建索引，例如：

  ```sql
  CREATE UNIQUE INDEX 索引的名字 ON tablename (列的列表)；
  ```

  修改表，例如：

  ```sql
  ALTER TABLE tablename ADD UNIQUE 索引的名字 (列的列表)；
  ```

- 创建表的时候指定索引，例如：

  ```sql
  CREATE TABLE tablename ([...], UNIQUE 索引的名字 (列的列表))；
  ```

##### 3. 主键索引

简称为主索引，数据库表中一列或列组合（字段）的值唯一标识表中的每一行。该列称为表的主键。

在数据库关系图中为表定义主键将自动创建主键索引，主键索引是唯一索引的特定类型。该索引要求主键中的每个值都唯一。当在查询中使用主键索引时，它还允许对数据的快速访问。

尽管唯一索引有助于定位信息，但为获得最佳性能结果，建议改用主键索引。

##### 4. 候选索引

与主索引一样要求字段值的唯一性，并决定了处理记录的顺序。在数据库和自由表中，可以为每个表建立多个候选索引。

##### 5. 聚集索引

也称为聚簇索引，在聚集索引中，表中行的物理顺序与键值的逻辑顺序（索引）相同。一个表只能包含一个聚集索引，即如果存在聚集索引，就不能再指定 CLUSTERED 关键字。

若索引不是聚集索引，则表中行的物理顺序与键值的逻辑顺序不匹配。与非聚集索引相比，聚集索引通常提供更快的数据访问速度。聚集索引更适用于很少对基表进行增删改操作的情况。

如果在表中创建了主键约束，SQL Server 将自动为其产生唯一性约束。在创建主键约束时，指定了 CLUSTERED 关键字或干脆没有指定该关键字，SQL Sever 将会自动为表生成唯一聚集索引。

##### **6. 非聚集索引**

也叫非聚簇索引，在非聚集索引中，数据库表中记录的物理顺序与索引顺序可以不相同。一个表中只能有一个聚集索引，但表中的每一列都可以有自己的非聚集索引。

如果在表中创建了主键约束，SQL Server 将自动为其产生唯一性约束。在创建主键约束时，如果指定 CLUSTERED 关键字，则将为表产生唯一聚集索引。

举例（方便理解）：

- 你翻到新华字典的汉字“爬”那一页就是 P 开头的部分，这就是物理存储顺序（聚簇索引）。
- 而不用你到目录，找到汉字“爬”所在的页码，然后根据页码找到这个字（非聚簇索引）。

#### 操纵索引

##### **1. 维护和使用**

DBMS 自动完成维护和自动选择是否使用索引以及使用哪些索引。

##### 2. 创建索引

SQL 语言使用 CREATE INDEX 语句建立索引，其一般格式是：

```sql
CREATE [UNIQUE] [CLUSTERED | NONCLUSTERED] INDEX <索引名> ON <表名> (<列名>[ASC | DESC] , <列名>[ASC|DESC] ... );

-- 示例
alter table staffs add index idx_nap(name, age, pos);
-- 展示当前表中已经添加的索引
show index from staffs;
```

说明：与表一样，索引也需要有唯一的名字，且基于一个表来建立，可以根据表中的一列或者多列，当列的顺序都是升序默认可不必标出，当属性列有按照降序排列的，所有属性的升序降序都不要标明。

- UNIQUE：建立唯一索引
- CLUSTERED：建立聚集索引
- NONCLUSTERED：建立非聚集索引
- ASC：索引升序排序
- DESC：索引降序排序

##### 3. 修改索引

对于已经建立的索引，如果需要对其重新命名，可以使用 ALTER INDEX 语句，其一般格式为：

```sql
ALTER INDEX <旧引索名字> RENAME TO <新引索名>;
```

##### 4. 删除索引

当某个时期基本表中数据更新频繁或者某个索引不再需要时，需要删除部分索引。SQL 语言使用 DROP INDEX 语句删除索引，其一般格式是：

```sql
DROP INDEX <索引名>;
```

删除索引时，DBMS 不仅在物理删除相关的索引数据，也会从数据字典删除有关该索引的描述。

#### 索引总结

- 含义：索引是为了加速对表中数据行的检索而创建的一种分散的存储结构。
- 优点：加速查询。
- 缺点：需要占用额外的内存；随着表数据的增删改，索引需要动态维护，占用资源。
- 分类：普通索引、唯一索引、主键索引、聚簇索引（表中数据行的存储顺序与索引的顺序一致，如：字典的页码与当前页的内容）、非聚簇索引（...不一致，如：字典开头的目录）。
- 组织方式：最常见的是树形，查询速度快，动态增删改方便。

并非所有的数据库都以相同的方式使用索引。作为通用规则，只有当经常查询索引列中的数据时，才需要在表上创建索引。索引占用磁盘空间，并且降低添加、删除和更新行的速度。如果应用程序非常频繁地更新数据或磁盘空间有限，则可能需要限制索引的数量。在表较大时再建立索引，表中的数据越多，索引的优越性越明显。

可以基于数据库表中的单列或多列创建索引。多列索引使您可以区分其中一列可能有相同值的行。如果经常同时搜索两列或多列或按两列或多列排序时，索引也很有帮助。例如，如果经常在同一查询中为姓和名两列设置判据，那么在这两列上创建多列索引将很有意义。

确定索引的有效性：

- 检查查询的 WHERE 和 JOIN 子句。在任一子句中包括的每一列都是索引可以选择的对象。
- 对新索引进行试验以检查它对运行查询性能的影响。
- 考虑已在表上创建的索引数量。最好避免在单个表上有很多索引。
- 检查已在表上创建的索引的定义。最好避免包含共享列的重叠索引。
- 检查某列中唯一数据值的数量，并将该数量与表中的行数进行比较。比较的结果就是该列的可选择性，这有助于确定该列是否适合建立索引，如果适合，确定索引的类型。

> 参考资料：
>
> - [索引 - 快懂百科 (baike.com)](https://www.baike.com/wikiid/5527083834876297305?prd=result_list&view_id=2dxggh2qxjgg00)

#### b+ 树

b+ 树结构：

- MySQL 的 InnoDB 是通过 b+ 树结构对主键创建索引，然后叶子节点中存储记录，如果没有主键，那么会选择唯一键，如果没有唯一键，那么会生成一个 6 位的 row_id 来作为主键。
- 非叶子节点只存储 key，叶子节点存储 key 和 data。
- 除了从根节点出发的指针，叶子节点之间还有互相指向的指针（顺序访问指针：方便实现区间查找）。

回表查询：

- 如果创建索引的是其它字段，那么叶子节点中存储的是该记录的主键，然后再通过主键索引找到对应的记录，叫做回表。
- 覆盖索引：要查询的字段已经包含在叶子节点中，不用再进行回表查询。

> 参考资料：
>
> - [数据库两大神器【索引和锁】 - 掘金 (juejin.cn)](https://juejin.cn/post/6844903645125820424#heading-2)[CodingLabs - MySQL索引背后的数据结构及算法原理](http://blog.codinglabs.org/articles/theory-of-mysql-index.html)

### 2. 数据库索引类型？聚簇索引和辅助索引的区别？

索引类型：

- 普通索引
- 唯一索引
- 主键索引
- 聚簇索引
- 非聚簇索引（辅助索引就是非聚簇索引）

区别：

- 聚簇索引：叶子节点存储的是完整的每一个数据行。
- 非聚簇索引：key 为非主键的某一字段（列），value 为主键。

> 参考资料：
>
> - [MySQL聚集索引与辅助索引的区别 - 楼兰胡杨 - 博客园 (cnblogs.com)](https://www.cnblogs.com/east7/p/14775017.html)

### 3. 索引查询？联合索引的最左匹配原则？

索引查询：

- 全列匹配
- 最左前缀匹配：按顺序匹配索引的字段，只有查询时 where 后的字段顺序与索引中的字段顺序一致的部分才会使用索引，剩余的部分会使用 where 进行过滤。
- ……

> 参考资料：
>
> - [CodingLabs - MySQL索引背后的数据结构及算法原理](http://blog.codinglabs.org/articles/theory-of-mysql-index.html)

### 4. MySQL 为什么要使用 b+ 树？

一般来说，索引本身也很大，不可能全部存储在内存中，因此索引往往以索引文件的形式存储在磁盘上。这样的话，索引查找过程中就要产生磁盘 I/O 消耗，相对于内存存取，I/O 存取的消耗要高几个数量级，所以评价一个数据结构作为索引的优劣最重要的指标就是在查找过程中磁盘 I/O 操作次数的渐进复杂度。

磁盘预读：

- 原因：磁盘的存取速度远远慢于主存。
- 含义：每次都顺序读取一定长度的数据放入内存。
- 局部性原理：程序运行期间用到的数据通常都比较集中。
- 目的：可以提高 I/O 的效率。
- 预读的长度：一般为页的整倍数。
  - 页是计算机管理存储器的逻辑块，硬件及操作系统往往将主存和磁盘存储区分割为连续的大小相等的块，每个存储块称为一页（在许多操作系统中，页的大小通常为 4k），主存和磁盘以页为单位交换数据。
  - 当程序要读取的数据不在主存中时，会触发一个缺页异常，此时系统会向磁盘发出读盘信号，磁盘会找到数据的起始位置并向后连续读取一页或几页载入内存中，然后异常返回，程序继续运行。

数据库系统的设计者巧妙利用了磁盘预读原理，将一个节点的大小设为等于一个页，这样每个节点只需要一次 I/O 就可以完全载入。

b+ 树非叶子节点不存储数据，树的深度浅，I/O 查询的次数少，效率更高。

> 参考资料：
>
> - [CodingLabs - MySQL索引背后的数据结构及算法原理](http://blog.codinglabs.org/articles/theory-of-mysql-index.html)

### 5. b 树和 b+ 树的区别？为什么 b+ 树更矮？将某个值放入 b+ 树的节点，树结构会不会发生变化？

#### b 树

- 所有键值分布在整棵树中。
- 搜索有可能在非叶子节点结束，在关键字全集内做一次查找，性能逼近二分查找。
- 每个节点占用一个磁盘块。
- 缺点：
  - 除了叶子节点，每个节点都有 key，同时也包含 data，而每个页的存储空间是有限的，如果 data 比较大的话会导致每个节点存储的 key 数量变小。
  - 当存储的数据量很大的时候，会导致树的深度很大，增大查询时磁盘 I/O 的次数，进而影响查询性能。

![image-20220711124316682](E:\编程学习\学习笔记\面试笔记\img\image-20220711124316682.png)

#### b+ 树

- MySQL 索引数据结构。
- 对 B 树的优化，非叶子节点不存储数据：
  - 降低树的高度。
  - 将数据范围变为多个区间，区间越多，数据检索越快。
- 非叶子节点存储 key，叶子节点存储 key 和数据。
- 叶子节点两两指针相互连接（符合磁盘的预读特性），顺序查询性能更高。
- 树上有两个头指针，一个指向根节点，另一个指向关键字最小的叶子节点，而且所有叶子节点（即数据节点）之间是一种链式环数据结构，因此可以对 B+ 树做两种查找运算：
  - 对于主键的范围查找和分页查找。
  - 从根节点开始，进行随机查找。

![image-20220711124359010](E:\编程学习\学习笔记\面试笔记\img\image-20220711124359010.png)

b+ 树的插入操作：

- b+ 树的插入必须保证插入后叶子节点中的记录依然有序，同时需要考虑插入 b+ 树的三种情况，每种情况都可能会导致不同的插入算法。
- 为了保持平衡，对于新插入的键值可能需要做大量的拆分页（split）操作，而 b+ 树主要用于磁盘，因此页的拆分意味着磁盘的操作，应该尽量减少页的拆分。因此，b+ 树提供了旋转（rotation）的功能。

> 参考资料：
>
> - [数据结构与算法（五）B树、B+树、B*树_Damon_zqt的博客-CSDN博客](https://blog.csdn.net/Damon_zqt/article/details/105807110)

### 6. 聚簇索引的节点使用什么数据结构？

……

### 7. 为什么会产生最左匹配原则？底层是因为什么引起的？

……

### 8. Hash 索引和 b＋树索引的优缺点？

……

### 9. 为什么使用索引查询比直接查询要快？

- 直接查询：遍历每一行记录，依次进行匹配。
- 索引查询：通过 b+ 树进行查询，每个非叶子节点存储的是 key 的范围，可以快速缩小范围，找到需要查询的数据。 

## 日志

### 1. undolog、redolog、binlog？

#### redolog

**为什么需要 redolog？**

事务的四大特性里面有一个是持久性，具体来说就是只要事务提交成功，那么对数据库做的修改就被永久保存下来了，不可能因为任何原因再回到原来的状态。

事务在运行过程中，都是在内存的 Buffer Pool 修改页面，事务提交后，这些被修改后的脏页并不会立刻刷盘。

但如果不采取其他措施，那么在事务提交后 MySQL 发生故障，导致内存中数据丢失，那么这个已提交事务作出的更改也会丢失，那么 MySQL 是如何保证内存和磁盘的一致性的呢？

最简单的做法是在每次事务提交的时候，将该事务涉及修改的数据页全部刷新到磁盘中。但是这么做会有严重的性能问题。主要体现在两个方面：

- 因为 Innodb 是以页为单位进行磁盘交互的，而一个事务很可能只修改一个数据页里面的几个字节，这个时候将完整的数据页刷到磁盘的话，太浪费资源了。
- 一个事务可能涉及修改多个数据页，并且这些数据页在物理上并不连续，使用随机 I/O 写入性能太差。

所以这里就需要引入 redo 日志，对任意页面进行修改的操作都会生成 redo 日志，在事务提交时，只要保证生成的 redo 日志成功落盘即可，这样，即使 MySQL 发生故障导致内存中的数据丢失，也可以根据已落盘的 redo 日志恢复数据。

**基本概念**

redolog 是 InnoDB 存储引擎层的日志，又称重做日志文件，用于记录事务操作的变化，记录的是数据修改之后的值，不管事务是否提交都会记录下来。一个事务生成的 redolog 是按顺序写入磁盘的，是顺序 I/O。

在数据库掉电时，redolog 文件就能派上用场，InnoDB 存储引擎会使用 redolog 恢复到掉电前的时刻，以此来保证数据的完整性。

redolog 包括两部分：

- 内存中的日志缓冲（redo log buffer）
- 磁盘上的日志文件（redo log file）

MySQL 每执行一条 DML 语句，会先将记录写入 redo log buffer，后续某个时间点再一次性将多个操作记录写到 redo log file 中。这种先写日志，再写磁盘的技术就是 MySQL 里经常说到的 WAL（Write-Ahead Logging）技术。

**记录形式**

redolog 日志的大小是固定的，即记录满了以后就从头循环写。

#### binlog

**基本概念**

binlog 是属于 MySQL Server 层面的，又称为归档日志，属于逻辑日志，是以二进制的形式记录的，用于记录数据库执行的写入性操作（不包括查询）信息，依靠 binlog 是没有 crash-safe 能力的。

- 逻辑日志：可以简单理解为记录的就是 sql 语句。
- 物理日志：因为 MySQL 数据最终是保存在数据页中的，物理日志记录的就是数据页变更。

**使用场景**

在实际应用中，binlog 的主要使用场景有两个：

- 主从复制：在 Master 端开启 binlog，然后将 binlog 发送到各个 Slave 端，Slave 端重放 binlog 从而达到主从数据一致。
- 数据恢复：通过使用 mysqlbinlog 工具来恢复数据。

**三种格式**

binlog 日志有三种格式，分别为：STATEMENT、ROW、MIXED。

在 MySQL 5.7.7 之前，默认的格式是 STATEMENT，MySQL 5.7.7 之后，默认值是 ROW。日志格式通过 binlog-format 指定。

- STATEMENT：
  - 基于 SQL 语句的复制（statement-based replication, SBR），每一条会修改数据的 sql 语句会记录到 binlog 中。
  - 优点：不需要记录每一行的变化，减少了 binlog 日志量，节约了 I/O, 从而提高了性能；。
  - 缺点：在某些情况下会导致主从数据不一致，比如执行 `sysdate()`、`sleep()` 等。
- ROW：
  - 基于行的复制（row-based replication, RBR），不记录每条 sql 语句的上下文信息，仅需记录哪条数据被修改了。
  - 优点：不会出现某些特定情况下的存储过程、或 function、或 trigger 的调用和触发无法被正确复制的问题。
  - 缺点：会产生大量的日志，尤其是 alter table 的时候会让日志量暴涨。
- MIXED：
  - 基于 STATMENT 和 ROW 两种模式的混合复制（mixed-based replication, MBR）。
  - 一般的复制使用 STATEMENT 模式保存 binlog。
  - 对于 STATEMENT 模式无法复制的操作使用 ROW 模式保存 binlog。

#### undolog

数据库事务四大特性中有一个是原子性，具体来说就是原子性是指对数据库的一系列操作，要么全部成功，要么全部失败，不可能出现部分成功的情况。

实际上，原子性底层就是通过 undolog 来实现的。

undolog 主要记录了数据的逻辑变化，比如一条 INSERT 语句，对应一条 DELETE 的 undolog，对于每个 UPDATE 语句，对应一条相反的 UPDATE 的 undolog，这样在发生错误时，就能回滚到事务之前的数据状态。

undolog 保存了事务发生之前的数据的一个版本，可以用于回滚，同时可以提供多版本并发控制下的读（MVCC），也即非锁定读（快照读）。

> 参考资料：
>
> - [MySQL三大日志——binlog、redoLog、undoLog详解_向着百万年薪努力的小赵的博客-CSDN博客](https://blog.csdn.net/weixin_44688973/article/details/125460075)

### 2. redolog、binlog 的区别？

- redolog 属于 innoDB 层面；binlog 属于 MySQL Server 层面，这样在数据库用别的存储引擎时可以达到一致性的要求。
- redolog 是物理日志，记录该数据页更新的内容；binlog 是逻辑日志，记录的是这个更新语句的原始逻辑。
- redolog 是循环写，日志空间的大小固定；binlog 是追加写，是指一份写到一定大小的时候会更换下一个文件，不会覆盖。
- redolog 作为异常宕机或者介质故障后的数据恢复使用；binlog 可以作为恢复数据使用、主从复制搭建。
- redolog 是 InnoDB 存储引擎层的日志，binlog 是 MySQL Server 层记录的日志， 两者都是记录了某些操作的日志（不是所有）自然有些重复，但两者记录的格式不同。

## 系统架构

### 1. MySQL 系统结构？数据过滤在哪一层？

#### MySQL 基础架构

- 客户端
- 服务端
  - **连接器**：身份认证和权限相关（登录 MySQL 的时候）。
  - 查询缓存：执行查询语句的时候，会先查询缓存（MySQL 8.0 版本后移除，因为这个功能不太实用）。
  - **分析器**：没有命中缓存的话，SQL 语句就会经过分析器，分析器说白了就是要先看你的 SQL 语句要干嘛，再检查你的 SQL 语句语法是否正确。
  - **优化器**：按照 MySQL 认为最优的方案去执行。
  - **执行器**：执行语句，然后从存储引擎返回数据。 执行语句之前会先判断是否有权限，如果没有权限的话，就会报错。
- 存储引擎
  - 主要负责数据的存储和读取。
  - 支持 InnoDB、MyISAM、Memory 等多种存储引擎。

![img](%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0%20-%20%E7%94%B3%E6%9D%89%E6%9D%89.assets/13526879-3037b144ed09eb88.png)

（面试不常问）

### 2. MySQL 存储引擎？

MySQL 存储引擎采用的是插件式架构，支持多种存储引擎，我们甚至可以为不同的数据库表设置不同的存储引擎以适应不同场景的需要。**存储引擎是基于表的，而不是数据库。**

MySQL 支持多种存储引擎，可以通过 `show engines` 命令来查看 MySQL 支持的所有存储引擎。

默认存储引擎：

- 5.5.5 之前：MyISAM。
- 5.5.5 之后：InnoDB。

可以通过 `select version()` 命令查看你的 MySQL 版本。

也可以通过 `show variables like '%storage_engine%'` 命令直接查看 MySQL 当前默认的存储引擎。

如果只想查看数据库中某个表使用的存储引擎的话，可以使用 `show table status from db_name where name='table_name'` 命令。

### 3. MyISAM 和 InnoDB 的区别？

#### 概述

虽然，MyISAM 的性能还行，各种特性也还不错（比如全文索引、压缩、空间函数等）。但是，MyISAM 不支持事务和行级锁，而且最大的缺陷就是崩溃后无法安全恢复。

|        区别        |    myisam    |  innodb  |
| :----------------: | :----------: | :------: |
|      事务支持      |      否      |    是    |
|     数据行锁定     |      否      |    是    |
|      外键约束      |      否      |    是    |
|     表空间大小     |      小      |    大    |
|      物理文件      | .myd 和 .myi |   .ibd   |
|      索引结构      |  非聚簇索引  | 聚簇索引 |
|  是否保存表的行数  |      是      |    否    |
| 是否必须有唯一索引 |      否      |    是    |

#### 是否支持行级锁？

- MyISAM：只支持表锁。一锁就是锁住了整张表，在高并发的情况下性能极差。
- InnoDB：支持表锁、行锁（默认）。并且 innodb 的行锁是实现在索引上的（不是物理行记录）。

#### 是否支持外键？

MyISAM 不支持，而 InnoDB 支持。

外键对于维护数据一致性非常有帮助，但是对性能有一定的损耗。因此，通常情况下，我们是不建议在实际生产项目中使用外键的，在业务代码中进行约束即可！

阿里的《Java 开发手册》也是明确规定禁止使用外键的：

![img](%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0%20-%20%E7%94%B3%E6%9D%89%E6%9D%89.assets/image-20220510090309427.png)

总结：一般我们也是不建议在数据库层面使用外键的，而是在应用层面解决。不过，这样会对数据的一致性造成威胁。具体要不要使用外键还是要根据你的项目来决定。

#### 是否支持数据库异常崩溃后的安全恢复？

MyISAM 不支持，而 InnoDB 支持。

使用 InnoDB 的数据库在异常崩溃后，数据库重新启动的时候会保证数据库恢复到崩溃前的状态。这个恢复的过程依赖于 `redo log` 。

#### 是否支持 MVCC？

MyISAM 不支持，而 InnoDB 支持。

MVCC 可以看作是行级锁的一个升级，可以有效减少加锁操作，提高性能。而 MyISAM 连行级锁都不支持，则更不可能支持 MVCC。

#### 是否保存行数补充？

- MyISAM：对于 `select count(*) from table`，只要简单的读出保存好的行数即可。注意的是，当 `count(*)` 语句包含 `where` 条件时，两种表的操作是一样的。
- InnoDB：不保存表的具体行数，也就是说，执行 `select count(*) from table` 时，InnoDB 要扫描一遍整个表来计算有多少行。

#### 如何选择？各自的应用场景？

大多数时候我们使用的都是 InnoDB 存储引擎，在某些读密集的情况下，使用 MyISAM 也是合适的。不过，前提是你的项目不介意 MyISAM 不支持事务、崩溃恢复等缺点（可是一般都会介意！）。

- MyISAM
  - 做很多 count() 的计算
  - 更新操作少，查询操作多
  - 没有事务
- InnoDB
  - 可靠性要求高（如需要使用事务）
  - 更新操作多
  - 使用行锁的机会比使用表锁的机会多

一般情况下我们选择 InnoDB 都是没有问题的，但是某些情况下你并不在乎可扩展能力和并发能力，也不需要事务支持，也不在乎崩溃后的安全恢复问题的话，选择 MyISAM 也是一个不错的选择。但是一般情况下，我们都是需要考虑到这些问题的。

> 参考资料：
>
> - [数据库引擎INNODB和MYISAM的区别_GOV_D的博客-CSDN博客_数据库innodb和myisam](https://blog.csdn.net/gdnlnsjd/article/details/119713875)
> - [Innodb与Myisam引擎的区别与应用场景_wx5caecf2ed0645的技术博客_51CTO博客](https://blog.51cto.com/u_14286115/5194278)
> - [MySQL常见面试题总结 | JavaGuide](https://javaguide.cn/database/mysql/mysql-questions-01.html#myisam-和-innodb-如何选择)

### 4. 性能优化？

#### 存储引擎选择

可以为不同的业务表选择不同的存储引擎。

- memory：存放临时数据
- MyISAM：存放查询多的表
- InnoDB：存放并发大、更新多的表

为什么 MyISAM 会比 InnoDB 的查询速度快？

因为 InnoDB 在做 select 的时候，要维护的东西比 MyISAM 引擎多很多；

- InnoDB 要缓存数据块；而 MYISAM 只用缓存索引块。
- InnoDB 寻址要映射到块，再到行；而 MYISAM 记录的直接是文件的 OFFSET，定位比 InnoDB 要快。
- InnoDB 还需要维护 MVCC，即使你的场景没有，但它还是需要去检查和维护。

#### 字段定义

整型：

|     类型     | 大小（字节） |
| :----------: | :----------: |
|   TINYINT    |      1       |
|   SMALLINT   |      2       |
|  MEDIUMINT   |      3       |
| INT、INTEGER |      4       |
|    BIGINT    |      8       |

字符型：

- char
- varchar

#### 其它

- 不要用外键、触发器、视图：
  - 降低了可读性。
  - 影响数据库性能，应该把计算的事情交给程序，数据库专心做存储。
  - 数据的完整性应该在程序中检查。
- 不要用数据库存储图片、视频（比如 base64 编码）或者大文件，数据库只需要存储 URI（相对路径）。
- 将不常用的字段拆分出去，避免列数过多和数据量过大。

> 参考资料：
>
> - [MySQL的存储引擎有哪些？以及它们的对比和使用场景_Duktig丶的博客-CSDN博客_黑洞存储引擎](https://blog.csdn.net/qq_42937522/article/details/120473606)
> - [Innodb与Myisam引擎的区别与应用场景_wx5caecf2ed0645的技术博客_51CTO博客](https://blog.51cto.com/u_14286115/5194278)

## 主从复制

### 1. 主从复制的原理？

#### 为什么要做主从复制？

- 在业务复杂的系统中，有这么一个情景，有一句 sql 语句需要锁表，导致暂时不能使用读的服务，那么就很影响运行中的业务，使用主从复制，让主库负责写，从库负责读，这样，即使主库出现了锁表的情景，通过读从库也可以保证业务的正常运行。
- 做数据的热备，主库宕机后能够及时替换主库，保证业务可用性。
- 架构的扩展，业务量越来越大，I/O 访问频率过高，单机无法满足，此时做多库的存储，降低磁盘 I/O 访问的频率，提高单个机器的 I/O 性能。

总结：通过主从复制实现读写分离，主库负责处理增删改的请求（写数据），从库可以有多个，负责处理查询的请求（读数据）。

#### 主从复制的流程

![image-20220710204021159](E:\编程学习\学习笔记\面试笔记\img\image-20220710204021159.png)

#### **配置主库**

![image-20220710204723906](E:\编程学习\学习笔记\面试笔记\img\image-20220710204723906.png)

![image-20220710204802047](E:\编程学习\学习笔记\面试笔记\img\image-20220710204802047.png)

![image-20220710204915601](E:\编程学习\学习笔记\面试笔记\img\image-20220710204915601.png)

![image-20220710204931312](E:\编程学习\学习笔记\面试笔记\img\image-20220710204931312.png)

![image-20220710205010513](E:\编程学习\学习笔记\面试笔记\img\image-20220710205010513.png)

#### **配置从库**

![image-20220710205118785](E:\编程学习\学习笔记\面试笔记\img\image-20220710205118785.png)

![image-20220710205203615](E:\编程学习\学习笔记\面试笔记\img\image-20220710205203615.png)

![image-20220710205224226](E:\编程学习\学习笔记\面试笔记\img\image-20220710205224226.png)

![image-20220710205315777](E:\编程学习\学习笔记\面试笔记\img\image-20220710205315777.png)

整理格式：show slave status \G;

#### **主从复制的原理**

MySQL 主从复制是一个异步的复制过程，主库发送更新事件到从库，从库读取更新记录，并执行更新记录，使得从库的内容与主库保持一致。

binlog：binary log，主库中保存所有更新事件日志的二进制文件。binlog 是数据库服务启动的一刻起，保存数据库所有变更记录（数据库结构和内容）的文件。在主库中，只要有更新事件出现，就会被依次地写入到 binlog 中，之后会推送到从库中作为从库进行复制的数据源。

- binlog 输出线程：每当有从库连接到主库的时候，主库都会创建一个线程然后发送 binlog 内容到从库。 对于每一个即将发送给从库的 sql 事件，binlog 输出线程会将其锁住。一旦该事件被线程读取完之后，该锁会被释放，即使在该事件完全发送到从库的时候，该锁也会被释放。

在从库中，当复制开始时，从库就会创建从库 I/O 线程和从库的 SQL 线程进行复制处理。

- 从库 I/O 线程：当 START SLAVE 语句在从库开始执行之后，从库创建一个 I/O 线程，该线程连接到主库并请求主库发送 binlog 里面的更新记录到从库上。 从库 I/O 线程读取主库的 binlog 输出线程发送的更新并拷贝这些更新到本地文件，其中包括 relay log 文件。
- 从库的 SQL 线程：从库创建一个 SQL 线程，这个线程读取从库 I/O 线程写到 relay log 的更新事件并执行。

综上所述，可知：

- 对于每一个主从复制的连接，都有三个线程。拥有多个从库的主库为每一个连接到主库的从库创建一个 binlog 输出线程，每一个从库都有它自己的 I/O 线程和 SQL 线程。
- 从库通过创建两个独立的线程，使得在进行复制时，从库的读和写进行了分离。因此，即使负责执行的线程运行较慢，负责读取更新语句的线程并不会因此变得缓慢。比如说，如果从库有一段时间没运行了，当它再次启动的时候，尽管它的 SQL 线程执行比较慢，它的 I/O 线程可以快速地从主库里读取所有的 binlog 内容。这样一来，即使从库在 SQL 线程执行完所有读取到的语句前停止运行了，I/O 线程也至少完全读取了所有的内容，并将其安全地备份在从库本地的 relay log，随时准备在从库下一次启动的时候执行语句。

> 参考资料：
>
> - [mysql主从复制原理是什么-mysql教程-PHP中文网](https://m.php.cn/article/462450.html)

### 2. MySQL 主库与从库数据同步的延迟是多少？如果对主库进行了增删改，但是从库还没来得及更新，然后从从库读到了脏数据应该怎么处理？

#### 为什么会有延迟？

mysql 的主从复制都是单线程的操作：

- 主库对所有 DDL 和 DML 产生 binlog，binlog 是顺序写，所以效率很高。
- slave 的 Slave_IO_Running 线程到主库取日志，效率比较高。
- slave 的 Slave_SQL_Running 线程将主库的 DDL 和 DML 操作在 slave 实施。

DML 和 DDL 的 IO 操作是随即的，不是顺序的，成本高很多，还可能和 slave 上的其他查询产生 lock 争用，由于 Slave_SQL_Running 也是单线程的，所以一个 DDL 卡主了，如果需要执行 10 分钟，那么所有之后的 DDL 会等待这个 DDL 执行完才会继续执行，这就导致了延时。

主库上那个相同的 DDL 也需要执行 10 分，为什么 slave 会延时？答案是 master 可以并发，Slave_SQL_Running 线程却不可以。

MySQL 数据库主从同步延迟是怎么产生的？当主库的并发较高时，产生的 DDL 数量超过 slave 一个 sql 线程所能承受的范围，那么延时就产生了。当然还有就是可能与 slave 的大型 query 语句产生了锁等待。

总结：

- 随机重放
  - Mysql 主库中写 binlog 的操作是顺序写的，之前我们提到过，磁盘的顺序读写速度是很快的。同样的，从库中的 I/O 线程操作日志的速度效率也是很高的。
  - 但是别忘了，还有一个 SQL 线程来进行数据重放，而重放的过程是随机写盘的。到这里你应该就明白了吧，某一时刻 relay log 里的数据来不及重放进从库，就会产生主从延迟的情况。
- 主库并发高
  - 知道了从库中 SQL 线程的重放情况，对于主库并发高导致主从延迟肯定就不难理解了。某一时刻，大量写请求打到主库上，意味着要不断对 binlog 进行写入，此时从库中的 SQL 线程就会应接不暇，自然会产生主从延迟。
- 锁等待
  - 对于 SQL 单线程来说，当遇到阻塞时就会一直等待，直到执行成功才会继续进行。如果某一时刻从库因为查询产生了锁等待的情况，此时只有当前的操作执行完成后才会进行下面的操作，同理也就产生了主从延迟的情况。

#### 如何判断出现了延迟？

在从库服务器上执行 show slave satus 可以看到很多同步的参数：　

- Master_Log_File：SLAVE 中的 I/O 线程当前正在读取的主服务器二进制日志文件的名称。
- Read_Master_Log_Pos：在当前的主服务器二进制日志中，SLAVE 中的 I/O 线程已经读取的位置。
- Relay_Log_File：SQL 线程当前正在读取和执行的中继日志文件的名称。
- Relay_Log_Pos：在当前的中继日志中，SQL 线程已读取和执行的位置。
- Relay_Master_Log_File：由 SQL 线程执行的包含多数近期事件的主服务器二进制日志文件的名称。
- Slave_IO_Running：I/O 线程是否被启动并成功地连接到主服务器上。
- Slave_SQL_Running：SQL 线程是否被启动。
- Seconds_Behind_Master：从属服务器 SQL 线程和从属服务器 I/O 线程之间的时间差距，单位以秒计。

出现延迟的现象：

- show slave status 显示参数 Seconds_Behind_Master 不为 0，这个数值可能会很大。

- show slave status 显示参数 Relay_Master_Log_File 和 Master_Log_File 显示 bin-log 的编号相差很大，说明 bin-log 在从库上没有及时同步，所以近期执行的 bin-log 和当前 IO 线程所读的 bin-log 相差很大。

- MySQL 的从库数据目录下存在大量 mysql-relay-log 日志，该日志同步完成之后就会被系统自动删除，存在大量日志，说明主从同步延迟很厉害。

#### 延迟时间是多少？

- 一级主从：50~100 us
- 二级主从：1.1~1.2 ms

#### 如何解决？

- 并行复制
  - 既然 SQL 单线程进行重放时速度有限，那么能不能采用多线程的方式来进行重放呢？
  - MySQL 5.6 版本后，提供了一种并行复制的方式，通过将 SQL 线程转换为多个 work 线程来进行重放，这样就解决了主从延迟的问题。

![preview](https://pic2.zhimg.com/v2-8f67254c48ef93fe8af86c48f409765d_r.jpg)

- 降低主库并发
  - 对于低版本的数据库，无法进行版本升级，那么对于主库并发高的情况，就只能通过控制主库的并发来解决延迟了。
  - 可以通过使用 Redis 缓存减少打到 MySQL 的请求。
- 强制读主库
  - 对于一些实时性要求比较高的数据（比如：金融类业务），直接去主库读数据。
  - 读程序会影响主库的性能，虽然实现起来比较简单，但是高并发的场景不适用。
- 从库延迟查询：
  - 在正式的业务查询前，先执行一个 sleep 语句，给从库预留一定的数据同步缓冲期。
  - 当面对高并发业务场景时，性能会下降得非常厉害，一般不推荐这个方案。


```sql
select sleep(1)
select * from order where order_id=11111;
```

- 写程序双写
  - 写主库，同时写读库。
  - 双写会消耗一定的性能，虽然实现起来比较简单，但是高并发写的场景不适用。
- 引入缓存中间件
  - 客户端写主库、写缓存（设置一定的失效时间，一般略大于数据库同步最大时延即可）。
  - 读程序读缓存、读从库。
  - 优点：高并发读写都适用（缓存读写非常快）。
  - 缺点：K-V 存储，适用于一些简单的条件查询场景。如果是复杂的查询，还是要查询从库。

![img](https://pic2.zhimg.com/80/v2-11dd42821970112106ae9fe058c6aa01_1440w.jpg)

- 分库分表
  - 每次读写都是操作主库的一个分表，从库只用来做数据备份。
  - 当主库发生故障时，主从切换，保证集群的高可用性。

> 参考资料：
>
> - [mysql主从延迟时间是多少_MySQL主从同步个般是多久的延迟？_霸气sir的博客-CSDN博客](https://blog.csdn.net/weixin_42360899/article/details/113944680)
> - [mysql从库更新延迟时间_mysql数据库从库同步延迟的问题_马德阿姨的博客-CSDN博客](https://blog.csdn.net/weixin_32081079/article/details/113642595)
> - [MySQL主从同步延迟的原因及解决办法-木庄网络博客 (muzhuangnet.com)](http://www.muzhuangnet.com/show/44972.html)
> - [一篇文章帮你解决Mysql 中主从库不同步的问题 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/342557853)
> - [MySQL - 主从延迟、读写分离 7 种解决方案_Q.E.D.的博客-CSDN博客_mysql读写分离延迟](https://blog.csdn.net/qq_34272760/article/details/124154383?ops_request_misc=%7B%22request%5Fid%22%3A%22165821631916782350857733%22%2C%22scm%22%3A%2220140713.130102334.pc%5Fblog.%22%7D&request_id=165821631916782350857733&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~blog~first_rank_ecpm_v1~rank_v31_ecpm-5-124154383-null-null.185^v2^control&utm_term=Redis&spm=1018.2226.3001.4450)

# Redis

## 基本概念

### 1. Redis 为什么快？

#### 基于内存

Redis 基于内存，纯内存操作的速度快。

Redis 速度快还取决于其他的一些因素，而这些都跟 Redis 的高可用性有很大关系。下面是衡量 Redis 的三个纬度：

- 高性能：线程模型、网络 I/O 模型、数据结构，合理的数据编码。
- 高可用性：主从复制、哨兵模式、Cluster 分片集群和持久化机制。
- 高拓展性：负载均衡。

#### 线程模型

Redis 4.0 之前是单线程模型。

为什么单线程模型的 Redis 性能不减？

- 单线程不代表一定就慢，单线程可以节省线程间切换的开销（时间），也不用考虑并发读写带来的复杂操作场景。
- 单线程模型避免了多线程的上下文频繁切换，这也避免了多线程可能产生的竞争问题。
- Reids 是基于内存的读写操作，比传统的基于磁盘的数据库快。
- 可以通过 I/O 多路复用来实现并发，是非阻塞的。

Redis 4.0 之后新增了一些可以被其他线程异步处理的删除操作。原因是有一些超大的键值对占用了很大的内容，例如几十 MB 或者几百 MB 的数据，这些数据的删除在几百毫秒内结束不了，如果是同步的就会阻塞待处理的任务，所以加入了多线程，目的就是为了异步处理这些大的数据。

#### 网络 I/O 模型

epoll：采用多路复用机制，同时监听多个 socket，根据 socket 上的事件来选择对应的事件处理器进行处理，以此来实现并发操作。

多个 socket 可能会并发产生不同的操作，每个操作对应不同的文件事件，但是 I/O 多路复用程序会监听多个 socket，会将 socket 产生的事件放入队列中排队，事件分派器每次从队列中取出一个事件，把该事件交给对应的事件处理器进行处理。

![image-20220718113752595](E:\编程学习\学习笔记\面试笔记\img\image-20220718113752595.png)

#### 数据结构

首先，Redis 整个数据库就是一张全局哈希表，而哈希表查询的时间复杂度是  O(1)，只需要计算每个键的哈希值，便知道对应的哈希桶位置，定位桶里面的 entry 找到对应数据，这个也是 Redis 快的原因之一。

![image-20220718104131710](E:\编程学习\学习笔记\面试笔记\img\image-20220718104131710.png)

其次，不同的数据类型使用不同的数据结构，并且每种数据类型底层都有一种或者多种数据结构来支撑。

![image-20220718104145689](E:\编程学习\学习笔记\面试笔记\img\image-20220718104145689.png)

Redis 针对自己内部的数据类型有专门对应的 API，在抢购、秒杀、详情页、点赞、评论数等情景中，使用 Redis 内部的方法来操作数据，可以规避并发下对数据库的事务操作（完全由 redis 内存操作代替）。

##### （1）SDS 简单动态字符

- Redis 将获取字符串长度所需的复杂度从 O(N) 降低到了 O(1) ， 这确保了获取字符串长度的工作不会成为 Redis 的性能瓶颈。
- 空间预分配
- 惰性空间释放
- 二进制安全：
  - 为了确保 Redis 可以适用于各种不同的使用场景， SDS 的 API 都是二进制安全的（binary-safe）：所有 SDS API 都会以处理二进制的方式来处理 SDS 存放在 buf 数组里的数据， 程序不会对其中的数据做任何限制、过滤、或者假设 —— 数据在写入时是什么样的， 它被读取时就是什么样。
  - 1 字符 = 1 字节
  - 这也是我们将 SDS 的 buf 属性称为字节数组的原因 —— Redis 不是用这个数组来保存字符， 而是用它来保存一系列二进制数据。

![image-20220718104637923](E:\编程学习\学习笔记\面试笔记\img\image-20220718104637923.png)

##### （2）zipList 压缩列表

压缩列表是 List 、hash、 sortedSet 三种数据类型底层实现之一。

当一个列表只有少量数据的时候，并且每个列表项要么就是小整数值，要么就是长度比较短的字符串，那么 Redis 就会使用压缩列表来做列表键的底层实现。

Ziplist 是由一系列特殊编码的内存块构成的列表， 一个 ziplist 可以包含多个节点（entry）， 每个节点可以保存一个长度受限的字符数组（不以 \0 结尾的 char 数组）或者整数。

##### （3）双端链表

双端链表是 Redis 列表类型的底层实现之一。

![image-20220718105604612](E:\编程学习\学习笔记\面试笔记\img\image-20220718105604612.png)

##### （4）skipList 跳表

- 表头（head）：负责维护跳跃表的节点指针。
- 跳跃表节点：保存着元素值，以及多个层。
- 层：保存着指向其他元素的指针。高层的指针越过的元素数量大于等于低层的指针，为了提高查找的效率，程序总是从高层先开始访问，然后随着元素值范围的缩小，慢慢降低层次。
- 表尾：全部由 NULL 组成，表示跳跃表的末尾。

![image-20220718105854129](E:\编程学习\学习笔记\面试笔记\img\image-20220718105854129.png)

要注意到，每一层上的索引是可以向下层走的。上面的图只是一个简化结构，更严谨的一个结构应该如下：

![image-20220718111522663](E:\编程学习\学习笔记\面试笔记\img\image-20220718111522663.png)

上图的 31 节点，出现在了 0 - 3 层，其实就是一个节点，不是四个节点。

插入节点：

- 随机生成待插入节点的层数。
- 层数：算法返回 1 的概率是 1/2，返回 2 的概率是 1/4 ……
- 第 0 层包含所有节点，第 1 层包含 1/2 的节点 ……

示例：

插入值为 2 的节点，假设随机生成的层数是 3。

![image-20220718112620960](E:\编程学习\学习笔记\面试笔记\img\image-20220718112620960.png)

删除节点：

删除是插入的逆过程。

##### （5）intset 整数集合

整数集合（intset）用于有序、无重复地保存多个整数值， 根据元素的值， 自动选择该用什么长度的整数类型来保存元素。

> 参考资料：
>
> - [Redis访问速度很快只是因为它是内存数据库吗？_灰子学技术的博客-CSDN博客_redis访问速度](https://blog.csdn.net/zhghost/article/details/113622812)
> - [Redis线程模型 - 简书 (jianshu.com)](https://www.jianshu.com/p/8f2fb61097b8)
> - [十分钟弄懂什么是跳表，不懂可以来打我_愤怒的可乐的博客-CSDN博客_跳表](https://blog.csdn.net/yjw123456/article/details/105159817/)

### 2. Redis 作为数据库和缓存的区别？

数据库：

- 需要存储所有的数据（全量数据），数据不能丢。
- 使用 noeviction 缓存策略（内存超过限制时，不丢弃数据，继续增大内存）。
- 掉电易失，追求速度的同时，更强调持久性。

缓存：

- 缓存数据不重要，不是全量数据，只保留热数据（因为内存大小是有限的，是瓶颈）。
- Redis 里的数据应该随着访问（业务）变化。
- 使用除 noeviction 以外的缓存策略（自动清除一些相对老的数据）。
- 使用缓存追求的就是急速。

### 3. 为什么要使用 Redis 作为缓存？有什么优势？

为什么需要缓存？

磁盘 IO 及网络开销是直接请求内存 IO 的上千倍，做个简单计算，如果我们需要某个数据，该数据从数据库磁盘读出来需要 0.0045 S，经过网络请求传输需要 0.0005 S，那么每个请求完成最少需要 0.005 S，该数据服务器每秒最多只能响应 200 个请求，而如果该数据存于本机内存里，读出来只需要 100 us，那么每秒能够响应 10000 个请求。通过将数据存储到离 CPU 更近的位置，减少数据传输时间，提高处理效率，这就是缓存的意义。

缓存可以把系统的响应能力提高几个数量级，远高于传统的基于硬盘的关系型数据库。

Redis 的优势：

- Redis 支持丰富的数据结构，新版本数据结构从最初的 5 种变成 9 种。
- Redis 是读写单进程单线程，不用考虑并发读写的复杂场景，速度也快。
- Reids 功能完备，支持数据持久化，支持主从复制和集群。
- Redis 支持 Lua 脚本、事务、发布订阅模型等功能。

> 参考资料：
>
> - [分布式 - Redis中有哪些数据结构及底层实现原理_Q.E.D.的博客-CSDN博客](https://blog.csdn.net/qq_34272760/article/details/120734895?ops_request_misc=%7B%22request%5Fid%22%3A%22165821624816782350829224%22%2C%22scm%22%3A%2220140713.130102334.pc%5Fblog.%22%7D&request_id=165821624816782350829224&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~blog~first_rank_ecpm_v1~rank_v31_ecpm-15-120734895-null-null.185^v2^control&utm_term=Redis&spm=1018.2226.3001.4450)

### 4. Redis 和 Memcached 的区别和共同点？

现在公司一般都是用 Redis 来实现缓存，而且 Redis 自身也越来越强大了！不过，了解 Redis 和 Memcached 的区别和共同点，有助于我们在做相应的技术选型的时候，能够做到有理有据！

**共同点**：

- 都是基于内存的数据库，一般都用来当做缓存使用。
- 都有过期策略。
- 两者的性能都非常高。

**区别**：

1. Redis 支持更丰富的数据类型（支持更复杂的应用场景）。Redis 不仅仅支持简单的 k/v 类型的数据，同时还提供 list，set，zset，hash 等数据结构的存储。Memcached 只支持最简单的 k/v 数据类型。
2. Redis 支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用，而 Memcached 把数据全部存在内存之中。
3. Redis 有灾难恢复机制。因为可以把缓存中的数据持久化到磁盘上。
4. Redis 在服务器内存使用完之后，可以将不用的数据放到磁盘上。但是，Memcached 在服务器内存使用完之后，就会直接报异常。
5. Memcached 没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据；但是 Redis 目前是原生支持 cluster 模式的。
6. Memcached 是多线程，非阻塞 IO 复用的网络模型；Redis 使用单线程的多路 IO 复用模型。（Redis 6.0 引入了多线程 IO）
7. Redis 支持发布订阅模型、Lua 脚本、事务等功能，而 Memcached 不支持。并且，Redis 支持更多的编程语言。
8. Memcached 过期数据的删除策略只用了惰性删除，而 Redis 同时使用了惰性删除与定期删除。

### 5. 为什么要使用缓存？

下面主要从“高性能”和“高并发”这两点来看待这个问题。

#### 高性能

假如用户第一次访问数据库中的某些数据的话，这个过程是比较慢的，毕竟是从硬盘中读取的。但是，如果用户访问的数据属于高频数据并且不会经常改变的话，那么我们就可以很放心地将该用户访问的数据存在缓存中。

这样有什么好处呢？那就是保证用户下一次再访问这些数据的时候就可以直接从缓存中获取了。操作缓存就是直接操作内存，所以速度相当快。

不过，要保持数据库和缓存中的数据的一致性。 如果数据库中的对应数据改变的之后，同步改变缓存中相应的数据即可！

#### 高并发

一般像 MySQL 这类的数据库的 QPS 大概都在 1w 左右（4 核 8g） ，但是使用 Redis 缓存之后很容易达到 10w+，甚至最高能达到 30w+（就单机 redis 的情况，redis 集群的话会更高）。

> QPS（Query Per Second）：服务器每秒可以执行的查询次数；

由此可见，直接操作缓存能够承受的数据库请求数量是远远大于直接访问数据库的，所以我们可以考虑把数据库中的部分数据转移到缓存中去，这样用户的一部分请求会直接到缓存这里而不用经过数据库。进而，我们也就提高了系统整体的并发。

### 6. Redis 除了做缓存，还能做什么？

- **分布式锁**：通过 Redis 来做分布式锁是一种比较常见的方式。通常情况下，我们都是基于 Redisson 来实现分布式锁。
- **限流**：一般是通过 Redis + Lua 脚本的方式来实现限流。
- **消息队列**：Redis 自带的 list 数据结构可以作为一个简单的队列使用。Redis 5.0 中增加的 Stream 类型的数据结构更加适合用来做消息队列。它比较类似于 Kafka，有主题和消费组的概念，支持消息持久化以及 ACK 机制。
- **复杂业务场景** ：通过 Redis 以及 Redis 扩展（比如 Redisson）提供的数据结构，我们可以很方便地完成很多复杂的业务场景比如通过 bitmap 统计活跃用户、通过 sorted set 维护排行榜。
- ……

> 参考资料：
>
> - [分布式锁中的王者方案 - Redisson (qq.com)](https://mp.weixin.qq.com/s/CbnPRfvq4m1sqo2uKI6qQw)
> - [我司用了 6 年的 Redis 分布式限流器，可以说是非常厉害了！ (qq.com)](https://mp.weixin.qq.com/s/kyFAWH3mVNJvurQDt4vchA)
> - [Redis 消息队列的三种方案（List、Streams、Pub/Sub） | JavaKeeper (starfish.ink)](https://javakeeper.starfish.ink/data-management/Redis/Redis-MQ.html)



## 数据结构

### 1. Redis 的五种数据类型？底层是怎么实现的？

string（字符串、数值、位图）、list、hash、set、zset。

![image-20220711152941773](E:\编程学习\学习笔记\面试笔记\img\image-20220711152941773.png)

#### string

字符串是 Redis 中最为基础的数据存储类型，数据结构简单，可存储文本、Json、图片数据等任何二进制文件，如：姓名、订单号等。

简单动态字符串（simple dynamic string）简称 SDS。Redis 使用 C 语言编写，但是传统的 C 字符串使用长度为 N+1 的字符串数组来表示长度为 N 的字符串，所以为了获取一个长度为 C 字符串的长度，必须遍历整个字符串。和 C 字符串不同，动态字符串的数据结构中，有专门用于保存字符串长度的变量，我们可以通过获取 len 属性的值，直接知道字符串长度，从一定程度上提高了读取效率。

![image-20220719193752690](E:\编程学习\学习笔记\面试笔记\img\image-20220719193752690.png)

#### list

类似 Java 中的 List ，按照插入顺序排序的字符串链表，在插入时，如果该键并不存在，Redis 将为该键创建一个新的链表。与此相反，如果链表中所有的元素均被移除，那么该键也将会被从数据库中删除。

底层实现：双向链表。

![image-20220711154615551](E:\编程学习\学习笔记\面试笔记\img\image-20220711154615551.png)

#### hash

相当于 Java 中的 HashMap，所以该类型非常适合于存储值对象的信息，比如用户基本信息对象含有昵称、性别和 Age 等属性，可以使用 Hash 来存储 User 对象， Key 可以为用户的唯一 ID 属性。

#### set

类似 Java 中的 set，但它是一个无序集合，用于存储无序（存入和取出的顺序不一定相同）元素，值不能重复。可以使用 Redis 的 Set 数据类型跟踪一些唯一性数据，比如访问系统的唯一 IP 地址，唯一用户 ID 等信息，再比如在微博应用中，每个人的好友存在一个集合（set）中，这样求两个人的共同好友的操作，可能就只需要用求交集命令即可。

#### zset

类似 Java 中的 TreeSet，支持从小到大排序的 set，适用于排行榜结构的数据存储。

底层通过 SkipList（跳表）实现。

特点：牺牲内存空间，提高查找速度，每次插入元素后，会随机造层。

为什么使用 SkipList 而不是红黑树呢？

- 红黑树：
  - 红黑树的查找效率很高，但是在进行重新平衡时，会涉及到大量节点的变化（旋转操作等），因此实现和操作起来都比较复杂。
- 跳跃表：
  - 通过简单的多层索引结构，实现简单，且能达到近似于红黑树的查找效率，插入节点（多层插入）不需要像红黑树那样有额外操作。
  - 而且跳跃表还能实现范围查找及输出，而红黑树只支持单个元素查找，对于范围查找效率低。

#### 补充

除了 5 种基本的数据结构外，还有 3 种特殊的数据结构：

- HyperLogLogs（基数统计）
- Bitmap（位存储）
- Geospatial（地理位置）

> 参考资料：
>
> - [分布式 - Redis中有哪些数据结构及底层实现原理_Q.E.D.的博客-CSDN博客](https://blog.csdn.net/qq_34272760/article/details/120734895?ops_request_misc=%7B%22request%5Fid%22%3A%22165821624816782350829224%22%2C%22scm%22%3A%2220140713.130102334.pc%5Fblog.%22%7D&request_id=165821624816782350829224&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~blog~first_rank_ecpm_v1~rank_v31_ecpm-15-120734895-null-null.185^v2^control&utm_term=Redis&spm=1018.2226.3001.4450)
> - [Redis 5 种基本数据结构详解 | JavaGuide](https://javaguide.cn/database/redis/redis-data-structures-01.html#string-字符串)
> - [Redis 3 种特殊数据结构详解 | JavaGuide](https://javaguide.cn/database/redis/redis-data-structures-02.html#bitmap)

### 2. zset 是怎么实现的？插入一个值，跳表是怎么做的，如何裂变，什么情况下会发生裂变？

底层实现：跳表。

跳表是一种多层的有序链表。

![image-20220711193402761](E:\编程学习\学习笔记\面试笔记\img\image-20220711193402761.png)

跳表的操作实现：

- 查询：搜索的平均时间复杂度为 O(logN)，这是由于每在上层搜索一次就平均缩小了一半的搜索范围。
- 插入：在实际实现时，采用了一种随机确定要插入元素的高度的方法，即第 1 层一定会插入，所以节点高度最小值为 1，节点高度为 2 的概率为 0.5，高度为 3 的概率为 0.25 …… 这样就保证了第 i + 1 层链表节点个数约为第 i 层的一半。
- 删除：与插入操作类似。

相比于红黑树，跳表的优点有：

- 查询复杂度两者相同，都为 O(logN)。
- 插入和删除的时间复杂度两者相同，都为 O(logN)，但红黑树插入、删除后需要进行调整，操作较为复杂，而跳表只需要插入节点的相邻节点。
- 跳表更适合进行范围查询，只要找到范围的最小值，然后在第一层遍历即可。
- 跳表的整体实现要比红黑树简单。

> 参考资料：
>
> - [【学习笔记】Redis中有序集合zset的实现原理——跳表_棉花糖灬的博客-CSDN博客_zset 跳表](https://blog.csdn.net/zuzhiang/article/details/120260152)

### 3. 二进制安全？

Redis 在与外界进行交互时，只使用字节流，而不使用字符流。避免不同语言对不同类型的数据定义的大小不同而造成溢出的情况。

Redis 中的 int 类型数据只占 1 个字节，即不管什么类型的数据，都按“1 字符 = 1 字节”计算（Redis 的所有数据在底层都以字节存储）。

对于中文字符：

- 使用 UTF-8 编码时，中文占 3 个字节。
- 使用 GBK 编码时，中文占 2 个字节。

Redis 不管上层客户端外围使用的是什么编码类型（UTF-8、GBK ...），底层的数据长度都一样。？？？

### 4. String 的应用场景有哪些？

- 常规数据（比如 session、token、序列化后的对象等）的缓存。
- 计数比如用户单位时间的请求数（简单限流可以用到）、页面单位时间的访问数。
- 分布式锁（利用 `SETNX key value` 命令可以实现一个最简易的分布式锁）；
- ......

### 5. String 还是 Hash 存储对象数据更好呢？

- String 存储的是序列化后的对象数据，存放的是整个对象。Hash 是对对象的每个字段单独存储，可以获取部分字段的信息，也可以修改或者添加部分字段，节省网络流量。如果对象中某些字段需要经常变动或者经常需要单独查询对象中的个别字段信息，Hash 就非常适合。
- String 存储相对来说更加节省内存，缓存相同数量的对象数据，String 消耗的内存约是 Hash 的一半。并且，存储具有多层嵌套的对象时也方便很多。如果系统对性能和资源消耗非常敏感的话，String 就非常适合。

在绝大部分情况，我们建议使用 String 来存储对象数据即可！

举例：购物车信息用 String 还是 Hash 存储更好呢?

购物车信息建议使用 Hash 存储：

- 用户 id 为 key
- 商品 id 为 field，商品数量为 value

由于购物车中的商品频繁修改和变动，这个时候 Hash 就非常适合了！

### 6. 使用 Redis 实现一个排行榜怎么做？

Redis 中有一个叫做 `sorted set` 的数据结构经常被用在各种排行榜的场景，比如直播间送礼物的排行榜、朋友圈的微信步数排行榜、王者荣耀中的段位排行榜、话题热度排行榜等。

相关的一些 Redis 命令：`ZRANGE`（从小到大排序）、`ZREVRANGE`（从大到小排序）、`ZREVRANK`（指定元素排名）。

![img](%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0%20-%20%E7%94%B3%E6%9D%89%E6%9D%89.assets/image-20220719071115140.png)

### 7. 使用 Set 实现抽奖系统需要用到什么命令？

- `SPOP key count`：随机移除并获取指定集合中一个或多个元素，适合不允许重复中奖的场景。
- `SRANDMEMBER key count`：随机获取指定集合中指定数量的元素，适合允许重复中奖的场景。

### 8. 使用 Bitmap 统计活跃用户怎么做？

使用日期（精确到天）作为 key，然后用户 ID 为 offset，如果当日活跃过就设置为 1。

初始化数据：

```bash
> SETBIT 20210308 1 1
(integer) 0
> SETBIT 20210308 2 1
(integer) 0
> SETBIT 20210309 1 1
(integer) 0
```

统计 20210308~20210309 总活跃用户数：

- 将 20210308 与 20210309 按位与后，存到 desk1 中。
- 统计 desk1 中位为 1 的数量。

```bash
> BITOP and desk1 20210308 20210309
(integer) 1
> BITCOUNT desk1
(integer) 1
```

统计 20210308~20210309 在线活跃用户数：

- 将 20210308 与 20210309 按位或后，存到 desk2 中。
- 统计 desk2 中位为 1 的数量。

```bash
> BITOP or desk2 20210308 20210309
(integer) 1
> BITCOUNT desk2
(integer) 2
```

## 线程模型

### 1. Redis 单线程模型了解吗？

Redis 基于 Reactor 模式来设计开发了自己的一套高效的事件处理模型（Netty 的线程模型也基于 Reactor 模式，Reactor 模式不愧是高性能 IO 的基石），这套事件处理模型对应的是 Redis 中的文件事件处理器（file event handler）。由于文件事件处理器（file event handler）是单线程方式运行的，所以我们一般都说 Redis 是单线程模型。

**既然是单线程，那怎么监听大量的客户端连接呢？**

Redis 通过 **IO 多路复程序**来监听来自客户端的大量连接（或者说是监听多个 socket），它会将感兴趣的事件及类型（读、写）注册到内核中并监听每个事件是否发生。

这样的好处非常明显： **I/O 多路复用技术的使用让 Redis 不需要额外创建多余的线程来监听客户端的大量连接，降低了资源的消耗**（和 NIO 中的 `Selector` 组件很像）。

另外， Redis 服务器是一个事件驱动程序，服务器需要处理两类事件：

- 文件事件
- 时间事件

时间事件不需要多花时间了解，我们接触最多的还是**文件事件**（客户端进行读取写入等操作，涉及一系列网络通信）。

《Redis 设计与实现》有一段话是这样介绍文件事件的：

> Redis 基于 Reactor 模式开发了自己的网络事件处理器：这个处理器被称为文件事件处理器（file event handler）。文件事件处理器使用 I/O 多路复用（multiplexing）程序来同时监听多个套接字，并根据套接字目前执行的任务来为套接字关联不同的事件处理器。
>
> 当被监听的套接字准备好执行连接应答（accept）、读取（read）、写入（write）、关 闭（close）等操作时，与操作相对应的文件事件就会产生，这时文件事件处理器就会调用套接字之前关联好的事件处理器来处理这些事件。
>
> **虽然文件事件处理器以单线程方式运行，但通过使用 I/O 多路复用程序来监听多个套接字**，文件事件处理器既实现了高性能的网络通信模型，又可以很好地与 Redis 服务器中其他同样以单线程方式运行的模块进行对接，这保持了 Redis 内部单线程设计的简单性。

可以看出，文件事件处理器（file event handler）主要是包含 4 个部分：

- 多个 socket（客户端连接）
- IO 多路复用程序（支持多个客户端连接的关键）
- 文件事件分派器（将 socket 关联到相应的事件处理器）
- 事件处理器（连接应答处理器、命令请求处理器、命令回复处理器）

![img](%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0%20-%20%E7%94%B3%E6%9D%89%E6%9D%89.assets/redis-event-handler.png)

### 2. Redis 6.0 之前为什么不使用多线程？

虽然说 Redis 是单线程模型，但实际上，Redis 在 4.0 之后的版本中就已经加入了对多线程的支持。不过，Redis 4.0 增加的多线程主要是针对一些大键值对的删除操作的命令，使用这些命令就会使用主处理之外的其他线程来“异步处理”。

大体上来说，Redis 6.0 之前主要还是单线程处理。

那 Redis 6.0 之前为什么不使用多线程？

主要原因有下面 3 个：

- 单线程编程容易并且更容易维护。
- Redis 的性能瓶颈不在 CPU ，主要在内存和网络。
- 多线程就会存在死锁、线程上下文切换等问题，甚至会影响性能。

### 3. Redis 6.0 之后为何引入了多线程？

Redis 6.0 引入多线程主要是为了提高网络 IO 读写性能，因为这个算是 Redis 中的一个性能瓶颈（Redis 的瓶颈主要受限于内存和网络）。

虽然，Redis 6.0 引入了多线程，但是 Redis 的多线程只是在网络数据的读写这类耗时操作上使用了，执行命令仍然是单线程顺序执行。因此，你也不需要担心线程安全问题。

Redis 6.0 的多线程默认是禁用的，只使用主线程。如需开启需要修改配置文件 `redis.conf`：

```bash
io-threads-do-reads yes
```

开启多线程后，还需要设置线程数，否则是不生效的。同样需要修改配置文件 `redis.conf`：

```bash
# 官网建议 4 核的机器设置为 2 或 3 个线程，8 核的设置为 6 个线程
io-threads 4 
```

> 参考资料：
>
> - [Redis 6.0 新特性-多线程连环13问！ (qq.com)](https://mp.weixin.qq.com/s/FZu3acwK6zrCBZQ_3HoUgw)
> - [为什么 Redis 选择单线程模型 - 面向信仰编程 (draveness.me)](https://draveness.me/whys-the-design-redis-single-thread/)

## 内存管理

### 1. Redis 给缓存数据设置过期时间有什么用？

一般情况下，我们设置保存的缓存数据的时候都会设置一个过期时间。为什么呢？因为内存是有限的，如果缓存中的所有数据都是一直保存的话，很容易就会出现 Out of memory 错误。

Redis 自带了给缓存数据设置过期时间的功能，比如：

```bash
127.0.0.1:6379> exp key 60 # 数据在 60s 后过期
(integer) 1
127.0.0.1:6379> setex key 60 value # 数据在 60s 后过期 (setex:[set] + [ex]pire)
OK
127.0.0.1:6379> ttl key # 查看数据还有多久过期
(integer) 56
```

注意：

- Redis 中除了字符串类型有自己独有的设置过期时间的命令 `setex` 外，其他方法都需要依靠 `expire` 命令来设置过期时间。
- 另外，`persist` 命令可以移除一个键的过期时间。

**过期时间除了有助于缓解内存的消耗，还有什么其他用么？**

很多时候，我们的业务场景就是需要某个数据只在某一时间段内存在，比如我们的短信验证码可能只在 1 分钟内有效，用户登录的 token 可能只在 1 天内有效。如果使用传统的数据库来处理的话，一般都是自己判断过期，这样更麻烦并且性能要差很多。

### 2. Redis 是如何判断数据是否过期的呢？

Redis 使用过期字典（可以看作是一张 hash 表）来保存数据过期的时间。过期字典的 key 指向 Redis 数据库中的某个 key，过期字典的值是一个 long long 类型的整数，这个整数保存了 key 所指向的数据库键的过期时间（毫秒精度的 UNIX 时间戳）。

![redis过期字典](%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0%20-%20%E7%94%B3%E6%9D%89%E6%9D%89.assets/redis-expired-dictionary.png)

过期字典是存储在 redisDb 这个结构里的：

```c
typedef struct redisDb {
    // ...
    dict *dict;     // 数据库键空间，保存着数据库中所有键值对
    dict *expires   // 过期字典保存着键的过期时间
    // ...
} redisDb;
```

### 3. Redis 内存淘汰机制了解么？

#### 6 种数据淘汰策略

- **volatile-lru（least recently used）**：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰。
- **volatile-ttl**：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰。
- **volatile-random**：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰。
- **allkeys-lru（least recently used）**：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的 key（这个是最常用的）。
- **allkeys-random**：从数据集（server.db[i].dict）中任意选择数据淘汰。
- **no-eviction**：禁止驱逐数据，也就是说当内存不足以容纳新写入数据时，新写入操作会报错。

#### 4.0 版本后新增

- **volatile-lfu（least frequently used）**：从已设置过期时间的数据集（server.db[i].expires）中挑选最不经常使用的数据淘汰。
- **allkeys-lfu（least frequently used）**：当内存不足以容纳新写入数据时，在键空间中，移除最不经常使用的 key。

### 4. key 的有效期如何决定？

业务逻辑决定 key 的有效期，业务运转决定缓存中哪些是冷数据应该被淘汰掉。

- 会随着被访问而刷新有效期吗？（否）
- 会随着被修改而刷新有效期吗？（否，被修改后，直接去掉该 key 的有效期）
- 可以设置倒计时，且 Redis 不能延长。
- 可以设置定时，由业务逻辑自己补全。

### 5. 如何淘汰过期的 key？

对于过期 key，Redis 采用的是“**定期删除 + 惰性/懒汉式删除**”策略。

两种方式：

- 主动方式：当 key 过期后再被客户端访问到时，该 key 会被发现已经过期并被 Redis 淘汰。
- 被动方式：Redis 定期地在所有 key 中随机抽取 key 来进行检查，并清除掉已经过期的 key，若有多于 25% 的 key 过期，则再次进行抽取并检查过期时间。

总结：

- 优点：保证了 Redis 的性能（不会占用太多的资源（时间）用于去删除已经过期的 key）。
- 缺点：稍微牺牲了一些内存（Redis 中会继续存有大约 25% 的已过期的 key）。

## 持久化

### 1. Redis 的持久化？RDB、AOF？

#### RDB

- 含义：
  - 快照、副本。
  - RDB（Redis DataBase）是 Redis 默认的持久化方案。
  - Redis 可以通过创建快照来获得存储在内存里面的数据在某个时间点上的副本。Redis 创建快照之后，可以对快照进行备份，可以将快照复制到其他服务器从而创建具有相同数据的服务器副本（Redis 主从结构，主要用来提高 Redis 性能），还可以将快照留在原地以便重启服务器的时候使用。
  - 在指定的时间间隔内，执行指定次数的写操作后，会将内存中的数据写入到磁盘中，即在指定目录下生成一个 dump.rdb 文件。Redis 重启时会通过加载 dump.rdb 文件恢复数据。
    - 载入 RDB 文件不需要手动运行，而是 server 端自动进行，只要启动时检测到 RDB 文件存在，server 端便会载入 RDB 文件重建数据集。
    - 如果同时存在 AOF 的话，会优先使用 AOF 重建数据集，因为其保存的数据更完整。
  - 把当前进程的数据生成快照（某个时间节点），并保存到磁盘上。
    - 时点性：存储快照时，需要一定的时间，但我们应该实现存储的状态是刚开始进行存储时的状态（不存储在生成快照的过程中发生的数据修改）。
- 存储方式：
  - save（阻塞）：
    - 在开始存储快照后，阻塞当前 Redis 服务器，Redis 不再对外提供服务，直到 RDB 过程完成。
    - 在前台以阻塞的方式执行（应用场景：关机维护）。
  - bgsave（非阻塞）：
    - Redis 继续对外提供服务，需要被存储的数据在向磁盘写入的过程中可能被修改，会造成时点混乱。
    - 在后台以异步非阻塞的方式执行，会触发 fork 创建子进程。
    - Redis 进程执行 fork 操作创建子进程来完成 RDB 的持久化，保证了 Redis 服务器不会停止对客户端包括写请求在内的任何响应。
    - 原理：
      - 使用 fork 创建子进程去存储快照。
      - 使用 copy on write（写时复制）机制应对存储快照的过程中可能会发生的对数据的修改（只用动指针，不用复制数据，速度快）。
      - 数据的增删改是发生在原（父）进程，每一次修改都会触发一次内核级的 copy on write，使原进程的数据指针指向新的物理地址，而子进程（存储快照）的数据指针不会发生变化（仍指向刚开始进行存储时的物理地址）。
      - ![image-20220711170506270](E:\编程学习\学习笔记\面试笔记\img\image-20220711170506270.png)
- 优点：
  - 文件体积小（被压缩过，类似 java 中的序列化），适用于备份、全量复制等场景。
  - 恢复速度快。
  - 适合大规模的数据恢复，如果业务对数据完整性和一致性要求不高，RDB 的启动速度更快，是很好的选择。
  - RDB 文件简洁，它保存了某个时间点的 Redis 数据集，适合用于做备份。
  - 考虑到磁盘硬件故障的问题，RDB 文件很适合用于灾备，因为单文件可以很方便地传输到另外的数据中心。
  - RDB 的性能很好，需要进行持久化时，主进程可以 fork 一个子进程出来，然后把持久化的工作交给子进程，而自己不会有相关的 I/O 操作。
- 缺点：
  - 数据的完整性和一致性不高，实时性不够，可能会造成数据的丢失（时点与时点之间窗口的数据容易丢失）。
    - 因为 SAVE 命令执行是有时间间隔的，比如每 5 min 备份一次，RDB 可能在最后一次备份时宕机，这 5 min 的时间窗数据就可能丢失。
  - fork 创建子进程属于重量级操作，执行成本高，备份时占用内存。
    - 因为 Redis 在备份时会独立创建一个子进程，将数据写入到一个临时文件（此时内存中的数据是原来的两倍），最后再将临时文件替换之前的备份文件。
    - 所以 Redis 的持久化和数据的恢复要选择在夜深人静的时候执行是比较合理的。
  - RDB 文件是二进制的，没有可读性。

在 `redis.conf` 配置文件中默认有此下配置：

```bash
# 在900秒(15分钟)之后，如果至少有1个key发生变化，Redis就会自动触发BGSAVE命令创建快照。
save 900 1           

# 在300秒(5分钟)之后，如果至少有10个key发生变化，Redis就会自动触发BGSAVE命令创建快照。
save 300 10          

# 在60秒(1分钟)之后，如果至少有10000个key发生变化，Redis就会自动触发BGSAVE命令创建快照。
save 60 10000        
```

#### AOF 

- 含义：
  - 日志。
  - Redis 默认不开启 AOF。
  - 它采用日志的形式来记录每个写操作，生成一个 appendonly.aof 文件，并将日志追加到文件末尾。
  - Redis 重启的时候会根据日志文件的内容将写指令从前到后执行一次以完成数据的恢复工作（有点类似 Mysql 的 binlog）。
- Redis 中 RDB 和 AOF 可以同时开启，但是只要开启了 AOF，则只会用 AOF 来恢复数据（更完整）。
- 优点：
  - 丢失数据少，数据记录完整。
- 缺点：
  - appendonly.aof 文件体积较大（Redis 针对 AOF 文件体积大的问题，提供了重写的瘦身机制）。
  - 恢复速度慢。
- 优化：
  - 混合模式：
    - Redis 4.0 以后出现，在每两次快照之间，通过 AOF 日志来记录命令增量。
    - hdfs：让日志只记录增量，每经过一段时间，就存储一个新的镜像，并清空日志，重新开始记录（减少日志文件体积）。
    - 总结：Redis 4.0 以后，AOF 是一个混合体。
      - 利用了 RDB 的快（数据恢复速度）
      - 利用了日志的全量（数据的完整性）
  - 重写机制：
    - Redis 4.0 以前：删除抵消的命令，合并重复的命令，最终的日志文件还是一个纯指令的日志文件。
    - Redis 4.0 以后：触发 AOF 重写之后，会进入 AOF 与 RDB 的混合模式，即将老的数据存入 RDB 中，再将增量以指令的形式 append 到 AOF 中。

与快照持久化相比，AOF 持久化的实时性更好，因此已成为主流的持久化方案。默认情况下 Redis 没有开启 AOF（append only file）方式的持久化，可以通过 appendonly 参数开启：

可以通过 appendonly 参数开启：

```bash
appendonly yes
```

开启 AOF 持久化后每执行一条会更改 Redis 中的数据的命令，Redis 就会将该命令写入到内存缓存 `server.aof_buf` 中，然后再根据 `appendfsync` 配置来决定何时将其同步到硬盘中的 AOF 文件。

AOF 文件的保存位置和 RDB 文件的位置相同，都是通过 dir 参数设置的，默认的文件名是 `appendonly.aof`。

在 Redis 的配置文件中存在三种不同的 AOF 持久化方式，它们分别是：

```bash
# 每次有数据修改发生时都会写入 AOF 文件，这样会严重降低 Redis 的速度
appendfsync always

# 每秒钟同步一次，显式地将多个写命令同步到硬盘
appendfsync everysec

# 让操作系统决定何时进行同步
appendfsync no        
```

为了兼顾数据和写入性能，用户可以考虑 `appendfsync everysec` 选项 ，让 Redis 每秒同步一次 AOF 文件，Redis 性能几乎没受到任何影响。而且这样即使出现系统崩溃，用户最多只会丢失一秒之内产生的数据。当硬盘忙于执行写入操作的时候，Redis 还会优雅的放慢自己的速度以便适应硬盘的最大写入速度。

> 参考资料：
>
> - [Redis进阶 - 持久化：RDB和AOF机制详解_Ch3n的博客-CSDN博客_redis持久化rdb和aof](https://blog.csdn.net/weixin_43064185/article/details/122035596)
> - [redis的AOF 方式 · Issue #783 · Snailclimb/JavaGuide · GitHub](https://github.com/Snailclimb/JavaGuide/issues/783)
> - [redis AOF重写描述不准确以及一个小错误 · Issue #1439 · Snailclimb/JavaGuide · GitHub](https://github.com/Snailclimb/JavaGuide/issues/1439)

### 2. 使用 fork() 创建子进程的原理？

父进程与子进程的虚拟地址（对数据的引用）指向同一个物理地址。数据不用拷贝，而是将子进程的数据指针与物理地址做一个绑定，从而快速地得到一个子进程。

![image-20220711162453594](E:\编程学习\学习笔记\面试笔记\img\image-20220711162453594.png)

采用 copy on write（写时复制：什么时候修改数据，什么时候才进行复制）机制，创建子进程并不发生复制（使进程创建变快）（一般不可能子进程把所有数据都改一遍，所有只需要把被修改的数据复制到子进程）。在该方式下，父子进程对数据的修改，对方看不到。

![image-20220711162636922](E:\编程学习\学习笔记\面试笔记\img\image-20220711162636922.png)

### 3. AOF 重写了解吗？

AOF 重写可以产生一个新的 AOF 文件，这个新的 AOF 文件和原有的 AOF 文件所保存的数据库状态一样，但体积更小。

AOF 重写是一个有歧义的名字，该功能是通过读取数据库中的键值对来实现的，程序无须对现有 AOF 文件进行任何读入、分析或者写入操作。

在执行 `BGREWRITEAOF` 命令时，Redis 服务器会维护一个 **AOF 重写缓冲区**，该缓冲区会在子进程创建新 AOF 文件期间，记录服务器执行的所有写命令。当子进程完成创建新 AOF 文件的工作之后，服务器会将重写缓冲区中的所有内容追加到新 AOF 文件的末尾，使得新的 AOF 文件保存的数据库状态与现有的数据库状态一致。最后，服务器用新的 AOF 文件替换旧的 AOF 文件，以此来完成 AOF 文件重写操作。

### 4. Redis 4.0 对于持久化机制做了什么优化？

Redis 4.0 开始支持 RDB 和 AOF 的混合持久化（默认关闭，可以通过配置项 `aof-use-rdb-preamble` 开启）。

如果把混合持久化打开，AOF 重写的时候就直接把 RDB 的内容写到 AOF 文件开头。这样做的好处是可以结合 RDB 和 AOF 的优点，快速加载同时避免丢失过多的数据。当然缺点也是有的， AOF 里面的 RDB 部分是压缩格式不再是 AOF 格式，可读性较差。

## 事务

### 1. 如何使用 Redis 事务？

Redis 可以通过 **`MULTI`、`EXEC`、`DISCARD` 和 `WATCH`** 等命令来实现事务（transaction）功能。

```bash
> MULTI
OK
> SET USER "Guide哥"
QUEUED
> GET USER
QUEUED
> EXEC
1) OK
2) "Guide哥"
```

使用 `MULTI` 命令后可以输入多个命令。Redis 不会立即执行这些命令，而是将它们放到队列，当调用了 `EXEC` 命令将执行所有命令。

这个过程是这样的：

- 开始事务（`MULTI`）
- 命令入队（批量操作 Redis 的命令，以先进先出（FIFO）的顺序执行）
- 执行事务（`EXEC`）

你也可以通过 `DISCARD` 命令取消一个事务，它会清空事务队列中保存的所有命令。（Redis 不支持事务的回滚）

```bash
> MULTI
OK
> SET USER "Guide哥"
QUEUED
> GET USER
QUEUED
> DISCARD
OK
```

`WATCH` 命令用于监听指定的键，当调用 `EXEC` 命令执行事务时，如果一个被 `WATCH` 命令监视的键被修改的话，整个事务都不会执行，直接返回失败。

```bash
> WATCH USER
OK
> MULTI
> SET USER "Guide哥"
OK
> GET USER
Guide哥
> EXEC
ERR EXEC without MULTI
```

### 2. Redis 支持原子性吗？

Redis 的事务和我们平时理解的关系型数据库的事务不同。

Redis 事务在运行错误的情况下，除了执行过程中出现错误的命令外，其他命令都能正常执行。并且，Redis 是不支持回滚（roll back）操作的。因此，Redis 事务其实是不满足原子性的（而且不满足持久性）。

Redis 官网也解释了自己为啥不支持回滚。简单来说就是 Redis 开发者们觉得没必要支持回滚，这样更简单便捷并且性能更好。Redis 开发者觉得即使命令执行错误也应该在开发过程中就被发现而不是生产过程中。

总结：**Redis 事务相当于提供了一种将多个命令请求打包的功能。然后，再按顺序执行打包的所有命令，并且不会被中途打断。**

除了不满足原子性之外，事务中的每条命令都会与 Redis 服务器进行网络交互，这是比较浪费资源的行为。明明一次批量执行多个命令就可以了，这种操作实在是看不懂。因此，Redis 事务是不建议在日常开发中使用的。

总结&补充：

- Redis 同一个事务中如果有一条命令执行失败，其后的命令仍然会被执行，没有回滚。
- 若在事务队列中存在命令性错误（类似于 Java 编译性错误），则执行 EXEC 命令时，该事务中的所有命令都不会执行。
- 若在事务队列中存在语法性错误（类似于 Java 的 1/0 的运行时异常），则执行 EXEC 命令时，其它正确命令会都被执行，而错误命令则会抛出异常。

> 参考资料：
>
> - [关于Redis事务不是原子性问题 · Issue #452 · Snailclimb/JavaGuide · GitHub](https://github.com/Snailclimb/JavaGuide/issues/452)
> - [关于 redis 没有事务回滚？ · Issue #491 · Snailclimb/JavaGuide · GitHub](https://github.com/Snailclimb/JavaGuide/issues/491)

### 3. 如何解决 Redis 事务的缺陷？

Redis 从 2.6 版本开始支持执行 Lua 脚本，它的功能和事务非常类似。我们可以利用 Lua 脚本来批量执行多条 Redis 命令，这些 Redis 命令会被提交到 Redis 服务器一次性执行完成，大幅减小了网络开销。

一段 Lua 脚本可以视作一条命令执行，一段 Lua 脚本执行过程中不会有其他脚本或 Redis 命令同时执行，保证了操作不会被其他指令插入或打扰。

如果 Lua 脚本运行时出错并中途结束，出错之后的命令是不会被执行的。并且，出错之前执行的命令是无法被撤销的。因此，严格来说，通过 Lua 脚本来批量执行 Redis 命令也是不满足原子性的。

## 集群

### 1. 单机的弊端？集群扩展的 3 个维度（AKF）？

#### 单机、单节点、单实例的弊端

- 单点故障（可能会挂掉）
- 容量有限
- 压力大（Socket I/O、CPU）

如何解决？从这三个角度扩展集群。

#### 集群的扩展（AKF）

- X 方向：
  - 全量，镜像。
  - 解决单点故障的问题，用于数据容灾备份。
  - 实现：主从复制。
- Y 方向：
  - 按业务、功能拆分，存储不同的数据。
  - 解决容量有限的问题。
  - 实现：
    - 数据可以分类，交集不多：
      - 按逻辑、业务拆分数据。
    - 数据无法拆解：
      - hash + 取模：
        - 含义：通过一个 hash 函数将每一个数据映射到后端不同的 Redis 服务器上。
        - 弊端：取模的数必须固定（取决于 Redis 服务器的台数），会影响分布式下的扩展性，当增加新服务器时，需要修改该取模值。
      - random：
        - 含义：随机地将数据扔给后端的 Redis 服务器。
        - 应用场景：当客户端并发较大时，将 Redis 用作消息队列，起一个缓冲的作用。
      - 一致性哈希（kemata）：
        - 含义：是没有取模的 hash 算法。
        - 实现：哈希环。
    - 集群代理：
      - 将客户端的映射逻辑（modula、random、kemata）迁移到中间的代理（Twemproxy：Twitter 维护的（缓存）代理系统）。
      - ![image-20220720114203240](E:\编程学习\学习笔记\面试笔记\img\image-20220720114203240.png)
- Z 方向：
  - 按优先级、逻辑再拆分。
  - 解决单点压力大的问题。

#### 哈希环的原理

数据（key）、承载数据的节点（node，这里是 Redis 服务器）都需要参与 hash 的计算。

- 用节点的参数（如 IP 地址等）进行 hash，映射到环上，作为环上的物理节点，其它都是虚拟节点（解决数据倾斜的问题）。
- 数据经过 hash 后，找到它后面离它最近的物理节点。
- 新增一个节点（node03），不影响节点后的数据的查找，但是节点前的一些数据可能无法被查找到。

![image-20220720114304928](E:\编程学习\学习笔记\面试笔记\img\image-20220720114304928.png)

### 2. Redis 集群是如何保证数据一致性的？

Redis 默认采用异步的方式实现，是弱一致性。

特点：低延迟、高性能。

### 3. 主从复制？

#### 基本概念

一般在主机上会进行全量的增删改查操作（读、写），而在一个备机（或从机）上只进行读操作。

原理：

- RDB 先通过磁盘 IO 存储到磁盘，再通过网络 IO 发送给从机。
- RDB 直接通过网络 IO 发送给从机（更快）。

![image-20220711164653408](E:\编程学习\学习笔记\面试笔记\img\image-20220711164653408.png)

#### 实现流程

- 开启主机（本机 6379）。
- 从机（本机 6380）执行：REPLICAOF 127.0.0.1（主机 ip）6379（主机端口），追随主机。
- 主机日志：
  - 开启服务端进程。
  - 使用 bgsave 存储 RDB 到磁盘，为同步做准备（dump RDB 采用 copy-on-write）。
  - 与 6380 服务端达成同步。
- 从机日志：
  - 开启服务端进程。
  - 连接到主机 127.0.0.1:6379，采用非阻塞的方式连接。
  - MASTER <-> REPLICA sync started：开始同步。
  - Flushing old data：主机与备机同步数据时，从节点需要先删除自己的旧数据。
  - Loading DB in memory
  - 同步成功。

#### 注意事项

- 从机默认禁止写入数据（可以配置）。
- 从机与主机完成同步后，之前的旧数据就被 flush 掉了，而只存有主机的数据。
- 从机与主机同步后挂了，重启从机，可以 get 到从机挂掉之前 + 挂掉之后主机新增的数据。
- RDB 中可以记录自己曾经追随过哪台主机，但 AOF 中不会记录该数据。
- 在主机上可以知道与自己同步的从机的信息（可以知道有哪些从机）。

#### 配置参数

- replicaof ...：追随主机。
- masterauth ...：主机密码。
- replica-server-stale-data：从机在与主机同步的过程中，是否还对外暴露旧的数据，若为 yes，则在同步过程中，还可以查从机中的旧数据。
- replica-read-only：从机是否只支持读，若为 no，则开启写入功能。
- repl-diskless-sync：RDB 复制到从机的过程中，若为 yes，则直接走网络 IO；若为 no，则需要先通过磁盘 IO 存储到磁盘。
- min-replicas-to-write 3
- min-replicas-max-lag 10

### 4. 哨兵？

#### 基本概念

主机也是一个单点，一般会对主机做 HA（高可用），实现故障的自动转移（代替人），通过一个技术、程序（哨兵：sentinel）来实现监控，然而只要是一个程序就可能会有单点故障的问题，因此监控也需要以集群的方式来实现（一变多）。

如何判断主机是否挂了？

- 一般使用奇数台监控。
- 需要超过 n/2 + 1 个监控都判断主机挂了才算数（即需要半数以上）。

#### 应用场景

- 自动管理多个 Redis 服务器，解决需要人工维护主机故障的问题。
- 功能：
  - 监控：不断检查主、从服务器是否运作正常。
  - 提醒：当被监控的某个 Redis 服务器出现问题时，可以通过 API 向管理员或其它应用程序发送通知。
  - 自动故障转移：当主服务器挂掉时，会自动地将该主机的一个从机升级为新的主机，并让其它从机改为复制新的主机；当客户端试图连接已经失效的主机时，会通知客户端新的主服务器的地址。
- 一个哨兵可以通过主机上的发布、订阅知道别的哨兵。

![image-20220711165247787](E:\编程学习\学习笔记\面试笔记\img\image-20220711165247787.png)

#### 实现流程

- 配置 sentinel：
  - port 23679
  - sentinel monitor mymaster 127.0.0.1 6379 2
  - 参数介绍：
    - mymaster：集群名称，一套哨兵可以监控多个主从复制集群。
    - 127.0.0.1：主机地址。
    - 6379：主机端口号。
    - 2：投票数（这里的意思是，一共投了 2 票给 6379，让它成为主机）。
- 启动主、从服务器。
- 启动多个哨兵。
  - redis-server ./26379.conf --sentinel（或：redis-sentinel）
  - 可以看到：redis-sentinel -> redis-server，此时哨兵不作为单独的一个进程运行，而是被包含进了 server 进程中。

#### 注意事项

- 哨兵只要监控了主机，就可以知道该集群里的所有从机。
- 一个哨兵可以通过主机上的发布、订阅知道别的所有哨兵。
- 当主机挂掉以后，哨兵不会马上决定出新的主机，会有一定的延时。
- 哨兵会自己不断动态地修改自己的配置文件（投票选出新的主机）。

### 5. 分片集群？

#### 基本概念

- 分区：
  - 将不同的数据分布到多个 Redis 服务器里面。
  - 降低单机的压力。
- 使用哈希槽：
  - Redis 集群有 16384 个哈希槽。
  - 每个 key 通过 CRC16 校验后对 16384 取模来决定放到哪个槽。
- 无主模型：
  - 每一台服务器都是主机（可以读、写）。
  - 弊端：数据很难整合在一起使用。

#### 实现原理

![Image](E:\编程学习\学习笔记\面试笔记\img\Image-16582871241413.png)

### 6. CAP 原则？

含义：在一个分布式系统中，一致性（Consistency）、可用性（Availability）、分区容错性（Partition Tolerance）这三个要素最多只能同时实现两个，不可能三者兼顾。

- 一致性：指在分布式系统中的所有数据备份，在同一时刻是否有同样的值。
- 可用性：指在集群中一部分节点故障后，集群整体是否还能响应客户端的读写请求。
- 分区容忍性：指系统如果不能在时限内达成数据一致性，就意味着发生了分区的情况，必须就当前操作在一致性和可用性之间做出抉择（强一致性一定会破坏可用性）。

### 7. 如何搭建一个高可用的 Redis 集群？

Reids 官方给出了 Redis-cluster 方案（分片集群），无中心架构，可线性扩展到 1000 个节点。

Master-slave（主从）模式中，Master 是集群中至关重要的一个节点，Master 的稳定性决定整个系统的稳定性，为解决这一问题，Redis Cluster 应需求而生。

Redis Cluster 是官方在 Redis 3.0 版本正式推出的高可用以及分布式的解决方案。 内置数据自动分片机制，由多个 Redis 实例组成的整体，数据按照槽（slot）存储分布在多个 Redis 实例上，集群内部将所有的 key 映射到 16384 个 Slot 中。

![image-20220719205118205](E:\编程学习\学习笔记\面试笔记\img\image-20220719205118205.png)

Redis Cluster 实现的功能：

- 将数据分片到多个实例（按照 slot 存储）。
- 集群节点宕掉会自动 failover。
- 提供相对平滑地扩容/缩容节点。

优点：

- 无中心架构：三机房部署，其中一主一从构成一个分片，之间通过异步复制同步数据，异步复制存在数据不一致的时间窗口，保证高性能的同时牺牲了部分一致性。
  - 一旦某个机房掉线，则分片上位于另一个机房的 slave 会被提升为 master 从而可以继续提供服务。
  - 每个 master 负责一部分 slot，数目尽量均摊。
  - 客户端对于某个 Key 操作先通过公式计算出所映射到的 slot，然后直连某个分片，写请求一律走 master，读请求根据路由规则选择连接的分片节点。
- 可扩展性：可线性扩展到 1000 多个节点，节点可动态添加或删除。
- 降低运维成本，提高系统的扩展性和可用性。

> 参考资料：
>
> - [分布式 - 缓存必问：Reids持久化，高可用集群_Q.E.D.的博客-CSDN博客](https://blog.csdn.net/qq_34272760/article/details/120750625?ops_request_misc=%7B%22request%5Fid%22%3A%22165821624816782350829224%22%2C%22scm%22%3A%2220140713.130102334.pc%5Fblog.%22%7D&request_id=165821624816782350829224&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~blog~first_rank_ecpm_v1~rank_v31_ecpm-20-120750625-null-null.185^v2^control&utm_term=Redis&spm=1018.2226.3001.4450)

## 性能优化

### 1. Redis bigkey？

#### 什么是 bigkey？

简单来说，如果一个 key 对应的 value 所占用的内存比较大，那这个 key 就可以看作是 bigkey。具体多大才算大呢？有一个不是特别精确的参考标准：string 类型的 value 超过 10 kb，复合类型的 value 包含的元素超过 5000 个（对于复合类型的 value 来说，不一定包含的元素越多，占用的内存就越多）。

#### bigkey 有什么危害？

除了会消耗更多的内存空间，bigkey 对性能也会有比较大的影响。因此，我们应该尽量避免写入 bigkey！

#### 如何发现 bigkey？

- 使用 Redis 自带的 `--bigkeys` 参数来查找。
  - 这个命令会扫描 Redis 中所有的 key ，会对 Redis 的性能有一点影响。
  - 并且，这种方式只能找出每种数据结构 top 1 bigkey（占用内存最大的 string 数据类型，包含元素最多的复合数据类型）。
- 通过分析 RDB 文件来找出 big key。
  - 这种方案的前提是你的 Redis 采用的是 RDB 持久化。

### 2. 大量 key 集中过期问题？

对于过期 key，Redis 采用的是“**定期删除 + 惰性/懒汉式删除**”策略。

定期删除执行过程中，如果突然遇到大量过期 key 的话，客户端请求必须等待定期清理过期 key 任务线程执行完成，因为这个这个定期任务线程是在 Redis 主线程中执行的。这就导致客户端请求没办法被及时处理，响应速度会比较慢。

解决方法：

- 给 key 设置随机过期时间。
- 开启 `lazy-free`（惰性删除/延迟释放）：lazy-free 特性是 Redis 4.0 开始引入的，指的是让 Redis 采用异步方式延迟释放 key 使用的内存，将该操作交给单独的子线程处理，避免阻塞主线程。

个人建议不管是否开启 lazy-free，我们都尽量给 key 设置随机过期时间。

### 3. 热点 key 和大 value 问题？

正常情况下，Redis 集群中的数据都是均匀分配到每个节点，请求也会均匀的分布到每个分片上，但在一些特殊场景中，比如外部爬虫、攻击、热点商品等，最典型的就是明星在微博上宣布离婚，吃瓜群众纷纷涌入留言，导致微博评论功能崩溃，这种短时间内某些 key 访问量过于大，对于这种相同的 key 会请求到同一台数据分片上，导致该分片负载较高成为瓶颈问题，导致雪崩等一系列问题。

#### Reids 集群负载不均衡故障的主要原因

- 高访问量的 Key：也就是热 key，根据过去的维护经验一个 key 访问的 QPS 超过 1000 就要高度关注了，比如热门商品，热门话题等。
- 大 Value：有些 key 访问 QPS 虽然不高，但是由于 value 很大，造成网卡负载较大，网卡流量被打满，单台机器可能出现千兆 / 秒，IO 故障。
- 热点 Key + 大 Value 同时存在，服务器杀手。

#### 热点 key 和大 Value 会造成哪些故障？

- 数据倾斜问题：
  - 大 Value 会导致集群不同节点数据分布不均匀，造成数据倾斜问题。
  - 热点 key 会导致大量读写比例非常高的请求都会落到同一个 redis server 上，该 redis 的负载就会严重升高，容易打挂。
-  大 Value 会导致 Redis 服务器缓冲区不足，造成 get 超时。
- 阻塞请求：
  - Redis 为单线程，单 value 较大时，读写需要较长的处理时间，会阻塞后续的请求处理。
- 阻塞网络：
  - 单 value 较大时，会占用服务器网卡较多带宽，可能会影响该服务器上的其他 Redis 实例或者应用。
  - 由于 Value 过大，导致机房网卡流量不足。
- QPS 倾斜：
  - 热点 key 会造成各个 Redis 分片上的 QPS 不均。
- Redis 缓存失效导致数据库层被击穿的连锁反应。

缓冲区的概念：

![image-20220719115503380](E:\编程学习\学习笔记\面试笔记\img\image-20220719115503380.png)

#### 如何定位热点 key 问题？

- 提前预知
  - 根据业务，人肉统计或系统统计可能会成为热点的数据，如：促销活动商品、热门话题、节假日话题、纪念日活动等。
- Redis 客户端统计
  - 调用端通过计数的方式统计 key 的请求次数。
  - 但是无法预知 key 的个数，代码侵入性强。
- Redis 集群代理层统计
  - 像 Twemproxy，codis 这些基于代理的 Redis 分布式架构，具有统一的入口，可以在 Proxy 层做收集上报。
  - 但是缺点很明显，并非所有的 Redis 集群架构都有 proxy。

![image-20220719111743873](E:\编程学习\学习笔记\面试笔记\img\image-20220719111743873.png)

- Redis 服务端统计
  - 监控 Redis 单个分片的 QPS，对 QPS 倾斜到一定程度的节点，执行 monitor 命令，获取热点 key。
  - Redis 提供了 monitor 命令，可以统计出一段时间内的某 Redis 节点上的所有命令，可以用于分析热点 key。
  - 在高并发条件下，会存在内存暴涨和 Redis 性能的隐患，所以此种方法适合在短时间内使用。

![image-20220719112446386](E:\编程学习\学习笔记\面试笔记\img\image-20220719112446386.png)

#### 如何解决热点 key 问题？

- key 拆分：
  - 如果当前 key 的类型是一个二级数据结构，例如哈希类型。如果该哈希元素个数较多，可以考虑将当前 hash 进行拆分。
  - 这样该热点 key 可以拆分为若干个新的 key 分布到不同 Redis 节点上，从而减轻压力。
- 迁移热点 key：
  - 以 Redis Cluster 为例，可以将热点 key 所在的 slot 单独迁移到一个新的独立的 Redis 节点上。
  - 这样这个热点 key 即使 QPS 很高，也不会影响到整个集群的其他业务，还可以定制化开发。
- 热点 key 限流：
  - 对于读命令我们可以通过迁移热点 key 然后添加从节点来解决。
  - 对于写命令我们可以通过单独针对这个热点 key 来限流。
- 增加本地缓存：
  - 对于数据一致性不是那么高的业务，可以将热点 key 缓存到业务机器的本地缓存中，因为是业务端的本地内存中，省去了一次远程的 IO 调用。
  - 但是当数据更新时，可能会造成业务和 Redis 数据不一致。

#### 如何解决大 value 问题？

由于 Redis 是单线程运行的，如果一次操作的 value 很大会对整个 redis 的响应时间造成负面影响，因为 Redis 是 Key - Value 结构数据库，大 value 就是单个 value 占用内存较大，对 Redis 集群造成最直接的影响就是数据倾斜。

多大的 Value 算大？

- 大：
  - string 类型：value > 10K。
  - set、list、hash、zset 等集合数据类型：元素个数 > 1000。
- 超大：
  - string 类型：value > 100K。
  - set、list、hash、zset 等集合数据类型：元素个数 > 10000。

在业务上进行拆分：

- 一个较大的 key-value 拆分成几个 key-value ，将操作压力平摊到多个 redis 实例中，降低对单个 redis 的 IO 影响。
- 将分拆后的几个 key-value 存储在一个 hash 中，每个 field 代表一个具体的属性，使用 hget、hmget 来获取部分的 value，使用 hset、hmset 来更新部分属性。

> 参考资料：
>
> - [分布式 - Redis热点key大Value解决方案_Q.E.D.的博客-CSDN博客_redis 大value](https://blog.csdn.net/qq_34272760/article/details/120754635)
> - [【Redis】手打整理 - 大key和大value的危害 - 简书 (jianshu.com)](https://www.jianshu.com/p/88d22ae7704e)
> - [redis value多大会影响性能_Redis性能调优，影响Redis性能的因素_weixin_39604478的博客-CSDN博客](https://blog.csdn.net/weixin_39604478/article/details/110984989)

## 生产问题

### 1. 缓存击穿、穿透、雪崩？

#### 缓存击穿

击穿是指一个 key 被穿透，这个 key 是热点 key，同一个 key 会被成千上万次请求，比如微博热点排行榜，key 是小时时间戳，value 是个 list 的榜单。每个小时产生一个 key，这个 key 会有百万 QPS，如果这个 key 失效了，就像保险丝熔断，百万 QPS 直接压垮数据库。

带来的问题：Redis 缓存中 key 的过期造成高并发访问数据库（Redis 自己实现分布式协调很麻烦）。

解决：客户端的请求到达 Redis 没有找到 key 后，所有人需要再请求一次，争抢锁，只有抢到了锁的人才会去访问数据库，而其他用户继续等待着锁释放（限制到达数据库的访问量）。

简单地来说，就是在缓存失效的时候（判断拿出来的值为空），不是立即去 load db，而是先使用缓存工具的某些带成功操作返回值的操作（比如 Redis 的 SETNX 或者 Memcache 的 ADD）去 set 一个 mutex key（NX 表示该 key 不存在时才设置，即只能新建），当操作返回成功时，再进行 load db 的操作并回设缓存；否则，就重试整个 get 缓存的方法。

示例代码：

```java
public String get(key) {
	String value = redis.get(key);
    if (value == null) { 
        // 代表缓存值过期
        // 设置 3min 的超时，防止 del 操作失败的时候，下次缓存过期一直不能 load db
        if (redis.setnx(key_mutex, 1, 3 * 60) == 1) {  
            // 代表设置成功
            // 从数据库中去查数据
            value = db.get(key);
            // 设置缓存
            redis.set(key, value, expire_secs);
            // 删除锁（key）
            redis.del(key_mutex);
        } else {  
            // 这个时候代表同时候的其他线程已经 load db 并回设到缓存了，这时候重试获取缓存值即可
            sleep(50);
            // 重试获取缓存值
            get(key);  
        }
    } else {
        return value;      
    }
}
```

总结：

- 含义：数据在缓存中没有，但在数据库中有。
- 危害：当高并发场景下，大量用户同时读取缓存没读到，会造成瞬时大量的访问到达数据库。
- 解决：分布式锁。

#### 缓存穿透

穿透是指请求绕过 Reids，调用者发起的请求参数（key）在缓存和数据库中都不存在，通过不存在的 key，成功穿透到系统底层，大规模不断发起不存在的 key 的检索请求会导致系统压力过大最后故障。

解决：

##### （1）缓存无效 key

返回空值：遇到数据库和 Redis 都查询不到的值，在 Redis 里 set 一个 null value，过期时间很短，目的在于同一个 key 再次请求时直接返回 null，避免穿透。

如果缓存和数据库都查不到某个 key 的数据就写一个到 Redis 中去并设置过期时间，具体命令如下： `SET key value EX 10086` 。

这种方式可以解决请求的 key 变化不频繁的情况，如果黑客恶意攻击，每次构建不同的请求 key，会导致 Redis 中缓存大量无效的 key 。很明显，这种方案并不能从根本上解决此问题。

如果非要用这种方式来解决穿透问题的话，尽量将无效的 key 的过期时间设置短一点比如 1 分钟。

另外，这里多说一嘴，一般情况下我们是这样设计 key 的：`表名:列名:主键名:主键值`。

示例：

```java
public Object getObjectInclNullById(Integer id) {
    // 从缓存中获取数据
    Object cacheValue = cache.get(id);
    // 缓存为空
    if (cacheValue == null) {
        // 从数据库中获取
        Object storageValue = storage.get(key);
        // 缓存空对象
        cache.set(key, storageValue);
        // 如果存储数据为空，需要设置一个过期时间(300秒)
        if (storageValue == null) {
            // 必须设置过期时间，否则有被攻击的风险
            cache.expire(key, 60 * 5);
        }
        return storageValue;
    }
    return cacheValue;
}
```

##### （2）布隆过滤器（不能删除 key）

将需要查找的数据与数据库中已有的数据作一个比较，若数据库中不存在需要查找的数据，则以一定的概率直接返回，不去数据库中进行查找。

其它过滤器：布谷鸟过滤器（查到空 key 就返回）。

布隆过滤器原理：

- 左边为数据库中的元素，右边为要查询的元素。
- 只有当要查询的元素经过多个映射函数的哈希后，结果都为 1，才会放行，让请求到数据库中去进行查找。
- 可能误放，但概率很小。
- 优点：
  - 用小的空间解决大量数据的匹配问题。
  - 可以减少与数据库建立连接的次数，避免缓存穿透的问题。

若发生了缓存穿透，但是数据却不存在，则需要在 client 中增加 Redis 中的 key，并对其 value 做标记（表示该数据不存在）。

当数据库中增加了新元素，同时需要完成元素对 bloom 的添加。

![image-20220711172045090](E:\编程学习\学习笔记\面试笔记\img\image-20220711172045090.png)

总结：

- 含义：查询一个根本不存在的数据，即缓存层（Redis）和持久层（MySQL）中都不存在该数据。
- 危害：会造成用户多次请求直接穿透到系统底层，从而压垮服务器。
- 解决：
  - 为该 key 设置过期时间很短的 null value。
  - 布隆过滤器。
  - 布谷鸟过滤器。


#### 缓存雪崩

雪崩是指缓存中大批量热点数据过期后系统涌入大量查询请求，因为大部分数据在 Redis 层已经失效，请求渗透到数据库层，大批量请求犹如洪水一般涌入，引起数据库压力造成查询堵塞甚至宕机。

- 含义：缓存在短时间内大量失效。
- 危害：会造成后面的请求短时间内大量地来到服务器。

如何解决？

针对 Redis 服务不可用的情况：

- 采用 Redis 集群，避免单机出现问题整个缓存服务都没办法使用。
- 限流，避免同时处理大量的请求。
- 多级缓存架构。

针对热点缓存失效的情况：

- 设置不同的失效时间比如随机设置缓存的失效时间。将缓存的失效时间分散开：比如每个 key 的过期时间是随机的，防止同一时间大量数据过期现象发生，这样不会出现同一时间全部请求都落在数据库层。
- 如果缓存数据库是分布式部署，可以将热点数据均匀分布在不同的 Redis 和数据库中，有效分担压力。

> 参考资料：
>
> - [分布式 - Redis雪崩，穿透，击穿三连问_Q.E.D.的博客-CSDN博客](https://blog.csdn.net/qq_34272760/article/details/120751379?ops_request_misc=%7B%22request%5Fid%22%3A%22165821624816782350829224%22%2C%22scm%22%3A%2220140713.130102334.pc%5Fblog.%22%7D&request_id=165821624816782350829224&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~blog~first_rank_ecpm_v1~rank_v31_ecpm-18-120751379-null-null.185^v2^control&utm_term=Redis&spm=1018.2226.3001.4450)
> - [JavaGuide](https://javaguide.cn/cs-basics/data-structure/bloom-filter.html#什么是布隆过滤器)

### 2. 如何保证缓存和数据库的一致性？

读缓存：

- 命中缓存，直接返回。
- 缓存中没找到 -> 查询数据库 -> 更新缓存。

写缓存：

- 写缓存 -> 更新数据库 -> 删除缓存。
- 延迟双删：删除缓存 -> 更新数据库 -> 延迟 N 秒后再次删除缓存。
- Cache-Aside Pattern（旁路缓存模式）：遇到写请求时，更新 DB，然后直接删除对应的缓存。（推荐）

如果更新数据库成功，而删除缓存这一步失败的情况的话，简单说两个解决方案：

- **缓存失效时间变短（不推荐，治标不治本）**：我们让缓存数据的过期时间变短，这样的话缓存就会从数据库中加载数据。另外，这种解决办法对于先操作缓存后操作数据库的场景不适用。
- **增加 cache 更新重试机制（常用）**：如果 cache 服务当前不可用导致缓存删除失败的话，我们就隔一段时间进行重试，重试次数可以自己定。如果多次重试还是失败的话，我们可以把当前更新失败的 key 存入队列中，等缓存服务可用之后，再将缓存中对应的 key 删除即可。

> 参考资料：
>
> - [如何保证缓存和数据库的一致性？ - 掘金 (juejin.cn)](https://juejin.cn/post/7080466384664133663)
> - [缓存和数据库一致性问题，看这篇就够了 (qq.com)](https://mp.weixin.qq.com/s?__biz=MzIyOTYxNDI5OA==&mid=2247487312&idx=1&sn=fa19566f5729d6598155b5c676eee62d&chksm=e8beb8e5dfc931f3e35655da9da0b61c79f2843101c130cf38996446975014f958a6481aacf1&scene=178&cur_album_id=1699766580538032128#rd)

# Spring

## 基本概念

### 1. 什么是 Spring 框架？

Spring 是一款开源的轻量级 Java 开发框架，旨在提高开发人员的开发效率以及系统的可维护性。

我们一般说 Spring 框架指的都是 Spring Framework，它是很多模块的集合，使用这些模块可以很方便地协助我们进行开发，比如说 Spring 支持 **IoC（Inverse of Control：控制反转）**和 **AOP（Aspect-Oriented Programming：面向切面编程）**、可以很方便地对数据库进行访问、可以很方便地集成第三方组件（电子邮件、任务、调度、缓存等）、对单元测试支持比较好、支持 RESTful Java 应用程序的开发等。

### 2. Spring 包含的模块有哪些？

4.x 版本：

![image-20220806204955422](%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0%20-%20%E7%94%B3%E6%9D%89%E6%9D%89.assets/image-20220806204955422.png)

5.x 版本：

![image-20220806205024906](%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0%20-%20%E7%94%B3%E6%9D%89%E6%9D%89.assets/image-20220806205024906.png)

Spring5.x 版本中 Web 模块的 Portlet 组件已经被废弃掉，同时增加了用于异步响应式处理的 WebFlux 组件。

#### Core Container

Spring 框架的核心模块，也可以说是基础模块，主要提供 IoC 依赖注入功能的支持。Spring 其他所有的功能基本都需要依赖于该模块。

- **spring-core** ：Spring 框架基本的核心工具类。
- **spring-beans** ：提供对 bean 的创建、配置和管理等功能的支持。
- **spring-context** ：提供对国际化、事件传播、资源加载等功能的支持。
- **spring-expression** ：提供对表达式语言（Spring Expression Language）SpEL 的支持，只依赖于 core 模块，不依赖于其他模块，可以单独使用。

#### AOP

- **spring-aspects** ：该模块为与 AspectJ 的集成提供支持。
- **spring-aop** ：提供了面向切面的编程实现。
- **spring-instrument** ：提供了为 JVM 添加代理（agent）的功能。具体来讲，它为 Tomcat 提供了一个织入代理，能够为 Tomcat 传递类文件，就像这些文件是被类加载器加载的一样。没有理解也没关系，这个模块的使用场景非常有限。

#### Data Access / Integration

- **spring-jdbc** ：提供了对数据库访问的抽象 JDBC。不同的数据库都有自己独立的 API 用于操作数据库，而 Java 程序只需要和 JDBC API 交互，这样就屏蔽了数据库的影响。
- **spring-tx** ：提供对事务的支持。
- **spring-orm** ：提供对 Hibernate、JPA 、MyBatis 等 ORM 框架的支持。
- **spring-oxm** ：提供一个抽象层支撑 OXM (Object-to-XML-Mapping)，例如：JAXB、Castor、XMLBeans、JiBX 和 XStream 等。
- **spring-jms** : 消息服务。自 Spring Framework 4.1 以后，它还提供了对 spring-messaging 模块的继承。

#### Spring Web

- **spring-web** ：对 Web 功能的实现提供一些最基础的支持。
- **spring-webmvc** ：提供对 Spring MVC 的实现。
- **spring-websocket** ：提供了对 WebSocket 的支持，WebSocket 可以让客户端和服务端进行双向通信。
- **spring-webflux** ：提供对 WebFlux 的支持。WebFlux 是 Spring Framework 5.0 中引入的新的响应式框架。与 Spring MVC 不同，它不需要 Servlet API，是完全异步。

#### Messaging

spring-messaging 是从 Spring4.0 开始新加入的一个模块，主要职责是为 Spring 框架集成一些基础的报文传送应用。

#### Spring Test

Spring 的测试模块对 JUnit（单元测试框架）、TestNG（类似 JUnit）、Mockito（主要用来 Mock 对象）、PowerMock（解决 Mockito 的问题比如无法模拟 final, static， private 方法）等常用的测试框架支持的都比较好。

### 3. Spring、SpringMVC、SpringBoot 之间是什么关系?

#### Spring

略 ……

#### SpringMVC

SpringMVC 是 Spring 中的一个很重要的模块，主要赋予 Spring 快速构建 MVC 架构的 Web 程序的能力。它是一个轻量级的 Web 框架，通过把 Model、View、Controller 分离，将 web 层的职责进行解耦，把复杂的 web 应用分成逻辑清晰的几部分，简化开发，减少出错，方便组内开发人员之间的配合。

MVC：

- 模型（Model）：DAO 封装
- 视图（View）：html、css、js、jsp
- 控制器（Controller）：Servlet 封装

基本原理：

- 用户发送请求至前端控制器 DispatcherServlet。

- DispatcherServlet 收到请求调用 HandlerMapping 处理器映射器。

- 处理器映射器根据请求 url 找到具体的处理器，生成处理器对象及处理器拦截器（如果有的话），并返回给 DispatcherServlet。

- DispatcherServlet 通过 HandlerAdapter 处理器适配器调用处理器。

- 执行处理器（Controller，也叫后端控制器）。

- Controller 执行完成返回 ModelAndView。

- HandlerAdapter 将 controller 执行结果 ModelAndView 返回给 DispatcherServlet。

- DispatcherServlet 将 ModelAndView 传给 ViewReslover 视图解析器。

- ViewReslover 解析后返回具体 View。

- DispatcherServlet 对 View 进行渲染视图（即将模型数据填充至视图中）。

- DispatcherServlet 响应用户。

![image-20220806211645589](%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0%20-%20%E7%94%B3%E6%9D%89%E6%9D%89.assets/image-20220806211645589.png)

主控、核心：

- 前端控制器（DispatcherServlet）：负责接收请求、响应结果、转发数据，是整个流程控制的中心，由它调用其它组件处理用户的请求，可以减少组件之间的耦合度。

三大组件：

- 处理器映射器：根据请求的 URL 来查找对应的 Handler。
- 处理器适配器：通过 HandlerAdapter 对处理器进行执行（controller 中对应的方法），这是适配器模式的应用，通过扩展适配器可以对更多类型的处理器进行执行。
- 视图解析器：View Resolver 负责将处理结果生成 View 视图，View Resolver 首先根据逻辑视图名解析成物理视图名（即具体的页面地址），再生成 View 视图对象，最后对 View 进行渲染将处理结果通过页面展示给用户。

####  SpringBoot

Spring 的缺点：

- 配置工作繁琐：大量的 XML 配置文件。
- 依赖管理复杂：在环境搭建时，需要分析要导入哪些库的坐标，而且还需要分析导入与之有依赖关系的其他库的坐标，一旦选错了依赖的版本，随之而来的不兼容问题就会严重阻碍项目的开发进度。

如何解决？（SpringBoot）

SpringBoot 的优点：

- 通过提供自己的启动器依赖，简化项目配置。
  - Spring Boot 的启动器实际上就是一个依赖，这个依赖包含了对应的 jar 包以及自动配置，以前绝大多数 XML 配置都不再需要配置了。
  - 启动器中的自动配置无法实现所有内容的自动配置，还是需要进行少量的配置（properties、yml）。
  - 如果是 Spring 自己封装的启动器，那么其 artifact id 为：`spring-boot-starter-xxxx`。
  - 如果是第三方公司提供的启动，那么其 artifact id 为：`xxxx(如：框架名)-spring-boot-starter`。
  - 以后每次使用Spring Boot整合其他技术时首先需要考虑导入启动器。
- 在 Spring Boot 中直接嵌入了 Tomcat、Jetty、Undertow 等 Web 容器，在使用 SpringBoot 做 Web 开发时不再需要部署 War 文件（直接运行 jar 文件）。
- ……

> 参考资料：
>
> - [Nice，终于有人把SpringMVC讲明白了，太简单了…… (baidu.com)](https://baijiahao.baidu.com/s?id=1717728194505578801&wfr=spider&for=pc)

## IOC

### 1. 谈谈自己对于 Spring IoC 的了解？

#### 基本概念

**IoC（Inverse of Control：控制反转）**是一种设计思想，而不是一个具体的技术实现，它是将原本在程序中手动创建对象的控制权，交由 Spring 框架来管理。

- **控制** ：指的是对象创建（实例化、管理）的权力。
- **反转** ：控制权交给外部环境（Spring 框架、IoC 容器）。

例如：现有类 A 依赖于类 B

- 传统的开发方式：往往是在类 A 中手动通过 new 关键字来 new 一个 B 的对象出来。
- 使用 IoC 思想的开发方式：不通过 new 关键字来创建对象，而是通过 IoC 容器（Spring 框架）来帮助我们实例化对象。我们需要哪个对象，就直接从 IoC 容器里面去取即可。

![image-20220807100338484](%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0%20-%20%E7%94%B3%E6%9D%89%E6%9D%89.assets/image-20220807100338484.png)

#### 优点

将对象之间的相互依赖关系交给 IoC 容器来管理，并由 IoC 容器完成对象的注入，这样可以很大程度上简化应用的开发，把应用从复杂的依赖关系中解放出来。

IoC 容器就像是一个工厂一样，当我们需要创建一个对象的时候，只需要配置好配置文件/注解即可，完全不用考虑对象是如何被创建出来的。

- 对象之间的耦合度或者说依赖程度降低。
- 资源变的容易管理，比如你用 Spring 容器提供的话很容易就可以实现一个单例。

#### 示例

在没有使用 IoC 思想的情况下，Service 层想要使用 Dao 层的具体实现的话，需要通过 new 关键字在 `UserServiceImpl` 中手动 new 出 `IUserDao` 的具体实现类  `UserDaoImpl`。

![image-20220807102502239](%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0%20-%20%E7%94%B3%E6%9D%89%E6%9D%89.assets/image-20220807102502239.png)

传统方式的弊端：当开发过程中突然接到一个新的需求，针对 `IUserDao` 接口开发出了另一个具体实现类。因为 Server 层依赖了 `IUserDao` 的具体实现，所以我们需要修改 `UserServiceImpl` 中 new 的对象。如果只有一个类引用了 `IUserDao` 的具体实现，可能觉得还好，修改起来也不是很费力气，但是如果有许许多多的地方都引用了 `IUserDao` 的具体实现的话，一旦需要更换 `IUserDao` 的实现方式，那修改起来将会非常的头疼。

![image-20220807102605911](%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0%20-%20%E7%94%B3%E6%9D%89%E6%9D%89.assets/image-20220807102605911.png)

使用 IoC 的思想：我们将对象的控制权（创建、管理）交由 IoC 容器去管理，我们在使用的时候直接向 IoC 容器去要就可以了。

![image-20220807102628624](%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0%20-%20%E7%94%B3%E6%9D%89%E6%9D%89.assets/image-20220807102628624.png)

在实际项目中一个 Service 类可能依赖了很多其他的类，假如我们需要实例化这个 Service，你可能要每次都要搞清这个 Service 所有底层类的构造函数，这可能会把人逼疯。如果利用 IoC 的话，你只需要配置好，然后在需要的地方引用就行了，这大大增加了项目的可维护性且降低了开发难度。

#### 依赖注入

在 Spring 中， IoC 容器是 Spring 用来实现 IoC 的载体， IoC 容器实际上就是个 Map（key，value），Map 中存放的是各种对象（key：bean id，value：bean 对象）。

配置方式：XML 文件配置（太麻烦）-> 注解。 

IoC 最常见以及最合理的实现方式叫做：依赖注入（Dependency Injection，简称 DI）。

> 参考资料：
>
> - [面试被问了几百遍的 IoC 和 AOP ，还在傻傻搞不清楚？ (qq.com)](https://mp.weixin.qq.com/s/9_lUOU2tgVUf5VMZImfWJA)

### 2. 什么是 Spring Bean？

简单来说，Bean 代指的就是那些被 IoC 容器所管理的对象。

我们需要告诉 IoC 容器帮助我们管理哪些对象，这个是通过配置元数据来定义的。配置元数据可以是：XML 文件、注解或者 Java 配置类。

XML 示例：

```xml
<bean id="..." class="...">
   <constructor-arg value="..."/>
</bean>
```

### 3. 将一个类声明为 Bean 的注解有哪些?

- `@Component` ：通用的注解，可标注任意类为 `Spring` 组件。如果一个 Bean 不知道属于哪个层，可以使用 `@Component` 注解标注。
- `@Repository` : 对应持久层即 Dao 层，主要用于数据库相关操作。
- `@Service` : 对应服务层，主要涉及一些复杂的逻辑，需要用到 Dao 层。
- `@Controller` : 对应 Spring MVC 控制层，主要用户接受用户请求并调用 Service 层返回数据给前端页面。

### 4. @Component 和 @Bean 的区别是什么？

`@Component` 注解作用于类，而 `@Bean` 注解作用于方法。

`@Component` 通常是通过类路径扫描来自动侦测以及自动装配到 Spring 容器中（我们可以使用 `@ComponentScan` 注解定义要扫描的路径从中找出标识了需要装配的类自动装配到 Spring 的 bean 容器中）。`@Bean` 注解通常是我们在标有该注解的方法中定义产生这个 bean，`@Bean` 告诉了 Spring 这是某个类的实例，当我需要用它的时候还给我。

`@Bean` 注解比 `@Component` 注解的自定义性更强，而且很多地方我们只能通过 `@Bean` 注解来注册 bean。比如当我们引用第三方库中的类需要装配到 `Spring` 容器时，则只能通过 `@Bean`来实现。

`@Bean` 注解使用示例：

```java
@Configuration
public class AppConfig {
    @Bean
    public TransferService transferService() {
        return new TransferServiceImpl();
    }
}
```

上面的代码相当于下面的 xml 配置：

```xml
<beans>
    <bean 
    id="transferService"   
    class="com.acme.TransferServiceImpl"
    />
</beans>
```

下面这个例子是通过 `@Component` 无法实现的。

```java
@Bean
public OneService getService(status) {
    case (status)  {
        when 1:
                return new serviceImpl1();
        when 2:
                return new serviceImpl2();
        when 3:
                return new serviceImpl3();
    }
}
```

### 5. 注入 Bean 的注解有哪些？

Spring 内置的 `@Autowired` 以及 JDK 内置的 `@Resource` 和 `@Inject` 都可以用于注入 Bean。

|  Annotaion   |              Package               |    Source    |
| :----------: | :--------------------------------: | :----------: |
| `@Autowired` | `org.springframework.bean.factory` | Spring 2.5+  |
| `@Resource`  |         `javax.annotation`         | Java JSR-250 |
|  `@Inject`   |           `javax.inject`           | Java JSR-330 |

`@Autowired` 和 `@Resource` 使用的比较多一些。

区别：

`Autowired` 属于 Spring 内置的注解，默认的注入方式为 `byType`（根据类型进行匹配），也就是说会优先根据接口类型去匹配并注入 Bean （接口的实现类）。

这会有什么问题呢？ 当一个接口存在多个实现类的话，`byType` 这种方式就无法正确注入对象了，因为这个时候 Spring 会同时找到多个满足条件的选择，默认情况下它自己不知道选择哪一个。

这种情况下，注入方式会变为 `byName`（根据名称进行匹配），这个名称通常就是类名（首字母小写）。就比如说下面代码中的 `smsService` 就是我这里所说的名称，这样应该比较好理解了吧。

举个例子，`SmsService` 接口有两个实现类：`SmsServiceImpl1`和 `SmsServiceImpl2`，且它们都已经被 Spring 容器所管理。

```java
// 报错，byName 和 byType 都无法匹配到 bean
@Autowired
private SmsService smsService;

// 正确注入 SmsServiceImpl1 对象对应的 bean
@Autowired
private SmsService smsServiceImpl1;

// 正确注入 SmsServiceImpl1 对象对应的 bean
// smsServiceImpl1 就是我们上面所说的名称
@Autowired
@Qualifier(value = "smsServiceImpl1")
private SmsService smsService;
```

我们还是建议通过 `@Qualifier` 注解来显示指定名称而不是依赖变量的名称。

`@Resource` 属于 JDK 提供的注解，默认注入方式为 `byName`。如果无法通过名称匹配到对应的 Bean 的话，注入方式会变为 `byType`。

`@Resource` 有两个比较重要且日常开发常用的属性：`name`（名称）、`type`（类型）。

```java
public @interface Resource {
    String name() default "";
    Class<?> type() default Object.class;
}
```

如果仅指定 `name` 属性，则注入方式为 `byName`；如果仅指定 `type` 属性则注入方式为 `byType`。如果同时指定 `name` 和 `type` 属性（不建议这么做）则注入方式为：`byType` + `byName`。

```java
// 报错，byName 和 byType 都无法匹配到 bean
@Resource
private SmsService smsService;

// 正确注入 SmsServiceImpl1 对象对应的 bean
@Resource
private SmsService smsServiceImpl1;

// 正确注入 SmsServiceImpl1 对象对应的 bean（比较推荐这种方式）
@Resource(name = "smsServiceImpl1")
private SmsService smsService;
```

总结：

- `@Autowired` 是 Spring 提供的注解，`@Resource` 是 JDK 提供的注解。
- `Autowired` 默认的注入方式为 `byType`（根据类型进行匹配），`@Resource` 默认注入方式为 `byName`（根据名称进行匹配）。
- 当一个接口存在多个实现类的情况下，`@Autowired` 和 `@Resource` 都需要通过名称才能正确匹配到对应的 Bean。`Autowired` 可以通过 `@Qualifier` 注解来显示指定名称，`@Resource` 可以通过 `name` 属性来显示指定名称。

### 6. Bean 的作用域有哪些?

#### Spring 中 Bean 的作用域

- **singleton**：IoC 容器中只有唯一的 bean 实例。Spring 中的 bean 默认都是单例的，是对单例设计模式的应用。
- **prototype**：每次获取都会创建一个新的 bean 实例。也就是说，连续 `getBean()` 两次，得到的是不同的 Bean 实例。
- Web 应用相关：
  - **request**（请求域）：每一次 HTTP 请求都会产生一个新的 bean，该 bean 仅在当前 HTTP request 内有效。
  - **session**（会话域）：每一次来自新 session 的 HTTP 请求都会产生一个新的 bean，该 bean 仅在当前 HTTP session 内有效。
  - **application / global-session**（应用域）：每个 Web 应用在启动时创建一个 Bean（应用 Bean），该 bean 仅在当前应用启动时间内有效。
  - **WebSocket**：每一次 WebSocket 会话产生一个新的 bean。

#### 配置 bean 的作用域

xml 方式：使用 `scope` 关键字。

```java
<bean id="..." class="..." scope="singleton"></bean>
```

注解方式：使用 `@scope` 注解。

```java
@Bean
@Scope(value = ConfigurableBeanFactory.SCOPE_PROTOTYPE)
public Person personPrototype() {
    return new Person();
}
```

### 7. 单例 Bean 的线程安全问题了解吗？

大部分时候我们并没有在项目中使用多线程，所以很少有人会关注这个问题。单例 Bean 存在线程问题，主要是因为当多个线程操作同一个对象的时候是存在资源竞争的。

常见的有两种解决办法：

- 在 Bean 中尽量避免定义可变的成员变量。
- 在类中定义一个 `ThreadLocal` 成员变量，将需要的可变成员变量保存在 `ThreadLocal` 中（推荐）。

不过，大部分 Bean 实际都是无状态（没有实例变量）的（比如 Dao、Service），这种情况下， Bean 是线程安全的。

### 8. Bean 的生命周期了解么?

- Bean 容器找到配置文件中 Spring Bean 的定义。
- Bean 容器利用 Java Reflection API 创建一个 Bean 的实例。
- 如果涉及到一些属性值，就利用 `set()` 方法设置一些属性值。
- 如果 Bean 实现了 `BeanNameAware` 接口，就调用 `setBeanName()` 方法，传入 Bean 的名字。
- 如果 Bean 实现了 `BeanClassLoaderAware` 接口，调用 `setBeanClassLoader()`方法，传入 `ClassLoader` 对象的实例。
- 如果 Bean 实现了 `BeanFactoryAware` 接口，调用 `setBeanFactory()` 方法，传入 `BeanFactory` 对象的实例。
- 与上面的类似，如果实现了其他 `*.Aware` 接口，就调用相应的方法。
- 如果有和加载这个 Bean 的 Spring 容器相关的 `BeanPostProcessor` 对象，执行 `postProcessBeforeInitialization()` 方法。
- 如果 Bean 实现了`InitializingBean`接口，执行`afterPropertiesSet()`方法。
- 如果 Bean 在配置文件中的定义包含 init-method 属性，执行指定的方法。
- 如果有和加载这个 Bean 的 Spring 容器相关的 `BeanPostProcessor` 对象，执行 `postProcessAfterInitialization()` 方法。
- 当要销毁 Bean 的时候，如果 Bean 实现了 `DisposableBean` 接口，执行 `destroy()` 方法。
- 当要销毁 Bean 的时候，如果 Bean 在配置文件中的定义包含 destroy-method 属性，执行指定的方法。

![图片](%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0%20-%20%E7%94%B3%E6%9D%89%E6%9D%89.assets/640-16598426732161.jpeg)

> 参考资料：
>
> - [Spring Bean的生命周期（非常详细） - Chandler Qian - 博客园 (cnblogs.com)](https://www.cnblogs.com/zrtqsk/p/3735273.html)

## AOP

### 1. 谈谈自己对于 AOP 的了解？

AOP（Aspect-Oriented Programming：面向切面编程）能够将那些与业务无关，却为业务模块所共同调用的逻辑或责任（例如事务处理、日志管理、权限控制等）封装起来，便于减少系统的重复代码，降低模块间的耦合度，并有利于未来的可拓展性和可维护性。

Spring AOP 就是基于动态代理的，如果要代理的对象，实现了某个接口，那么 Spring AOP 会使用 **JDK Proxy**，去创建代理对象；而对于没有实现接口的对象，就无法使用 JDK Proxy 去进行代理了，这时候 Spring AOP 会使用 **Cglib** 生成一个被代理对象的子类来作为代理。

- JDK 动态代理：基于接口的代理
- Cglib：基于继承的代理

![image-20220729210541228](%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0%20-%20%E7%94%B3%E6%9D%89%E6%9D%89.assets/image-20220729210541228.png)

AOP 切面编程涉及到的一些专业术语：

|        术语         |                             含义                             |
| :-----------------: | :----------------------------------------------------------: |
|   目标（Target）    |                         被通知的对象                         |
|    代理（Proxy）    |             向目标对象应用通知之后创建的代理对象             |
| 连接点（JoinPoint） |         目标对象的所属类中，定义的所有方法均为连接点         |
| 切入点（Pointcut）  | 被切面拦截 / 增强的连接点（切入点一定是连接点，连接点不一定是切入点） |
|   通知（Advice）    | 增强的逻辑 / 代码，也即拦截到目标对象的连接点之后要做的事情  |
|   切面（Aspect）    |                     切面 = 切入点 + 通知                     |
|   Weaving（织入）   |       将通知应用到目标对象，进而生成代理对象的过程动作       |

### 2. Spring AOP 和 AspectJ AOP 有什么区别？

Spring AOP 属于运行时增强，而 AspectJ 是编译时增强。 Spring AOP 基于代理（Proxying），而 AspectJ 基于字节码操作（Bytecode Manipulation）。

Spring AOP 已经集成了 AspectJ ，AspectJ 应该算的上是 Java 生态系统中最完整的 AOP 框架了。AspectJ 相比于 Spring AOP 功能更加强大，但是 Spring AOP 相对来说更简单，

如果我们的切面比较少，那么两者性能差异不大。但是，当切面太多的话，最好选择 AspectJ ，它比 Spring AOP 快很多。

### 3. AspectJ 定义的通知类型有哪些？

- Before（前置通知）：目标对象的方法调用之前触发。
- After（后置通知）：目标对象的方法调用之后触发。
- AfterReturning（返回通知）：目标对象的方法调用完成，在返回结果值之后触发。
- AfterThrowing（异常通知） ：目标对象的方法运行中抛出 / 触发异常后触发。AfterReturning 和 AfterThrowing 两者互斥。如果方法调用成功无异常，则会有返回值；如果方法抛出了异常，则不会有返回值。
- Around（环绕通知）：环绕通知是所有通知类型中可操作范围最大的一种，因为它可以直接拿到目标对象，以及要执行的方法，所以环绕通知可以任意的在目标对象的方法调用前后搞事，甚至不调用目标对象的方法。

### 4. 多个切面的执行顺序如何控制？

方式一：使用 `@Order` 注解定义切面顺序

```java
// 值越小优先级越高
@Order(3)
@Component
@Aspect
public class LoggingAspect implements Ordered {
    // ...
}
```

方式二：实现 `Ordered` 接口并重写 `getOrder` 方法

```java
@Component
@Aspect
public class LoggingAspect implements Ordered {
    @Override
    public int getOrder() {
        // 返回值越小优先级越高
        return 1;
    }
    // ....
}
```

> 参考资料：
>
> - [招银网络一面：AOP 了解吗？有什么用？切面执行顺序如何控制？ (qq.com)](https://mp.weixin.qq.com/s/NUnaiVWADxzDOYPQdAwm6w)

## SpringMVC

### 1. 说说自己对于 Spring MVC 了解？

# Mybatis

## SQL

### 1. where 1=1 有什么用？

在 mybatis 中常用到 if 标签判断 where 子句后的条件，为防止首字段为空导致 sql 报错，就会用到 where 1 = 1。

```xml
<select id="queryBookInfo" parameterType="com.ths.platform.entity.BookInfo" resultType="java.lang.Integer"> 
    select count(id) from t_book t where 1=1
    <if test="title !=null and title !='' "> 
        AND title = #{title} 
    </if> 
    <if test="author !=null and author !='' "> 
        AND author = #{author}
    </if> 
</select>
```

这样会让索引失效并引发性能问题吗？

结论：where 1=1 也会走索引，不会影响查询效率，我们写的 sql 指令会被 mysql  进行解析优化成自己的处理指令，在这个过程中 1 = 1 这类无意义的条件将会被优化。使用 explain EXTENDED sql 进行校对，发现确实 where1=1 这类条件会被 mysql 的优化器所优化掉。

但是我们还是可以在 mybatis 中改变一下写法，因为毕竟 mysql 优化器也是需要时间的，虽然是走了索引，但是当数据量很大时，还是会有影响，所以我们建议代码这样写：

```xml
<select id="queryBookInfo" parameterType="com.ths.platform.entity.BookInfo" resultType="java.lang.Integer">
 select count(*) from t_book
    <where>
    <if test="title !=null and title !='' ">
        title = #{title} 
    </if>
    <if test="author !=null and author !='' "> 
        AND author = #{author}
    </if>
    </where> 
</select>
```

# Linux

## 常用命令

### 1. Linux 系统如何查看文件日志？权限管理？chmod 777 设置的权限是什么？

查看日志：

- more xxx.log：查看文件日志。
- tail -f/num xxx.log：动态读取文件日志/查看日志的最后 num 行的日志。

后台运行程序，并将日志输出到指定文件：

![Image](E:\编程学习\学习笔记\面试笔记\img\Image-16576146028385.png)

权限管理：

![Image1](E:\编程学习\学习笔记\面试笔记\img\Image1.png)

![Image2](E:\编程学习\学习笔记\面试笔记\img\Image2.png)

### 2. Linux 系统查看一个目录下文件的命令？ll 命令的别名是什么？

- ls：查看目录下文件的粗略信息。
- ll：等价于 ls -l（别名），展示详细信息。

# 后端

## 服务器

### 1. 一个服务器启动后做了哪些事？

- 操作系统为该服务器程序创建一个进程
- 一些初始化工作
- 创建 socket，绑定端口，监听？
- ……

# 测试

## 基本概念

### 1. 说一下测试方法有哪些？

#### 黑盒测试

黑盒测试一般用来确认软件功能的正确性和可操作性，目的是检测软件的各个功能是否能得以实现，把被测试的程序当作一个黑盒，**不考虑其内部结构**，在知道该程序的输入和输出之间的关系或程序功能的情况下，依靠软件规格说明书来确定测试用例和推断测试结果的正确性。

等价划分类、边界值法、因果图法、判定表法、场景法、正交实验设计法、错误推断法、功能图分析法等。

#### 白盒测试

白盒测试根据软件内部的逻辑结构分析来进行测试，**是基于代码的测试**，测试人员通过阅读程序代码或者通过使用开发工具中的单步调试来判断软件的质量，一般黑盒测试由项目经理在程序员开发中来实现。

语句覆盖、判定覆盖、条件覆盖、判定/条件覆盖、条件组合覆盖、路径覆盖等。

### 2. 对性能测试的理解？

- 性能测试的分类（性能测试、负载测试、压力测试、基准测试、稳定性测试和扩展性测试）
- 性能测试的指标（响应时间、TPS/QPS、并发量、吞吐量、系统资源开销）
- 性能测试的工具（Jmeter、locust）
- 性能测试的监控
- 性能测试的瓶颈分析案例

## 场景题

### 1. 怎么测试一个网页？

#### 功能测试

- 搜索框
  - 内容为空
  - 内容为空格
  - 超长字符串，看长度是否会被系统截取
  - 在合法字符串中加入空格、`，`、`@`、`#` 等特殊字符，验证搜索结果
  - 是否支持回车键开始搜索
  - 非法内容、敏感词汇
  - 内容为一个网页链接
  - 内容为拼音
  - 内容关联
  - 图片扫描
- 页面跳转
  - 是否正确跳转
  - 是否有空页和无效页
  - 是否会返回错误信息

- 多媒体元素是否正常加载
- 多语言支持功能

#### 界面测试

- UI 是否正确显示
- 布局是否合理、美观
- 错别字

#### 性能测试

- 压力测试、负载测试、轻度测试
- 搜索速度、页面跳转速度
- 并发量（最多抗多少人）、QPS
- 不同网速下的响应时间

#### 安全测试

- 登录功能：密码校验、权限设置
- 有人攻击首页，考虑对异常请求进行拦截
- 脚本禁用
- SQL 注入攻击
- 禁止敏感内容的检索
- 不允许访问被删除、被加密、未授权的数据

#### 兼容性测试

- 浏览器
- 操作系统
- 软件平台
- 数据库
- 硬件
- 网络

> 参考资料：
>
> - [搜索框测试用例（很详细哦）_qq_40955824的博客-CSDN博客_搜索框测试用例](https://blog.csdn.net/qq_40955824/article/details/89715166)
> - [测开面试题 - 搜索结果 - 知乎 (zhihu.com)](https://www.zhihu.com/search?q=测开面试题&utm_content=search_suggestion&type=content)

### 2. 如果一个项目明天要上线了，但是你今天没测试完，你会怎么做？

- **风险评估与上报**：项目明天要上线，但目前没有测试完，肯定是存在风险的，这个时候一定要先把风险点及时暴露出来，让项目组周知上线存在风险。
- **调配资源加班测试**：如果是用例没有走完，可以测试组内申请人力资源调配，协助完成测试，以及让产品经理尽快介入协助验收测试。
- **优先确保主要流程功能正常**：项目上线在即，应该确保项目主流程能够正常运行，根据二八原则，80% 的缺陷都集中在 20% 的主流程功能上，应重点保证主流程功能无误。

# 个人问题

## 自我介绍

注意：

- 不要让面试官自己去看简历
- 介绍工作能力而不是学习能力（能给公司带来什么？）
- 不要长篇大论介绍与岗位无关的内容

大纲：

- 您好
- 学校、专业、研究方向
- 项目
- 开发能力、掌握的技术栈
- 为公司服务的精神

自我介绍：

面试官您好，我叫申杉杉，我本科和硕士都就读于北京交通大学，通信工程专业，（其中硕士是两年制的专硕，目前是研二在读），在硕士期间专业成绩排名第 9，拿过一等学习奖学金。

首先，我们实验室的研究方向主要是做一些与无线通信相关的研究以及对应的软件开发工作，而我个人则主要是做与 4G LTE 移动通信网络相关的一些研究与开发工作，主要工作包括对 3GPP 协议进行研究，然后使用 C/C++ 以及 Python 语言在一些开源无线电仿真软件平台上对一些研究进行验证，后来的话也接手了一些后端开发的相关工作。

其次，我们实验室的主要开发语言是 C/C++，但是由于我在刚开始读研的时候，经过自己网上调查以及和师兄师姐们交流，发现自己比较想去互联网行业从事开发相关的工作，并且发现 Java 的岗位比较多，比较好找工作，所以在读研期间，自己还自学了 Java 方向的技术栈（Spring、MySQL、Redis），也自己独立动手从环境搭建到编码完成过网络上的一个开源的后端项目。

介绍项目：……

【社团】我本科的时候，也曾经加入过学校学生会，参与组织过一些比较大型的活动，因此我也具有良好的组织与沟通能力。然后，我本人比较喜欢运动，也曾经加入过学校的羽毛球院队，身体比较健康、性格也比较乐观。

【成都】最后，虽然我在北京上学，但是我的家乡在四川泸州，我也非常愿意在成都这个地方进行长久的发展，希望自己在今后的工作中能坚持不断地学习，在自己的岗位上贡献出自己的一份力量。

【银行】最后，银行业务不熟悉，保持不断学习的态度，在今后的工作中……，同时，我家也是四川的，我也非常愿意在成都、工行进行长远的努力与奋斗。

## 项目经历

### (1) 外卖订餐平台后端系统的研发

#### 项目描述

这个项目是自己从网上找的一个 Java web 的后端开源项目，主要是基于外卖订餐平台，根据项目前端以及后端的接口文档，实现一些常见的餐饮类业务。

#### 主要工作

- 使用 Java 语言基于 SpringBoot + MybatisPlus 框架设计并开发系统的后台。
- 实现后台系统的管理员登录、员工管理、菜品（以及口味）管理、套餐管理、分类管理等功能。
- 实现移动端的用户登录、短信验证、地址管理、加入购物车、下单等功能。
- 使用 MySQL + ShardingJDBC 实现 MySQL 的主从复制，读写分离，在完成数据持久化的同时，保证数据库系统的可用性。
- 使用 Redis + SpringCache 实现数据的缓存，减少直接访问数据库的次数，提高系统查询的性能。

#### 功能模块

- 公共功能模块（common）
  - BaseContext：使用 Threadlocal 保存登录用户的 id，并方便后续进行获取。
  - 自定义异常、全局异常处理器。
  - 对象映射器：指定 Java 对象与 Json 对象在转换时，不同数据类型的转换规则。
    - id：long（会发生精度丢失） -> string
    - 日期：LocalDateTime（数组形式） -> "yyyy-MM-dd HH:mm:ss"（更直观）
  - 元数据对象处理器：实现所有表中的公共字段的自动填充。
    - createTime
    - updateTime
    - createUser
    - updateUser
  - 通用返回结果：服务端响应的数据最终都会封装成此对象。
- 配置（config）
  - 配置 MybatisPlus 的分页插件。
  - 设置 Redis 的 key 的序列化器为 string 类型，方便查看。
  - WebMvcConfig：
    - 静态资源放行（映射）
    - 扩展消息转换器：将自己定义的对象映射器添加到框架的消息转换器集合中。
- 过滤器
  - 拦截请求：获取请求的 URL，通过路径匹配器判断是否放行。可以直接放行的请求：
    - 后台系统：登录、注销
    - 移动端系统：登录、短信发送
    - 静态资源
  - 通过 Session 判断用户的登录状态，如果已登录，则从 Session 获取当前用户的 id 并存进 ThreadLocal，然后直接放行。
    - 管理员用户
    - 移动端用户
  - 若用户未登录则提示错误信息。
- 工具类
  - 短信发送（阿里云）
  - 随机生成验证码（4 位数）

#### 缓存机制

##### （1）缓存是如何实现的？

![Image](%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0%20-%20%E7%94%B3%E6%9D%89%E6%9D%89.assets/Image.png)

![Image](%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0%20-%20%E7%94%B3%E6%9D%89%E6%9D%89.assets/Image-16613531204791.png)

`@CachePut`：

- 作用：将方法的返回值放到缓存中。
- 使用方法：`@CachePut(value = "一类缓存的名称", key = "...")` 
- value 是一类缓存的集合，每一个缓存名称下面可以有多个 key。
- key 的名称应该是动态生成的，不能写死。使用 `#...` 语句设置 key 的值。

`@CacheEvict`：

- 作用：清理指定缓存。
- 使用方法：`@CacheEvict(value = "...", key = "...")`
- 用于 delete、update 方法。

`@Cacheable`：

- 作用：先查缓存，有则直接返回，否则再去数据库中进行查询，并设置到缓存中。
- 使用方法：`@Cacheable(value = "...", key = "...")`
- 可以添加条件，只有当从数据库查询到的结果不为空时，才将结果存入缓存：`@Cacheable(value = "...", key = "..."， condition = "#result != null")`，该条件等价于 `unless = "#result == null"`。

##### （2）使用过 Redis 的哪些数据结构？如何设计缓存的 key？

```java
@RestController
@RequestMapping("/setmeal")
@Slf4j
public class SetmealController {
    
    // 新增套餐
    @PostMapping
    @CacheEvict(value = "setmealCache", allEntries = true) // 删除该分类下的所有缓存
    public R<String> save(@RequestBody SetmealDto setmealDto) {
        log.info("套餐信息：{}", setmealDto);
        setmealService.saveWithDish(setmealDto);
        return null;
    }
    
    // 删除套餐
    @DeleteMapping
    @CacheEvict(value = "setmealCache", allEntries = true) // 删除该分类下的所有缓存
    public R<String> delete(@RequestParam List<Long> ids) {
        log.info("ids:{}", ids);
        setmealService.removeWithDish(ids);
        return R.success("删除成功");
    }
    
    // 修改套餐
    @PutMapping
    @CacheEvict(value = "setmealCache", allEntries = true) // 删除该分类下的所有缓存
    public R<String> update(@RequestBody SetmealDto setmealDto) {
        setmealService.updateWithDish(setmealDto);
        return R.success("修改套餐成功");
    }
    
    // 根据套餐分类查询对应的套餐集合
    @GetMapping("/list")
    @Cacheable(value = "setmealCache", key = "#setmeal.categoryId+'_'+#setmeal.status") // 设置缓存，并动态拼接 key
    public R<List<Setmeal>> list(Setmeal setmeal) {
        LambdaQueryWrapper<Setmeal> queryWrapper = new LambdaQueryWrapper<>();
        queryWrapper.eq(setmeal.getCategoryId() != null,
                Setmeal::getCategoryId, setmeal.getCategoryId());
        queryWrapper.eq(setmeal.getStatus() != null,
                Setmeal::getStatus, setmeal.getStatus());
        queryWrapper.orderByDesc(Setmeal::getUpdateTime);

        List<Setmeal> list = setmealService.list(queryWrapper);

        return R.success(list);
    }
    
}
```

##### （3）缓存过期时间？

```java
@RestController
@RequestMapping("/user")
@Slf4j
public class UserController {
    
    // 发送手机短信验证码
    @PostMapping("/sendMsg")
    public R<String> sendMsg(@RequestBody User user, HttpSession session) {
        // 获取手机号
        String phone = user.getPhone();

        if (StringUtils.isNotEmpty(phone)) {
            // 生成随机的 4 位验证码
            String code = ValidateCodeUtils.generateValidateCode(4).toString();
            log.info(code);

            // 调用阿里云提供的短信服务 API 完成发送短信
            // SMSUtils.sendMessage("瑞吉外卖","",phone,code);

            // 需要将生成的验证码保存到 session
            // session.setAttribute(phone, code);
            // 改进：将生成的验证码缓存到 Redis 中，并设置有效期为 5 分钟
            redisTemplate.opsForValue().set(phone,code,5, TimeUnit.MINUTES);

            return R.success("手机验证码短信发送成功");
        }

        return R.error("短信发送失败");
    }
    
    // 移动端用户登录
    @PostMapping("/login")
    public R<User> login(@RequestBody Map map, HttpSession session) {
        // 获取手机号和验证码
        String phone = map.get("phone").toString();
        String code = map.get("code").toString();

        // 从 session 中获取保存的验证码
        // Object codeInSession = session.getAttribute(phone);
        // 改进：从 Redis 中获取保存的验证码
        Object codeInSession = redisTemplate.opsForValue().get(phone);

        // 进行验证码的对比（页面提交的验证码 =? Redis 中缓存的验证码）
        if (codeInSession != null && codeInSession.equals(code)) {
            // 如果匹配成功，说明登录成功
            // 判断当前手机号对应的用户是否为新用户，如果是新用户就自动完成注册
            LambdaQueryWrapper<User> queryWrapper = new LambdaQueryWrapper<>();
            queryWrapper.eq(User::getPhone, phone);
            User user = userService.getOne(queryWrapper);
            if (user == null) {
                user = new User();
                user.setPhone(phone);
                user.setStatus(1);
                userService.save(user);
            }

            session.setAttribute("user", user.getId());

            // 用户登录成功后，需要删除 Redis 中缓存的验证码
            redisTemplate.delete(phone);

            return R.success(user);
        }

        return R.error("用户登录失败");
    }

}
```

#### 遇到的问题

根据 id 修改用户数据，没有报错，却无法完成修改：

- 问题：分页查询返回的 json 数据中用户 id 的类型为 long，id 长 19 位，而前端 js 在将 id 发送给后端时会发生精度的丢失，它只能保证 long 类型数据前 16 位数据的准确性（剩余的会四舍五入），会造成查询的 id 在数据库中根本不存在。
- 解决：自定义对象映射器，在将 Java 对象序列化的时候，将 long 类型的数据转换为 string 类型。

在新增、修改数据时，某些表中需要存储操作的用户 id：

- 问题：用户 id 无法直接在业务层获取到。
- 解决：使用 ThreadLocal，在用户登录时，将用户 id 存入 ThreadLocal，方便随时获取。

#### 项目部署

- 服务器 A：
  - Nginx：部署前端项目，配置反向代理
  - MySQL：主库
- 服务器 B：
  - Jdk、Git、Maven、Tomcat：运行项目 jar 包。
  - MySQL：从库
- 服务器 C：
  - Redis：缓存

### (2) LTE 安全仿真与验证平台的研发

#### 面试简述

项目描述：

【背景】4G LTE 是目前最主流的移动通信技术标准，其用户可能会面临敏感信息泄露、位置追踪、拒绝服务等风险。

【原因】目前该领域内对 LTE 网络的安全分析以及攻击验证的研究还比较少，并且对于一些研究团队提供的用于进行仿真的开源协议栈也缺少相关的文档，研究人员只能通过阅读特别繁杂的协议、零散的论文、以及大量的协议栈代码来进行分析，学习成本太高，对于一些进行纯理论研究的人员很不友好。

【目的】因此我们就开发了这样一个用于进行 LTE 网络攻击验证的平台，用户只需要了解与 LTE 网络相关的通信知识，而不必关注具体的代码是如何实现的，就可以利用该平台进行 LTE 网络安全的分析工作。 

开发团队（2 人）：

- 师兄：客户端平台的开发。
- 本人：协议栈内部服务端的开发、使用客户端编写 Python 脚本进行测试和验证。

系统架构：

- 客户端、服务端
- UE、基站（Linux 实体机）、核心网（Linux 虚拟机）

主要工作：

- 学习 LTE 移动通信技术标准，了解一些移动通信以及 LTE 系统架构的基本概念与原理。
- 阅读与 LTE 网络安全研究相关的论文，分析网络中可能存在的一些异常情况，以及用户可能会面临的网络攻击。
- 阅读协议栈代码，对异常情况以及网络攻击进行模拟，将每一种异常或者攻击封装为函数接口，供客户端调用。
- 建立与客户端的 socket 连接。
- 代码插桩：当 UE（用户）接入 EPC 后，截断协议栈内部的信令流程，获取协议栈内信令的数据，并发送给客户端。
- 客户端编写脚本，从服务端发送的消息接收参数（消息类型、用户信息，如：UE id 等），填入参数并发送客户端指令到协议栈中的服务端。
- 服务端封装协议栈提供的内部函数，根据接收到的客户端指令，让协议栈执行自定义的信令流程，模拟一些网络攻击以及可能会出现的异常情况。

#### 背景介绍

LTE 网络是目前最新一代的移动通信标准，其用户可能会面临敏感信息泄露、位置追踪、拒绝服务的风险。

以上关于 LTE 网络的安全研究主要可分为两类：标准分析和模糊测试。

- 标准分析指通过阅读 3GPP 标准，建立模型并寻找漏洞的过程，此类研究通常包括寻找漏洞方法论及真实网络环境验证。
- 模糊测试指制作自动化分析工具，对信令的某些字段实施模糊测试。

研究目的：目前关于 LTE 网络攻击验证的研究较少，各研究团队对开源协议栈的分析也不尽相同，无法形成通用文档，因此急需开发一个简单易用的 LTE 系统仿真与验证平台。

#### 主要工作

分析和修改开源协议栈中的流程从而验证攻击，需要读懂开源协议栈的代码并且能够进行修改。

难点：

- 此类开源协议栈由于对时延具有较高要求，使用的语言普遍偏底层，代码量大，例如对 srsRAN 的分析及修改包含 537 个文件内共计超九万行的代码。
- 缺乏足够的文档辅助进行分析。

特点：

- 本平台的设计采用 C/S 架构。
- 服务端集成在开源协议栈中，可以拦截并将消息发送到客户端，同时依据从客户端接收的指令向网络内发送信令。
- 客户端由 Python 库构成，用户使用库函数编写脚本，根据用户脚本，客户端向服务端发送指令，或是取回消息进行展示等，二者之间利用 socket 连接进行通信。

本平台使用模块化设计方法：

- 服务端：插桩代码（拦截信令并发送到客户端）、socket 通信的建立、消息处理。
- 客户端：以 Python 库形式呈现，主要模块有：消息 ID 定义、消息结构体定义、编解码卸载、socket 通信、函数接口。

模块功能介绍：

- 服务端
  - 消息处理：此模块负责在服务端处理 LTE 网络内部消息及客户端指令。一是拦截指定消息流并回传客户端。二是解析客户端指令，向网络内部注入消息，主要技术包含：网络包解析，消息 ID 识别、协议栈内部函数调用等。
  - Socket 通信：此模块负责建立客户端和服务端间的消息通路，在端间提供面向连接、有序、实时的连接，传递 LTE 内部流量及用户控制指令。
  - 函数接口：此模块将信令发送和接收解析流程封装为简单易用的函数，自底向上地整合字节流解析、消息/指令编解码、上下文获取等功能。自动提取上下文信息形成默认参数；减少必选参数，最大限度地简化用户接口；提供足够的可选参数，满足自定义需求。
- 客户端
  - 消息 ID 定义：此模块包含了 socket 通信所需消息及协议栈内部对于消息 ID 的宏定义，在通信中用于将消息名称映射到消息 ID，减少开销，在用户处用于提供可读版本的消息名称，方便脚本编写。
  - 消息结构体定义：此模块是协议栈中 LTE 网络消息的 Python 重写，将字节流转化为结构体，允许用户通过点运算符访问结构体内的成员。
  - 编解码卸载：此模块提供消息编解码的 C 语言实现，以动态链接库的形式加载到客户端中，以加快处理速度。

#### 可能会问的问题

##### 1. 看过哪些 3GPP 的协议？

EPC：

- **TS 23.002**：gives an overview the architecture of the 3GPP system. In particular, it describes all the network elements used in the EPC and also in legacy core networks.
- **TS 23.401**：defines the architecture of the EPC for E-UTRAN access.
- **TS 23.402**：defines the architecture enhancements for non-3GPP accesses.
- **TS 24.008**：defines inter-system mobility between LTE and 2G/3G.
- **TS 24.301**：defines the protocol details of the NAS.
- **TS 24.303**：defines inter-system mobility between LTE and non-3GPP accesses.

E-UTRAN：

- **TS 36.300**：Overall description.
- **TS 36.304**：User Equipment (UE) procedures in idle mode.
- **TS 36.321**：Medium Access Control (MAC) protocol specification.
- **TS 36.322**：Radio Link Control (RLC) protocol specification.
- **TS 36.323**：Packet Data Convergence Protocol (PDCP) specification
- **TS 36.331**：Radio Resource Control (RRC); Protocol specification.

重点看过的：

- **3GPP TS 23.002**：EPC 总述
- **3GPP TS 23.401**：介绍 EPC 中与无线接入相关的架构与功能 
- **3GPP TS 36.300**：E-UTRAN 总述

##### 2. 遇到过什么困难？怎么解决的？

**（1）客户端发送指令后，服务端却没有执行对应的流程**

检查客户端和服务端之间 sctp 数据的交互，在客户端侧使用 wireshark 进行抓包，使用 sctp 协议进行过滤，如果客户端与服务端运行在同一个系统下，还需要使用对应的端口进行过滤。

客户端的每一种指令，对应一种类型的攻击（服务端中的一种流程），经抓包发现客户端设定的指令 ID 与服务端设定的指令 ID 对应出错，校对一致后解决。

**（2）客户端与服务端之间交互数据的选取**

LEAP 想要实现的就是将编解码卸载到 LEAP 脚本所在的主机上，实现信息的按需获取。所以它在信息发送时会将整条完整的信息发送给脚本，由脚本使用共享库进行解码。

设想一下，如果我们需要获取多个字段的信息，那就有以下两种实现方式：

- 需要获取几个字段的信息，就需要插入多少个插桩代码，分别将协议栈处理程序解码的相应结果传给脚本，这种情况下，脚本可以直接进行显示，实现复杂度可以很低，但协议栈处理程序需要添加很多东西，实现复杂度较高，属于集中式设计，第三方人为修改与协议栈处理程序耦合度较高。
- 协议栈处理程序中只插桩一条代码，将接收到的整条 Nas 消息传给脚本，脚本通过共享库进行解码，按需获取需要的字段信息，这种情况下，脚本由于需要自己解码，实现复杂度会高一些，但协议栈处理程序改动很小，只需要添加一条插桩代码，实现复杂度较低，属于分布式设计，第三方人为修改与协议栈处理程序耦合度较低。

总的来说，就是希望尽可能少地改动协议栈处理代码，将主要的算力和处理工作交给第三方（脚本），减轻人为修改和协议栈处理代码的耦合，减少协议栈处理程序为实现第三方要求而进行的不必要的处理，将集中化修改改为分布式修改。

UE 发起 Attach 后，在 MME 的处理 s1ap 接口上的数据的函数中，截取 Nas 消息并发送到客户端，客户端解码后可以获取到如 UE 的 IMSI 等信息，可以用于后续的攻击模拟和验证。

**（3）程序运行后崩溃**

检查打印日志中的堆栈轨迹，发现是结构体指针在创建时忘记分配对应的堆内存导致的。

**（4）插桩代码处，服务端发送数据后，在接收到客户端的数据并进行相应处理之前，插桩代码后的部分代码会先得到执行，从而造成信令流程混乱**

目前还未解决。

##### 3. 为什么选择使用 SCTP 协议建立 socket 连接？SCTP 的优势是什么？使用的哪个库？

兼有 TCP 和 UDP 的特点：

- TCP：面向连接、可靠、全双工、端到端、流量/拥塞控制。
- UDP：面向消息（数据不分包，按块传输）。

连接 -> 关联：

- 多宿（一个节点可以有多个 ip 地址）
- 多流（数据流之间互不干扰，互相之间不会阻塞）

四次握手（安全，可以预防拒绝服务攻击）

![Image](E:\编程学习\学习笔记\面试笔记\img\Image-16578555821481.png)

总结：

- 能够保证数据传输的可靠性
- 数据按块传输，不会出现分包问题
- 可以解决数据报文的拥塞问题，当客户端出现错误后，不会造成协议栈的阻塞从而影响协议栈正常流程
- 安全性更高，可以有效防止泛洪攻击

使用的库：

```c++
#include <netinet/in.h> 
// 设置 sockaddr_in 地址信息
// 设置端口 htons(PORT)

#include <netinet/sctp.h>
// sctp_sendmsg、sctp_recvmsg 等
```

##### 4. 服务端的 socket 是如何建立的？

![Image](%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0%20-%20%E7%94%B3%E6%9D%89%E6%9D%89.assets/Image-16639888882071.png)

在 MME 初始化的时候，使用 `pthread_create(...)` 创建 socket 线程。

获取 socket 描述符：`socketfd = socket(AF_INET, SOCK_STREAM, IPPROTO_SCTP)` ，

- AF_INET：IPv4 网络通信
- SOCK_STREAM：流格式
- 协议类型：SCTP

`sockaddr_in` 是 internet 环境下套接字的地址形式。所以在网络编程中我们会对 `sockaddr_in` 结构体进行操作，建立所需的信息。

```c++
#include <netinet/in.h>
#include <netinet/sctp.h>

#define PORT 7897

int socketfd, assocfd; // 套接字描述符
struct sockaddr_in s_addr, r_addr; // 地址信息
socklen_t len;

// 1.使用 socket 创建套接字
if (-1 == (socketfd = socket(AF_INET, SOCK_STREAM, IPPROTO_SCTP))) {
    printf("fail to create SCTP socket!\n");
};
printf("SCTP socket create success!\n");

// 2.填写地址信息
memset(&s_addr, 0x00, sizeof(s_addr));
s_addr.sin_family      = PF_INET;
s_addr.sin_port        = htons(PORT);
s_addr.sin_addr.s_addr = inet_addr("192.168.137.99");

// 3.使用 bind 绑定服务器套接字地址
if (-1 == bind(socketfd, (struct sockaddr*)&s_addr, sizeof(s_addr))) {
    printf("bind failed!\n");
}
printf("bind success!\n");

// 4.设置 socket 选项
struct sctp_initmsg initmsg;
memset(&initmsg, 0, sizeof(initmsg));
initmsg.sinit_num_ostreams  = 5;
initmsg.sinit_max_instreams = 5;
initmsg.sinit_max_attempts  = 4;
setsockopt(socketfd, IPPROTO_SCTP, SCTP_INITMSG, &initmsg, sizeof(initmsg));

// 5.使用 listen 监听端口，等待连接
listen(socketfd, 5);
printf("listen success!\n");

// 6.使用 accept 接受连接请求，并返回对应于此次连接的套接字
len = sizeof(struct sockaddr);
assocfd = accept(socketfd, (struct sockaddr*)&r_addr, &len);
if (-1 == assocfd) {
  printf("accept failed!\n");
}
printf("accept success!\n");

// 7.使用 send 和 recv 与客户端进行通信
// ...
```

> 参考资料：
>
> - [C++知识分享： Socket 编程详解，万字长文_一起学编程的博客-CSDN博客_c++ socket编程](https://blog.csdn.net/qq_42366672/article/details/120019283)
> - [C++ socket编程_umr410的博客-CSDN博客_c++ socket](https://blog.csdn.net/qq_43571448/article/details/100522659)
> - [Socket编程（简单（C++）实现TCP通信）_一包辣条包邮！的博客-CSDN博客_socket编程](https://blog.csdn.net/weixin_43064827/article/details/118276407?spm=1001.2101.3001.6650.9&utm_medium=distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromBaidu~Rate-9-118276407-blog-120019283.pc_relevant_antiscanv2&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromBaidu~Rate-9-118276407-blog-120019283.pc_relevant_antiscanv2&utm_relevant_index=15)
> - [Socket编程（简单（C++）实现TCP通信）_一包辣条包邮！的博客-CSDN博客_socket编程](https://blog.csdn.net/weixin_43064827/article/details/118276407?spm=1001.2101.3001.6650.9&utm_medium=distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromBaidu~Rate-9-118276407-blog-120019283.pc_relevant_antiscanv2&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromBaidu~Rate-9-118276407-blog-120019283.pc_relevant_antiscanv2&utm_relevant_index=15)[C++ Socket编程实例解析_u012391923的博客-CSDN博客_socket编程c++实例](https://blog.csdn.net/u012391923/article/details/52881938?spm=1001.2101.3001.6650.3&utm_medium=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-3-52881938-blog-120019283.pc_relevant_antiscanv2&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-3-52881938-blog-120019283.pc_relevant_antiscanv2&utm_relevant_index=6)
> - [socket函数的domain、type、protocol解析_NoneSec的博客-CSDN博客_socket type](https://blog.csdn.net/liuxingen/article/details/44995467)
> - [【UNIX网络编程】|【07】SCTP协议探究_Jxiepc的博客-CSDN博客_sctp_getpaddrs](https://blog.csdn.net/weixin_45926547/article/details/125513954)

### (3) PDDS 宽带集群通信系统

#### 项目描述

本项目是课题组与赛普乐公司的校企合作项目，主要是基于 3GPP MCPTT 协议以及公司需求，使用 C/C++ 语言设计并开发项目的后端系统。该系统底层基于 LTE 移动通信网络，广泛应用于公安、地铁以及机场等需要调度指挥的场景，目前在使用本系统的单位包括南宁公安、天津公安、北京地铁、深圳机场等。

> MCPTT（Mission Critical Push to Talk，关键任务一键通）：
>
> MCPTT 协议是 3GPP 组织提出的基于 LTE 的新一代宽带集群通信协议。PDDS 系统是基于 MCPTT 协议的集群通信系统。 MCPTT 系统的主要功能为用户注册、用户鉴权、组附属、单呼、组呼、视频呼叫、话语权控制、优先级呼叫以及短信发送等。

项目人员：

- 赛普乐公司：负责项目的前端系统，约 5-6 人
- 实验室同学：负责项目的客户端（终端）以及后端系统，各约 2-3 人

后端系统：所有组件均部署在一台阿里云服务器上（运存：2G、内存：40G）。

#### 系统架构

- http 服务器：
  - **推送服务器**：向终端推送在线联系人、群组成员、文件、图片等数据
  - **web 服务器**：负责管理系统中用户相关的信息和通话组相关的信息
    - 用户身份管理：号码（唯一的 mcptt id）、用户名、密码
    - 组管理：通话组、成员列表
- SIP 服务器：
  - C 面（控制流）：	
    - **调度服务器**：解包、处理、封包、转发（相当于 Java SpringMVC 中的前端控制器）
    - **交换服务器**：通过处理信令，实现终端登录、组附属、呼叫建立、 呼叫挂断、话语权授予、话语权释放等业务
  - D 面（数据流）：
    - **媒体网关**：负责在呼叫过程中为终端转发语音等媒体资源。当终端发起一路呼叫后，调度服务器会为每路呼叫分配媒体流接收端口并告知媒体网关，然后媒体网关会将接收的用户媒体流（语音数据）转发至相应的用户和 Web 服务器。
- 数据库：
  - **数据库代理服务器**：负责管理系统的数据，并为其它组件提供增删改查的接口。
  - MySQL 服务器

> SpringMVC：
>
> ![image-20221214095737852](%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0%20-%20%E7%94%B3%E6%9D%89%E6%9D%89.assets/image-20221214095737852.png)

#### 数据库

- 用户相关：
  - **用户基本信息表**：mcptt id（用户号）、用户名、终端使用的 ip 和端口号、设备状态、地理位置（经度、纬度）、呼叫优先级等
  - **用户登录信息表**：mcptt id、用户名、密码等
  - **网管信息表**：用户名、密码
  - **用户简档表**：mcptt id、配置信息
  - **用户单户列表**：mcptt id、用户允许进行单呼的列表（被呼 mcptt id）
  - **用户组呼列表**：mcptt id、该用户所在的群组 id
- 群组相关：
  - **组信息表**：group id、组名、组类型、呼叫权限、组优先级
  - **组配置表**：group id、配置信息
  - **组成员表**：group id、mcptt id
- 短信信息表：发送方、接收方、短信类型、数据
- 基站信息表：基站号、ip、端口、类型、状态

#### 协议栈

调度消息格式：

- 功能码
- 子功能码
- 消息长度
- 保留字段
- 消息数据

调度消息类型：

- 客户功能：Login、Logout、Sleep、Awake 等
- 语音功能：Setup、Alert、Connect 等
- 数据功能
- 用户管理功能
- 视频传输功能
- 非实时业务

语言传输，在 UDP 的基础上使用 RTP 对语音数据包进行封装。

> RTP 和 UDP 都属于传输层协议。

![image-20221214094103264](%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0%20-%20%E7%94%B3%E6%9D%89%E6%9D%89.assets/image-20221214094103264.png)

#### 调度服务器

- **SIP 模块**：解析来自终端的 SIP 信令，提取需要的参数，并封装成 TETRA 信令，将其发送至控制 MCPTT 实体服务器。
- **TETRA 模块**：解析来自控制 MCPTT 实体服务器的 TERTA 信令，提取需要的参数，并封装成 SIP 信令，将其发送至终端。
- **Floor Control 模块**：接收终端的打洞信令和 Floor Control 信令：接收打洞信令，记录终端接收 Floor Control 信令的端口；接收 Floor Control 信令，并将其转换为 TETRA 信令发送至控制 MCPTT 实体服务器。在接收到控制 MCPTT 实体服务器发送的话语权指示信令之后，将其转换为 Floor Control 信令，并发送到通过打洞机制记录的终端端口。
- **HTTP 模块**：解析终端上报的 SIP MESSAGE 信令中位置的相关参数，将其封装成符合 HTTP 协议的 HTTP 信令发送给 Web 服务器。
- 接收媒体网关为呼叫分配的媒体端口，将其通知给相应的终端。

使用谷歌开源日志框架 `<glog/logging.h>`，可以设置日志最大大小，写满磁盘即停止等配置。

使用 `epoll` IO 多路复用（单线程）管理 socket 连接：

- `listenfd`：接受新连接
- `msc_recvfd`：处理来自交换和媒体网关的 UDP 数据
- `events[i].events & EPOLLIN`：处理来自终端的 TCP 数据

#### 遇到的问题

##### 1 系统功能失效问题

问题：后端服务器遇到故障或某些功能出现 bug。

解决：公司运维人员获取服务器日志与抓包结果并发给我，我根据日志与抓包结果，先定位出现问题的组件，然后再具体定位到可能出现问题的代码位置，最后修复 bug 并重新上线项目。

##### 2 服务器无法接收数据问题

问题：在接收处理函数中，流程因中途提前退出，没有关闭对应 socket 的 fd，导致服务器的 fd 满了，无法创建新的 socket 接收数据。

解决：修改函数逻辑，只要函数退出就关闭对应的 fd。

##### 3 服务器崩溃问题

问题：音频帧需要按序接收，需要先由关键帧初始化指针，再接收普通帧。若没有收到关键帧，并直接接收普通帧，会造成给野指针赋值，程序直接崩溃。

解决：增加全局标志位，判断已经接收到了关键帧后，再进行后续流程，否则直接退出所在函数。

#### 提问

##### 1 你这个 PDDS 系统的功能有啥用？为什么不能直接打电话或者用微信语音进行交流？

PDDS 系统的优点：

- **呼叫建立快**：支持摘挂机呼叫、直接建立呼叫
- **调度能力强**：支持单呼、组呼、广播、紧急呼叫等多种功能
  - **广播呼叫**：是指调度台同时对全部通话组的呼叫，广播呼叫功能允许调度员同时对全部组的所有成员讲话。但各个组之间是相互独立的，组间的用户不能互相通信，其实现方式只需在 Setup 消息的 calledParty 参数上选择预先规定的组号。
  - **紧急呼叫**：是无线用户处在紧急状态时的单呼。紧急呼叫具有最高的优先级，这样才能保证在任何情况下都能建立呼叫。当无线资源全部被占用时，紧急呼叫能让系统自动释放低优先级呼叫所占用的无线资源。
- **功能多样化**：支持语音、视频、短信、文件等多种数据的传输

反问：那既然已经有支付宝了，为什么还会有微信支付呢？

##### 2 这个系统的使用人数（用户规模）是多少？

之前有约 600 人在使用，现在在用的只有约 70 个用户。

## 学习方法

### 1. 你是如何进行学习的？看过什么书？

Java 基础：

- b 站视频（黑马程序员）：基本语法
- 《Head First Java》：集合与泛型
- 《Java 核心技术卷 1》：查漏补缺

算法和数据结构：

- 左程云算法视频：基础知识与原理
- 《剑指 Offer》：经典题目解法
- Leetcode：刷题练习
- 代码随想录

计算机网络：

- 本科与研究生课程：计算机网络、高等路由等
- 《图解 HTTP》
- 《图解 TCP/IP》

数据库：

- b 站视频：基本概念与原理
- 《SQL 基础教程》：查漏补缺
- 项目实战

### 2. 遇到问题是怎么解决的？

- 百度、谷歌
- CSDN 博客
- 掘金技术社区
- 论文
- 分析工具

## 简历修改

![image-20220715105122529](E:\编程学习\学习笔记\面试笔记\img\image-20220715105122529.png)

![image-20220715105144671](E:\编程学习\学习笔记\面试笔记\img\image-20220715105144671.png)

![image-20220715105204451](E:\编程学习\学习笔记\面试笔记\img\image-20220715105204451.png)

# 面试记录

## 360

### xxx部门

#### 笔试

##### 计算机网络

NP 难问题？

对称秘钥分发机构？ KDC：秘钥分发中心

DNS 端口号？53

##### 操作系统

信号量的初值为 2，当前值为 -3 代表有几个进程阻塞？
- 信号量控制互斥问题时，其初值往往代表资源的个数。本题初值为 2，说明该种资源数量 2 个。
- 当进程将 2 个资源全部占有之后，信号量值减至 0，此时若再有进程要求申请该资源，则必须在此信号量上等待，具体表现为：将信号量的值减 1，导致信号量的取值为负。
- 此时有几个进程申请该资源，信号量便被减几次；因此 S 的值为 -3，则表示有 3 个进程在等待该资源。

##### 算法和数据结构

给你一个数组，求 KMP 算法的模式串？

背包问题（选择题，直接算选项！）

图：节点数和边数相等，一定连通吗？一定有环吗？

黑白翻转：一个数组的元素只有黑、白两种状态，初始时全部为黑，每一次操作会将（L, R）下标范围内的元素翻转（黑变白、白变黑），一共操作 q 次，给出每一次的（L, R），返回每一次翻转后当前数组黑色元素的个数。

##### Java 基础

protected 的作用范围？
- 被修饰的成员可以在：本类、同包、不同包下的子类中使用。
- 不能修饰类，修饰类只能用：默认、public、final、abstract。
- 四种级别，由高到低：public、protected、默认、private。

在继承关系中，父类和子类中静态方法、构造方法的执行顺序？
- 静态 > 构造，静态方法在 Java 虚拟机加载的时候就会运行。
- 父类 > 子类，先初始化父类，再初始化子类。
- 因此执行顺序为：父类的静态方法、子类的静态方法、父类的构造方法、子类的构造方法。

##### C++ 基础

函数指针？

> [c++ 函数指针_途径北海道的博客-CSDN博客_c++ 函数指针](https://blog.csdn.net/zj1131190425/article/details/92065897)

##### Linux

文件系统有哪些？
- 文件系统类型就是分区的格式，管理磁盘空间的方式不同。
- Linux：
  - EXT（Extended file system）是延伸文件系统、扩展文件系统，ext1 于 1992 年 4 月发表，是为 linux 核心所做的第一个文件系统。
  - ext2：极快的速度、极小的 CPU 占用率。
  - ext3：增加日志功能，可回溯追踪。
  - ext4：日志式文件系统，支持连续写入，可以减少文件碎片。
  - xfs：是 centOS7.x 默认的文件系统，是一种高性能的日志文件系统。
- Windows：vfat。

复制指令？
- 语法：cp + 选项 + 源文件或目录 + 目标目录。
- -r / -R：递归处理，将指定目录下的子文件和子目录一并处理（复制目录的时候使用）。

##### 数学（智力题）

一天中时针、分针、秒针重合的次数？2 次，12 点的时候

## 美团

### 美团支付

#### 笔试

5 道算法题

#### 一面

Linux 系统如何查看文件日志？权限管理？chmod 777 设置的权限是什么？

http 状态码 502、503 是什么意思？

https 网站发送给客户端的证书是什么？

说一说知道的对称加密、非对称加密算法？

TCP 的 timeout 状态？时长是多少？

SQL 语句实现查询？group by 查询分组的平均值？如何优化 SQL 语句的查询速度（给需要查询的字段建立联合索引）？使用索引进行查询为什么比直接查询要快（b+ 树查询速度 > 直接遍历每一行的速度）？

算法题：买卖股票，可以多次买入卖出，求最后可以获得的最大利润？

> 题目链接：[122. 买卖股票的最佳时机 II - 力扣（LeetCode）](https://leetcode.cn/problems/best-time-to-buy-and-sell-stock-ii/)

### 金融平台

#### 一面

MySQL 存储引擎、事务、锁机制、日志？

MySQL 如何优化慢查询？

Redis 5 种数据结构？

什么是死锁？如何发现并解决？

Java 对象的内存分配？

JVM 垃圾回收器？

synchronized 和 ReentrantLock 的区别？

Spring 声明式事务的实现原理？传播机制？

Spring Bean 的声明周期？

算法题：最长不包含重复字符的子串。

你觉得本科和研究生学习最大的区别是什么？

有什么兴趣爱好？

#### 二面

Springboot 的启动流程？启动类上注解的作用和原理？

MySQL 索引最左匹配原则？面试官写不同的 SQL 语句，判断有没有用到索引？

算法题：移除有序数组中的重复元素，返回最后的数组长度。

## 滴滴

### 国际化策略

#### 笔试

Java 使用反射的优缺点？

Java 每个类对象对应的字节码相同吗？通过“类.class”能获取到对应的 class 类吗？

一个线程对象只能调用一次 start() 方法吗？通过 start() 方法调用 run() 是异步执行的吗？

Http 的 Range 和 Content-Range 的内容含义？

#### 一面

MySQL 的 undolog、redolog、binlog？binlog 的三种格式？

QUIC 协议？如何保证可靠性？

MVCC？

TCP 如何保证可靠性？

Redis 的五种数据类型，底层是怎么实现的？RDB 的原理？save 和 bgsave 是如何进行的？

http 客户端如何判断证书的合法性？如何预防中间人攻击？

MySQL 的快照读和当前读？

## 字节

### 实时通信（RTC）

#### 一面

LTE 项目为什么要使用 sctp？相比与 tcp 和 udp 有什么优势？使用哪个库实现的？多流特性是如何体现的？

udp 头的大小？包含的内容？

tcp 和 udp 在服务端能同时使用吗？

C++ 虚函数和纯虚函数的区别？

Java 深拷贝和浅拷贝？

udp 的使用场景？现在进行视频面试使用的是 tcp 还是 udp？wireshark 抓包分析一下？

值传递和引用传递的区别？

算法题：二叉树的层序遍历。

### 搜索业务

#### 一面

Spring 是什么？Springboot 是用来干什么的？

MySQL 主库与从库数据同步的延迟是多少？如果对主库进行了增删改，但是从库还没来得及更新，然后从从库读到了脏数据应该怎么处理？

Redis 为什么比 MySQL 快？我说 Redis 是基于内存的，所以快，面试官又问那现在的服务器内存都很大，MySQL 不能直接放内存吗？

wireshark 是工作在计算机网络中的哪一层的？

Linux 系统查看一个目录下文件的命令？ll、ls 命令的别名（原义）是什么？

算法题：股票问题。只能一次买入和卖出，求获取最大利润时，买入和卖出的数组下标（即是在哪一天买入，在哪一天卖出的）；变形：最多可以买入和卖出 2 次，继续求解？

#### 二面

Go 语言的协程为什么上下文切换快？differ 函数是用来干什么的？有什么好处？

Go 语言和 Python 语言有什么区别？

操作系统是怎么进行内存管理的？

当执行范围查询时，查到的是很多条数据，这个时候 Redis 缓存的 key 应该是这一条 SQL 语句，缓存的 value 是这些查到的数据，然后我们修改了其中一条数据，这个时候缓存应该如何进行处理？是直接把刚才这条 SQL 查到的所有数据的缓存都删了吗？你用的 SpringCache 框架能够实现这样的机制吗？

Redis 的热点 key 和大 value 问题？当 Redis 存的 value 特变大（好几个 G）的时候，会影响 Redis 的性能，如何处理？

你在项目中使用过 Redis 的哪些数据结构？

你的项目中 Redis 的缓存命中率有多少？

服务器启动后做了哪些事？面试官提示：比如说你运行一个 .exe 应用程序，操作系统会为这个程序创建一个进程，然后呢？

什么是私网 ip 和公网 ip？NAT 原理？内网的主机是如何与公网上的主机进行通信的？

了解 RPC 框架吗？

算法题：LRU 缓存算法。

#### 三面

Go 语言有什么特点？

你了解哪些设计模式？

作为通信专业的学生，你在自学计算机的过程中遇到过哪些困难？是如何解决的？

算法题：实现 36 进制的加法。

### Pico

#### 一面

Java 的函数形参传入一个对象时，是引用传递还是值传递？

Redis 集群有哪几种搭建方式？Redis 查找一个 key，是如何分辨应该去哪一个 Redis 进行查找的（非一致性哈希，哈希槽映射）？一致性哈希的应用场景（RPC 框架上下游通信）？

RPC 框架了解吗？

设计题：如何快速查询离用户位置最近的一些商铺，MySQL 应该如何设计？（空间栅格化：每一个商铺用一个字段表示所属的位置区，查询与用户地理位置属于同一片区域的商铺）

设计题：如何用 Redis 实现限制每个 IP 在一分钟内访问的次数不超过 3 次？（将用户的 IP 作为 key，value 使用 list，动态维护 3 个节点，表示最近 3 次访问的时间点，每一次用户访问，将当前时间与之前 3 次访问的时间进行对比，判断是否放行，并移除最老的节点，将最新的时间点存放到链表的末尾）

算法题：（会议室）要安排下所有的会议，最少需要几个会议室？ 

## 百度

### 商业平台研发部

#### 一面

Java 中的 final 在修饰类、方法、变量时分别有什么用？什么是不可变类？不可变类有哪些（String、基本数据类型的包装类）？如何自己实现一个不可变的类（成员变量用 private、final 修饰，不提供 set 方法，构造方法使用 clone 拷贝传入的对象，创建新的实例对象）？字符串常量池，举例：String s  = "hello"; s += " world"; 后会发生什么（s 指向新的地址，字符串常量池中会有 "hello"、"hello world" 两个字符串常量）？

Java 为什么是单继承和多实现？如果是多继承会有什么问题？接口的默认方法？

ThreadLocal？

Throwable 接口的子类有哪些？常见的 error 和 exception 有哪些？

如何查看一条 SQL 语句是否使用了索引（explain）？

MySQL 主从复制的原理？什么时候会出现延迟？如果主从复制出现延迟后，主库崩掉了，此时应该怎么做？

MySQL 服务器如何应对短时高并发的场景（消息队列）？

如何使用 Spring 打印一个方法的名字、参数、执行时间（AOP：@Before 中记录当前时间并存入 ThreadLocal，@After 中从 ThreadLocal 中取出之前记录的时间，并获取当前时间与之相减）？

算法：求两个字符串的最长公共子序列（dp）。

## 快手

### 信息安全中心

#### 一面

介绍项目：项目中的 http 接口是你实现的吗？遇到过什么困难？接口数有多少？

Java 集合你熟悉哪些？HashMap 的实现？ConcurrentHashMap 的实现？这两种 Map 在 jdk 1.7 和 jdk 1.8 的实现有什么区别？ConcurrentHashMap 的加锁是如何实现的？

Synchronized 与 ReentrantLock 的区别？什么是公平锁与非公平锁？各自的底层实现？

volatile？

MySQL innodb 的事务特性？事务的原子性（undolog）和持久性（redolog）是如何保证的？如果一个事务执行到一半时，MySQL 服务器崩掉了，这个时候的原子性如何保证？

算法题：寻找旋转数组的最小值。

#### 二面

说一下项目使用到的技术？

Https 的原理？

SpringMVC 的 Controller 中给前端提供接口，以及向前端返回 Json 格式数据分别应该使用什么注解？

算法题：反转链表的一部分、寻找字符串的最长回文子串。

#### 三面

外卖项目：用户登录，分配一个 cookie 还是 session？

外卖项目：难点是什么？

外卖项目：有哪些功能模块？有哪些实体（表）？

介绍一下你们实验室的通信项目？

目前面试情况、offer 情况？为什么没有实习？在校期间还做过别的项目吗？

可以提前来实习吗？

## 蚂蚁

### 大安全技术部

#### 一面

介绍下你的两个项目？

什么是死锁？如何避免？（举例说明）

Java 垃圾回收机制？（举例说明）

http 和 https 的原理和区别？

XSS（脚本跨站攻击）了解吗？

Java 注解的实现原理？应该什么时候使用注解，什么时候使用 xml 文件？所有能使用注解的地方都应使用注解吗？如何控制其使用频率？

假设支付宝 app 上只有一个转账的功能，如何进行测试？

如何才能保证测试用例的完全覆盖？
