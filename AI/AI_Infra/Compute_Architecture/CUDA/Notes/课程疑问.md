# 课程疑问

## 32. FP16 GELU 算子

1. 在调用 kernel 之前，先判断了数据是否对齐，那什么情况才是没对齐的呢？好像数据创建之后直接就对齐了。

if (n % 8 == 0 && is_aligned(x, kAlignment) && is_aligned(y, kAlignment)) {...}

2. 在 GeluFunctor<half> 里，为什么一定要先转换为 float 去计算再转换回来？

__device__ half operator()(const half x) const {
    return static_cast<half>(float_functor(static_cast<float>(x)));
}

3. 最后释放 host 数据内存的时候，直接用 delete 好像也没问题，但是我搜了一下释放数组内存不是应该用 delete[] 吗？

delete x;
delete y;

4. 我尝试实现了一个最简单的不使用 AlignedVector、不使用向量化存取的版本，跑了一下性能和课程里的（不启用 Ampere 代码）好像没啥区别，这是什么原因呢？
