# AI 框架核心技术

## AI 框架基础

### AI 框架的作用

灵活的编程模型/编程接口：

- 自动推导计算图；
- 支持 AI 生态；
- 直观地构建模型，语言简洁。

高效 & 可扩展的计算能力：

- 自动编译优化算法；
- 支持多种硬件，自动并行化。

总结：上承应用算法，下接芯片使能。

### 发展历史

第三代 AI 框架的分层结构：

- **前端**：前端编程语言和接口；
- **统一表示**：神经网络模型中间表示（计算图）；
- **优化层**：自动微分、计算图优化；
- **运行时**：内存管理、计算图调度/执行；
- **底层库**：内核代码优化与编译、计算硬件支持。

### 编程范式

- 命令式编程；
- 声明式编程。

**命令式编程**：
define-by-run/动态图。
前端语言直接驱动后端算子执行，用户表达式会立即被求值。
如：PyTorch。

- 优点：方便调试、灵活性高；
- 缺点：缺少对算法的统一描述、缺乏编译期优化。

**声明式编程**：
define-and-run/静态图。
前端语言中的表达式不直接执行，而是构建一个完整的前向计算过程的表示，对数据流图经过优化后再执行。
如：TensorFlow。

- 优点：执行之前得到全程序描述、运行前编译优化、性能优化；
- 缺点：数据和控制流限制强、不方便调试、灵活性低。

其它方式：

- 分阶段编程（Multi-stage）；
- 及时编译（JIT）。

## 计算图

### 基本概念

计算图（数据流图，DAG，有向无环图）：

- 节点：算子；
- 边：张量；
- 控制流（如 for/while）。

计算图解决了 AI 系统向下硬件执行计算的统一表示，向上承接 AI 相关程序的表示。

### 计算图与自动微分

将导数的计算也表示成计算图，通过 Graph IR 来对计算图进行统一表示。
反向传播时，需要存储中间变量。
如：TensorFlow、MindSpore。

- 不便于调试跟踪计算和数学表达过程；
- 方便全局图优化；
- 节省内存。

前端语言定义网络模型 -> 构建正向计算图 -> 通过自动微分构建反向计算图 -> 计算图优化。

## 自动微分

...

## PyTorch

### 2.0 新特性

- TorchDynamo：引入 `torch.compile()` 图编译模式；
- AOTAutograd；
- TorchInductor：引入 OpenAI Triton，支持用 Python 取代 CUDA 编程来写底层硬件的代码；
- PrimTorch：将 2000 个算子用 250 个基础算子实现，更加生态环保，使厂商对接更加方便。

### Dispatch 机制

针对一个算子/Tensor，有不同的 device。
Tensor 可以分为普通张量、稀疏张量，不同张量有不同的 layout（布局）。

注册/分发机制：
PyTorch Vtable：key（tag）-> value（具体函数的地址），新方法通过 register 注册到表里，接口通过 get 取到对应的函数实现并执行。
每个算子都会维护一个自己的 Vtable，扩展一个已有的算子，只需要提供一个新的 Vtable。

执行一个 add 算子：

1. dispatcher 找到这个算子对应的 dispatch key；
2. 根据这个 dispatch key 去找对应的 kernel 函数。
