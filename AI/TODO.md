# TODO

---

## LLM

- [ ] [zhang's Blog - Transformer](https://www.armcvai.cn/categories.html)
- [ ] [多模态技术梳理：ViT 系列](https://zhuanlan.zhihu.com/p/26719287825)
- [ ] [阿里通义千问 Qwen3 系列模型正式发布，该模型有哪些技术亮点？ - 刘聪 NLP 的回答 - 知乎](https://www.zhihu.com/question/1900300358229652607/answer/1900452232018767979)

---

## 推理引擎

- [ ] [3 万字详细解析清华大学最新综述工作：大模型高效推理综述](https://mp.weixin.qq.com/s/U9ESiWehnoKc9SnDz7DVKg)
- [ ] [vLLM Blog - V1 Metrics](https://docs.vllm.ai/en/stable/design/v1/metrics.html)
- [ ] [zhang's Blog - LLM Infer](https://www.armcvai.cn/categories.html)
- [ ] [从零开始设计 SGLang 的 KV Cache](https://zhuanlan.zhihu.com/p/31160183506)
- [ ] [DeepSeek-V3 / R1 推理系统概览](https://zhuanlan.zhihu.com/p/27181462601)
- [ ] [GTC 2025 - CUDA 亮点内容](https://zhuanlan.zhihu.com/p/31444691908)
- [ ] [vLLM 框架 V1 演进分析](https://zhuanlan.zhihu.com/p/1894423873145004335)
- [ ] [吞吐量破 10000 tokens/s，VLLM 0.8.1 版本驱动下的 Deepseek-r1 671B](https://zhuanlan.zhihu.com/p/1887527788514346095)
- [ ] [LLM (18)：LLM 的推理优化技术纵览](https://zhuanlan.zhihu.com/p/642412124?utm_psn=1897433318875693188)
- [ ] [图文详解 LLM inference：KV Cache](https://zhuanlan.zhihu.com/p/1893220743053030641?utm_psn=1897576305303721590)
- [ ] [大模型推理 - 为什么要 PD 分离？](https://zhuanlan.zhihu.com/p/1897270081664300462?utm_psn=1897629970966217092)
- [ ] [图解 vLLM Prefix Prefill Triton Kernel](https://zhuanlan.zhihu.com/p/695799736?share_code=Hz1PZDdfXLy7&utm_psn=1900943218725598209)
- [ ] [vLLM 的 prefix cache 为何零开销](https://zhuanlan.zhihu.com/p/1896927732027335111)
- [x] [vLLM V1 Scheduler 的调度逻辑 & 优先级分析](https://zhuanlan.zhihu.com/p/1900957007575511876?share_code=o9ZDfDnEpemP&utm_psn=1901069245619635086)
- [x] [图解 Vllm V1 系列 1：整体流程 - 猛猿](https://zhuanlan.zhihu.com/p/1900126076279160869?share_code=18FtZ4wqQM3hR&utm_psn=1900940137866716878)
- [x] [图解 Vllm V1 系列 2：Executor-Workers 架构 - 猛猿](https://zhuanlan.zhihu.com/p/1900613601577899465)
- [x] [图解 Vllm V1 系列 3：KV Cache 初始化 - 猛猿](https://zhuanlan.zhihu.com/p/1900932850829730567)
- [x] [vLLM V1 源码阅读](https://zhuanlan.zhihu.com/p/32045324831)（V1 全流程讲解，很细节）
- [x] [LLM 高速推理框架 vLLM 源代码分析](https://me.tric.space/2023/07/10/vllm/)（23 年写的，有点过时，但关于 Scheduler 的部分讲的不错）
- [x] [AI Infra 之模型显存管理分析](https://mp.weixin.qq.com/s/lNcszOFnGVktBRAAsHDVIA)（计算显存、推理时延评估方法）

---

## PyTorch

- [ ] [<u>PyTorch internals</u>](http://blog.ezyang.com/2019/05/pytorch-internals/)
- [ ] [<u>PyTorch dispatcher</u>](http://blog.ezyang.com/2020/09/lets-talk-about-the-pytorch-dispatcher/)

---

## CUDA

- [ ] [zhang's Blog - CUDA](https://www.armcvai.cn/categories.html)
- [ ] [腾讯云 CUDA 环境搭建](https://face2ai.com/CUDA-F-0-0-Tencent-GPU-Cloud/)
