# AI 推理引擎

## 基础知识

- [x] Transformer/SelfAttention 原理（精读论文：Attention is all you need）
- [ ] FlashAttention 原理（精读论文）
- [x] KVCache 原理
- [ ] FasterTransformer/DeepSpeed/TensorRT-LLM 使用（推理加速）
- [ ] CUDA/CANN 编程（算子开发）

## vLLM

- [x] 精读 PagedAttention 论文
- [ ] 阅读 vLLM 源码
- [ ] Prefill/Decode 性能分析（PD 混合/分离）

## 参考资料

- [<u>Basic LLM Inference/Generation</u>](https://zhuanlan.zhihu.com/p/694176507)
- [<u>Deep dive vLLM 和 SGLang 推理框架的 CPU 开销</u>](https://mp.weixin.qq.com/s/ZH6vzQFg9NNoPRyTgtdY4Q)
