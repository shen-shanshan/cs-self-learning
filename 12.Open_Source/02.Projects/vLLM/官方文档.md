# 官方文档

基本信息：

- [Installation](https://docs.vllm.ai/en/stable/getting_started/installation.html)
- [Contributing to vLLM](https://docs.vllm.ai/en/stable/contributing/overview.html)

整体设计：

- [Architecture Overview](https://docs.vllm.ai/en/stable/design/arch_overview.html)

Automatic Prefix Caching：

- [Introduction](https://docs.vllm.ai/en/stable/automatic_prefix_caching/apc.html#)
- [Implementation](https://docs.vllm.ai/en/stable/automatic_prefix_caching/details.html)

LoRA：

- [MultiLoRA Inference](https://docs.vllm.ai/en/stable/getting_started/examples/multilora_inference.html)
- [LoRA Adapters](https://docs.vllm.ai/en/stable/usage/lora.html)
