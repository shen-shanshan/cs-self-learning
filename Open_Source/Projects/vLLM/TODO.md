# TODO

## vllm-ascend

## vllm

- 在 NPU 上测试 `openai_chat_completion_structured_outputs_structural_tag.py`
- Spec Decode 相关代码优化
- V1 代码中的 `TODO`

## 技术学习

- [vLLM PD 分离方案浅析](https://zhuanlan.zhihu.com/p/1889243870430201414?utm_psn=1889596220076426760)
- DeepSeek 相关：MLA、MTP、DeepEP
- 分布式并行技术
- MoE

## 技术博客

- V1 整体架构
- V1 推理流程
- V1 调度机制
- KVCache 管理
- speculative decoding
- chunked prefills（V1 默认启用）
- prefix caching（V1 默认启用）
- continuous batching
- 硬件插件
- 模型支持
- 多模态（以 Qwen2.5-VL 为例）
