# PRs

vllm:

- [[V1][Core] Support for Structured Outputs](https://github.com/vllm-project/vllm/pull/12388)
- [[V1][Spec Decode] Ngram Spec Decode](https://github.com/vllm-project/vllm/pull/12193)
- [[RFC]: Implement Structured Output support for V1 engine](https://github.com/vllm-project/vllm/issues/11908)
- [[V1] Logprobs and prompt logprobs support](https://github.com/vllm-project/vllm/pull/9880)

vllm-ascend:

- [[RFC] V1 engine support](https://github.com/vllm-project/vllm-ascend/issues/9)

## Docs

- [Python Multiprocessing](https://docs.vllm.ai/en/latest/design/multiprocessing.html)
- [Troubleshooting](https://docs.vllm.ai/en/latest/getting_started/troubleshooting.html#troubleshooting-python-multiprocessing)
