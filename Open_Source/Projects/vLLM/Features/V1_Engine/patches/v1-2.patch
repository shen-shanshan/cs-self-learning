From 3bd89571be54a26f831a176dc43f290e383e884f Mon Sep 17 00:00:00 2001
From: d00516182 <didongli@huawei.com>
Date: Thu, 6 Mar 2025 11:12:02 +0800
Subject: [PATCH 2/2] =?UTF-8?q?=E9=80=82=E9=85=8D=E6=9C=80=E6=96=B0main?=
 =?UTF-8?q?=E4=BB=A3=E7=A0=81?=
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

---
 vllm_ascend/v1/npu_model_runner.py | 10 ++--------
 vllm_ascend/v1/npu_worker.py       |  4 ++++
 2 files changed, 6 insertions(+), 8 deletions(-)

diff --git a/vllm_ascend/v1/npu_model_runner.py b/vllm_ascend/v1/npu_model_runner.py
index ba1a4db..ec334cb 100644
--- a/vllm_ascend/v1/npu_model_runner.py
+++ b/vllm_ascend/v1/npu_model_runner.py
@@ -341,8 +341,7 @@ class NPUModelRunner(LoRAModelRunnerMixin):
 
             start_index = (len(req_state.block_ids) -
                            len(req_data.new_block_ids))
-            self.input_batch.block_table.append_row(req_index, start_index,
-                                                    req_data.new_block_ids)
+            self.input_batch.block_table.append_row(req_data.new_block_ids, req_index)
             # Add new_token_ids to token_ids_cpu.
             # 把新请求内容放到token_ids_cpu中存储
             start_token_index = num_computed_tokens
@@ -502,8 +501,6 @@ class NPUModelRunner(LoRAModelRunnerMixin):
             hidden_states = self.model(
                 input_ids=input_ids,
                 positions=positions,
-                kv_caches=self.kv_caches,
-                attn_metadata=attn_metadata,
                 intermediate_tensors=intermediate_tensors,
                 inputs_embeds=None,
             )
@@ -521,8 +518,7 @@ class NPUModelRunner(LoRAModelRunnerMixin):
         logits = self.model.compute_logits(hidden_states, None)
 
         # Sample the next token and get logprobs if needed.
-        sampling_metadata = self.input_batch.get_sampling_metadata(
-            scheduler_output.scheduled_spec_decode_tokens)
+        sampling_metadata = self.input_batch.sampling_metadata
         sampler_output = self.model.sample(
             logits=logits,
             sampling_metadata=sampling_metadata,
@@ -705,8 +701,6 @@ class NPUModelRunner(LoRAModelRunnerMixin):
                 positions=positions.to(self.device),
                 intermediate_tensors=intermediate_tensors,
                 inputs_embeds=inputs_embeds,
-                kv_caches=dummy_kv_caches,
-                attn_metadata=None,
             )
         return hidden_states
 
diff --git a/vllm_ascend/v1/npu_worker.py b/vllm_ascend/v1/npu_worker.py
index ceced8f..85f98f2 100644
--- a/vllm_ascend/v1/npu_worker.py
+++ b/vllm_ascend/v1/npu_worker.py
@@ -233,6 +233,10 @@ class NPUWorker(WorkerBase):
         else:
             self.profiler.stop()
 
+    def initialize_from_config(self, kv_cache_config: KVCacheConfig) -> None:
+        """Allocate NPU KV cache with the specified kv_cache_config."""
+        self.model_runner.initialize_kv_cache(kv_cache_config)
+
 def init_worker_distributed_environment(
         parallel_config: ParallelConfig,
         rank: int,
-- 
2.47.0.windows.2

