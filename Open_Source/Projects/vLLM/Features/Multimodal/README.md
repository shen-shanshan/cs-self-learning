# Multimodal

## 学习资料

**多模态基础：**

- [ ] [多模态技术梳理：ViT 系列](https://zhuanlan.zhihu.com/p/26719287825)
- [x] [vit 论文速读](https://www.armcvai.cn/2024-09-08/vit-paper.html)
- [x] [ViT 解读](https://datawhalechina.github.io/thorough-pytorch/%E7%AC%AC%E5%8D%81%E7%AB%A0/ViT%E8%A7%A3%E8%AF%BB.html)
- [x] [ViT pytorch 实现](https://github.com/lucidrains/vit-pytorch/blob/main/vit_pytorch/vit.py)
- [ ] [LLaVA 系列模型结构详解](https://www.armcvai.cn/2024-11-28/llava-structure.html)
- [ ] [Qwen2.5-VL 论文](https://arxiv.org/abs/2502.13923)
- [ ] [Qwen2.5-VL 代码](https://github.com/QwenLM/Qwen2.5-VL)
- [ ] [vLLM V1 - 7. Enhanced Support for Multimodal LLMs](https://blog.vllm.ai/2025/01/27/v1-alpha-release.html)

**vLLM 相关：**

- [x] [Multi-Modal Support](https://docs.vllm.ai/en/latest/contributing/model/multimodal.html)
- [x] [Multi-Modal Data Processing](https://docs.vllm.ai/en/latest/design/mm_processing.html)
- [x] [Multimodal Inputs](https://docs.vllm.ai/en/stable/features/multimodal_inputs.html)
- [ ] [vllm.multimodal](https://docs.vllm.ai/en/latest/api/vllm/multimodal/index.html)

**其它：**

- [torchcodec](https://github.com/pytorch/torchcodec)
