# vllm 多模态适配

- [Multi-modality Support on vLLM](https://github.com/vllm-project/vllm/issues/4194)
- [Multi-modality Core](https://github.com/orgs/vllm-project/projects/8/views/4)
- [Multi-modal Model Requests](https://github.com/orgs/vllm-project/projects/10/views/1)

---

## Merge input processor and input mapper for multi-modal models

**Info (PRs / Issues):**

- [ ] [Automatically cast multi-modal input dtype](https://github.com/vllm-project/vllm/pull/18756)
- [x] [Call async method of input preprocessor](https://github.com/vllm-project/vllm/pull/18134)
- [ ] [Parallel multi-modal processor](https://github.com/vllm-project/vllm/pull/17831)
- [ ] [DP scale-out (2/N): Decouple engine process management and comms](https://github.com/vllm-project/vllm/pull/15977)
- [x] [Remove legacy input mapper/processor from V0](https://github.com/vllm-project/vllm/pull/15686)
- [x] [Refactor Phi-4-multimodal to use merged processor and support V1](https://github.com/vllm-project/vllm/pull/15477)
- [x] [Support caching in merged multi-modal processor](https://github.com/vllm-project/vllm/pull/11396)
- [x] [Merge input processor and input mapper for multi-modal models](https://github.com/vllm-project/vllm/issues/10114)
- [ ] [vLLM's V1 Engine Architecture](https://github.com/vllm-project/vllm/issues/8779)

**Main Changes:**

- **Unified multi-modal processor:**
  - Text-only prompt: Pass to vLLM tokenizer (wraps HF AutoTokenizer) [Unchanged]
  - List of token IDs: Skip vLLM tokenizer [Unchanged]
  - **Text prompt with multi-modal input:** Pass to vLLM multi-modal processor [NEW]
  - **List of token IDs with multi-modal input:** Pass to vLLM multi-modal processor [NEW]
- **Automatic prompt replacement:**
  - `_get_prompt_replacements()`: automatically detect whether HF has replaced the input placeholder tokens.
  - `_apply_prompt_replacements()`: automatically replacing input placeholder tokens with feature placeholder tokens.
  - `_apply_hf_processor_main()`: accept text/token prompts and process them separately from the multi-modal data.

**TODO:** [Remove these methods in model runner](https://github.com/vllm-project/vllm-ascend/issues/673).

```
MultiModalRegistry.has_processor
MultiModalRegistry.create_input_mapper
MultiModalRegistry.init_mm_limits_per_prompt
```

---
