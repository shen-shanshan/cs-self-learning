# 实验记录

测试脚本：`vllm-project/vllm/examples/offline_inference$ python structured_outputs.py`

模型：

```bash
/home/sss/cache/modelscope/models/Qwen/Qwen2___5-7B-Instruct
/home/sss/cache/modelscope/models/LLM-Research/Meta-Llama-3-8B-Instruct
```

## 适配前

测试结果如下：

```bash
INFO 02-25 01:25:02 executor_base.py:111] # npu blocks: 45414, # CPU blocks: 4681
INFO 02-25 01:25:02 executor_base.py:116] Maximum concurrency for 100 tokens per request: 7266.24x
INFO 02-25 01:25:02 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 6.66 seconds
WARNING 02-25 01:25:05 __init__.py:33] xgrammar is only supported on x86 CPUs. Falling back to use outlines instead.
WARNING 02-25 01:25:05 __init__.py:33] xgrammar module cannot be imported successfully. Falling back to use outlines instead.
('Warning: torch.save with "_use_new_zipfile_serialization = False" is not recommended for npu tensor, which may bring unexpected errors and hopefully set "_use_new_zipfile_serialization = True"', 'if it is necessary to use this, please convert the npu tensor to cpu tensor for saving')
Processed prompts: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.62it/s, est. speed input: 73.09 toks/s, output: 13.29 toks/s]
Positive
WARNING 02-25 01:25:17 __init__.py:33] xgrammar is only supported on x86 CPUs. Falling back to use outlines instead.
WARNING 02-25 01:25:17 __init__.py:33] xgrammar does not support regex guided decoding. Falling back to use outlines instead.
Processed prompts: 100%|████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.24s/it, est. speed input: 7.54 toks/s, output: 1.89 toks/s]
alan_turing@enigma.com
WARNING 02-25 01:25:23 __init__.py:33] xgrammar is only supported on x86 CPUs. Falling back to use outlines instead.
WARNING 02-25 01:25:23 __init__.py:33] xgrammar does not support advanced JSON schema features like enums, patterns or numeric ranges. Falling back to use outlines instead.
Processed prompts: 100%|████████████████████████████████████████████████████████████████████| 1/1 [00:13<00:00, 13.08s/it, est. speed input: 1.68 toks/s, output: 1.22 toks/s]
{"brand": "Ford", "model": "Mustang", "car_type
WARNING 02-25 01:25:42 __init__.py:33] xgrammar is only supported on x86 CPUs. Falling back to use outlines instead.
WARNING 02-25 01:25:42 __init__.py:33] xgrammar does not support Lark grammars and the grammar failed to convert to GBNF. Falling back to use outlines instead.
/home/sss/software/miniconda3/envs/vllm/lib/python3.10/site-packages/outlines/fsm/guide.py:110: UserWarning: Outlines' public *community-contributed* CFG structured generation is experimental. Please review https://dottxt-ai.github.io/outlines/latest/reference/generation/cfg#disclaimer
  warnings.warn(
Processed prompts: 100%|████████████████████████████████████████████████████████████████████████| 1/1 [08:01<00:00, 481.33s/it, est. speed input: 0.04 toks/s, output: 0.03 toks/s]
SELECT username,email FROM usersonentokddt839npt0
```

问题：

```bash
'Warning: torch.save with "_use_new_zipfile_serialization = False" is not recommended for npu tensor, which may bring unexpected errors and hopefully set "_use_new_zipfile_serialization = True"', 'if it is necessary to use this, please convert the npu tensor to cpu tensor for saving'
```

## 适配后

测试结果如下：

```bash
...
```
