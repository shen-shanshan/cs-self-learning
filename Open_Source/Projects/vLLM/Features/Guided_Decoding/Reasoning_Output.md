# Reasoning Output

## 基本概念

### Reasoning Models

推理模型，顾名思义指具备推理能力的大语言模型（如：DeepSeek-R1），目前业内有“Understanding Reasoning LLMs”、“Reasoning models”、“Reasoning LLMs”等多种说法。

**两大特点：**

1. **复杂任务/场景适应性强**：推理模型尤其擅长将复杂问题/任务分解后，高度还原人类的思维过程（如尝试和验证不同的方法，直至找到最佳解决方案，输出结果），这种方式可能导致推理时间延长，但在理解和处理复杂的任务场景时，成功率和精准度却能成倍增长。而且通过多场景的强化学习，大模型在新问题中的泛化能力和鲁棒性也更好；
2. **可解释性更强**：相比以往直接输出答案，推理模型还会详细、分步骤给出推理过程，用来解释为什么会给出这样的答案。虽然最终的答案可能和通用大模型直接生成的答案类似，但因为推理过程公开透明，使得一定程度上能打破大众对大模型“黑盒”问题的顾虑，推理模型生成的答案，可信度与可解释性也因此大幅增强。此外，即便输出结果有偏差，通过检查和纠正推理步骤，也能更快发现问题，整个过程也更可控。
