# 性能调优

[How to quickly run a perf benchmark to determine if performance has improved](https://github.com/vllm-project/vllm-ascend/issues/864)

```bash
export VLLM_USE_MODELSCOPE=true

pip install mindie-turbo -i https://pypi.tuna.tsinghua.edu.cn/simple
# MindIE Turbo is installed. vLLM inference will be accelerated with MindIE Turbo.
pip install pandas datasets -i https://pypi.tuna.tsinghua.edu.cn/simple

# source /home/sss/Ascend/ascend-toolkit/set_env.sh
# source /home/sss/Ascend/nnal/atb/set_env.sh

source /usr/local/Ascend/ascend-toolkit/set_env.sh
source /usr/local/Ascend/nnal/atb/set_env.sh

# launch server
python -m vllm.entrypoints.openai.api_server \
--model Qwen/Qwen2.5-7B-Instruct \
--tensor-parallel-size 1 \
--swap-space 16 \
--disable-log-stats \
--disable-log-requests \
--load-format dummy \
--additional-config '{"ascend_scheduler_config":{}}'
# ‘{”config_key”:”config_value”}’
# '{"ascend_scheduler_config":{}}'
# {"ascend_scheduler_config":{}}

# run benchmark
cd /vllm-workspace/vllm/benchmarks
python benchmark_serving.py \
--model Qwen/Qwen2.5-7B-Instruct \
--dataset-name random \
--random-input-len 200 \
--num-prompts 200 \
--request-rate 1 \
--save-result --result-dir ./
```

开启前：

```bash
============ Serving Benchmark Result ============
Successful requests:                     200       
Benchmark duration (s):                  187.54    
Total input tokens:                      40000     
Total generated tokens:                  25600     
Request throughput (req/s):              1.07      
Output token throughput (tok/s):         136.51    
Total Token throughput (tok/s):          349.79    
---------------Time to First Token----------------
Mean TTFT (ms):                          63.83     
Median TTFT (ms):                        63.35     
P99 TTFT (ms):                           82.36     
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          22.22     
Median TPOT (ms):                        22.35     
P99 TPOT (ms):                           23.83     
---------------Inter-token Latency----------------
Mean ITL (ms):                           22.22     
Median ITL (ms):                         21.63     
P99 ITL (ms):                            48.08     
==================================================
```

开启后：

```bash

```
