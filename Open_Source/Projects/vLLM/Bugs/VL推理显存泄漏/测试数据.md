# 显存测试数据

启动服务：

```bash
watch -n 0.2 npu-smi info

VLLM_LOGGING_LEVEL=DEBUG \

vllm serve /root/.cache/modelscope/hub/models/Qwen/Qwen3-VL-8B-Instruct \
--tensor-parallel-size 2 \
--max-model-len 65536 \
--max-num-seqs 8 \
--max-num-batched-tokens 32768 \
--gpu-memory-utilization 0.95
```

## 旧 profiling 方法

**gpu_xxx = 0.95 时：**

```bash
Loading model weights took 9.1948 GB
Available memory: 43.396 GiB, total memory: 60.96 GiB
```

**gpu_xxx = 0.9 时：**

```bash
torch_memory before profiling is 10.25 G
torch_peak before profiling is 9.45 G
non_torch_memory before profiling is 0.36 G

torch_memory after profiling is 9.75 G
torch_peak after profiling is 13.30 G
non_torch_memory after profiling is 0.91 G

# results of real profiling:
peak_memory after profiling is 13.30 G
non_torch_memory after profiling is 1.21 G  # updated: 

Available memory: 40.35 GiB, requested memory: 54.86 GiB
```

## 新 profiling 方法

**gpu_xxx = 0.95 时：**

服务启动前：3409 / 65536
服务启动后：59614 / 65536 (进程占用：56257)

```bash
torch_memory before init HCCL is 0.00 G
torch_peak before init HCCL is 0.00 G
non_torch_memory before init HCCL is 0.35 G

torch_memory after init HCCL is 0.00 G
torch_peak after init HCCL is 0.00 G
non_torch_memory after init HCCL is 0.35 G

# Loading weights took 4.29 seconds
Loading model weights took 9.1948 GB
torch_memory before profiling is 9.75 G
torch_peak before profiling is 9.45 G
non_torch_memory before profiling is 0.36 G
# Encoder cache will be initialized with a budget of 32768 tokens, and profiled with 2 image items of the maximum feature size. (2.25 G ？)
# Qwen3-VL dummy_mm_data target_width: 4096.
# Qwen3-VL dummy_mm_data target_height: 4096.

torch_memory after profiling multi-modal is 17.69 G
torch_peak after profiling multi-modal is 13.30 G
non_torch_memory after profiling multi-modal is 1.05 G

torch_memory after profiling, before empty_cache() is 19.13 G
torch_peak after profiling, before empty_cache() is 13.30 G
non_torch_memory after profiling, before empty_cache() is 1.07 G

torch_memory after profiling, after empty_cache() is 9.75 G
torch_peak after profiling, after empty_cache() is 13.30 G
non_torch_memory after profiling, after empty_cache() is 0.91 G
peak_activation_memory new is 4.11 G

Initial free memory: 60.61 GiB; Requested memory: 0.95 (util), 57.91 GiB
Free memory after profiling: 50.30 GiB (total), 47.60 GiB (within requested)

Total non KV cache memory: 13.61 GiB;  # 13.86 G -> 14.37 G
torch peak memory increase: 3.86 GiB;  # peak = 13.30, increase = 4.11 ?
non-torch forward increase memory: 0.56 GiB;  # 1.06 G
weights memory: 9.19 GiB.

Available KV cache memory: 44.30 GiB  # 44.05 G -> 43.54 G
GPU KV cache size: 645,120 tokens  # ... -> 633,984
# encoder_compute_budget: 32768
# encoder_cache_size: 32768
```

KV cache memory: **44.30** GiB + Total non KV cache memory: **13.61** GiB
= Requested memory **57.91** GiB
= Initial free memory: **60.61** GiB * **0.95**

Total non KV cache memory: **13.61** GiB
= torch peak memory increase: **3.86** GiB + non-torch forward increase memory: **0.56** GiB + weights memory: **9.19** GiB.

**gpu_xxx = 0.9 时：**

```bash
Available KV cache memory: 40.49 GiB
```
