# 工作内容梳理（2025）

## 代码开发

**vllm-ascend：**

- V1 Engine 适配；
- Guided Decoding 适配；
- ModelRunner (V0)；
- 使用教程文档（用户体验）；
- 性能调优文档；
- 环境变量管理、格式化工具；
- Qwen3、Qwen3-MoE 模型适配；
- Qwen2.5-VL VeRL 场景适配；

**vllm：**

- Hardware Plugin 相关重构；
- Structured Output 特性重构与 Bugfix；
- Other Bugfix；

## 其它专项

- 负责 vllm-ascend 用户体验提升专项；
- 参与 vllm-ascend 社区 PR review、FAQ 维护、群聊答疑、Bugfix；
- 参与 vLLM 原生 UT 验证、模型支持验证；

---

## 2025 年中期审视

一、本周期工作回顾

主线工作内容如下：

1. 参与 vllm 昇腾硬件插件化方案的落地，包括：参与 vllm 上游 platform 相关重构、完成 vllm-ascend V0 组件的开发等工作；
2. 负责 vllm-ascend 用户体验提升专项，负责 vllm-ascend 内部体验测试工作的安排与问题闭环，并完成相应使用教程的编写。项目上线后，用户能够根据文档丝滑地跑通样例，为昇腾用户带来了极好的使用体验；
3. 参与 vllm-ascend 质量看护，包括：参与 vllm 原生 UT 梳理与测试、参与 vllm 模型支持测试、根据用户反馈完成相应 Bugfix 等工作；
4. 负责 vllm V1 Engine 的适配工作，包括：参与 V1 Worker / ModelRunner 等组件的开发与测试、负责 V1 特性清单的梳理与跟踪、持续参与后续的优化等工作；
5. 负责 vllm guided decoding (structured output) 特性的适配工作，包括：负责多种 grammar 后端在 V0 和 V1 上的适配和测试工作、遇到问题及时向 vllm 上游提 PR 进行优化、持续跟踪 vllm 社区该特性的发展与变化并持续集成到 vllm-ascend 中；
6. 参与 vllm-ascend 对 Qwen3 系列模型的适配，并负责解决 Qwen2.5-VL 在 VeRL 场景的适配问题；
7. 负责 vllm-ascend + mindie-turbo 性能调优的整体工作安排、端到端验证、指导文档编写；
8. 参与 vllm-ascend 开发工具和模块建设，包括：负责 vllm 格式化工具的迁移、环境变量管理模块的迁移与文档补齐等工作；
9. 参与 vllm-ascend 社区维护，包括：FAQ 整理、群聊答疑、PR review、Issue 回复、Bugfix 等工作。

小结：在整个 vllm 昇腾原生支持项目中，今年目前已累计贡献有效 PR 53 个。

支线工作内容如下：

1. 负责开源时刻整体安排，包括：各地域人员协调、议题规划与日程安排、GitHub 仓库维护、投稿审核与发布管理。

小结：在微信公众号和知乎两个平台上，今年已累计发布技术文章 XXX 篇。

二、下一步工作计划

1. 持续参与 vllm-ascend 的昇腾适配工作，持续参与对 vllm 上游社区的贡献；
2. 继续管理开源时刻相关事宜，保持文章发布频率，推动产出更多高质量内容。

三、问题与求助

1. 在 vllm-ascend 和 vllm 中还有许多多模态相关的工作可以参与，需要快速完成对这方面知识的补齐；
2. 目前的开发工作主要聚焦于推理框架的上层，对底层的算子、硬件等知识还有所欠缺，有时遇到偏底层的问题时不太会分析和排查。

---

## 2025 年全年总结

……
