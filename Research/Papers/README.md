# Papers

## 已读论文

- Scaling Down to Scale Up: A Guide to Parameter-Efficient Fine-Tuning
- Prefix-Tuning: Optimizing Continuous Prompts for Generation
- LORA: LOW-RANK ADAPTATION OF LARGE LANGUAGE MODELS
- QLORA: Efficient Finetuning of Quantized LLMs
- PUNICA: MULTI-TENANT LORA SERVING
- Efficient Memory Management for Large Language Model Serving with PagedAttention
- SGLang: Efficient Execution of Structured Language Model Programs
- Fast Inference from Transformers via Speculative Decoding
- Robust Text-to-SQL Generation with Execution-Guided Decoding

## 更多论文

- [<u>LLM Research Papers: The 2024 List</u>](https://magazine.sebastianraschka.com/p/llm-research-papers-the-2024-list?utm_source=publication-search)
